Btu in 2035 [1]. Compared to the transportation and industrial
sectors, the building sector consumes more energy (approximately
40% of global energy use) and generates 30% more CO 2 [2].
Therefore, a critical step in lowering carbon is reducing energy
consumption in buildings. Given the particularly high dependence
of Taiwan on imported fossil fuels, developing an economical, low-
carbon, and highly efficient green energy system is imperative [3].
Studies performed in the United Kingdom [4] and in the United
States [5] show that the growing use of energy-consuming equip-
ment beat efficiency gains in green building technology. The
increased energy consumption is mainly due to equipment for
maintaining comfort in residential and commercial buildings, such
as air conditioners, heaters and other mod[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBotomputer systems and the Internet from the malware, the malware needs to be detected before it affects a
large number of systems. Recently, there have been made several studies on malware detection approaches.
However, the detection of malware still remains problematic. Signature-based and heuristic-based detection
approachesarefastandefficienttodetectknownmalware,butespeciallysignature-baseddetectionapproach
has failed to detect unknown malware. On the other hand, behavior-based, model checking-based, and
cloud-based approaches perform well for unknown and complicated malware; and deep learning-based,
mobile devices-based, and IoT-based approaches also emerge to detect some portion of known and unknown
malware. However, no approach can detect all malware in the wild. This shows that to build an effective
method to detect malware is a very challenging task, and there is a huge gap for new studies and methods.
This paper presents a detailed review on malware detection approaches and recent detection methods which
use these approaches. Paper goal is to help researchers to have a general idea of the malware detection
approaches, pros and cons of each detection approach, and methods that are used in these approaches.
INDEX TERMS Cyber security, malware classification, malware detection approaches, malware features.
I. INTRODUCTION
In recent years, almost every member of the society has been
using the Internet for daily life. This is because it is almost
impossible to do anything without the Internet including
socialinteractions,onlinebanking,healthrelatedtransaction,
and marketing. Since the Internet has been growing rapidly,
criminalshavestartedtocommitcrimesontheInternetrather
than in real world. Criminals are generally using malicious
software to launch cyber-attacks to the victim machines. Any
software which intentionally executes malicious payloads
on victim machines (computers, smart phones, computer
networks, etc.) is considered as malware. There are differ-
ent types of malware including virus, worm, Trojan horse,
rootkit, and ransomware. Each malware type and family is
designed to affect original victim machine in different ways
such as damaging the targeted system, allowing remote code
execution, stealing confidential data, etc. These days, the
classification of malware is getting harder because some
The associate editor coordinating the review of this manuscript and
approving it for publication was Ali Kashif Bashir .
malware instances can present the characteristics of multiple
classes at the same time.
Intheearlydays,malwarewaswrittenforsimplepurposes,
thus, it was easier to detect. This kind of malware can be
definedastraditional(simple)malware.However,thesedays,
the malware which can run in kernel mode, and is more
destructive and harder to detect than traditional malware can
bedefinedasnewgenerationmalware(next-generation).This
kind of malware can easily bypass protection software that is
running in kernel mode such as firewalls, antivirus software,
etc. Generally, traditional malware consists of one process
anddoesnotusecomplicatedtechniquestohideitself.Onthe
other hand, new generation malware uses multiple different
existing or new processes at the same time, and uses some
obfuscated techniques to hide itself and become persistent
in the system. New generation malware can launch more
destructive attacks such as targeted and persistent which have
never been seen before, and more than one type of malware is
used during the attacks. The comparison of traditional versus
new generation of malware can be seen in Table 1.
These days, the number, sophistication, and cost of mal-
ware inflicted on the world economy have been increasing
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
6249
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
TABLE 1. Traditional versus new generation malware.
incrementally. According to scientific and business reports,
approximately 1 million malware files are created every day,
and cybercrime will damage the world economy by approxi-
mately $6 trillion annually by 2021 [1]. Recent studies show
that mobile malware is on the rise. According to the McAfee
mobile threat report, there is a huge increase in backdoors,
fake applications and banking Trojans for mobile devices [2].
Besides, the malware attacks related to the social media,
healthcareindustry,cloudcomputing,internetofthings(IoT),
and cryptocurrencies are also on the rise. According to cyber-
security ventures, ransomware malware will cost around
$11.5 billion globally at the end of 2019 [1].
To protect legitimate users and companies from mal-
ware, malware need to be detected. Malware detection is
the process of determining whether a given program has
malicious intent or not. In early days, signature-based detec-
tion approach was used widely to detect malware. However,
this approach has some limitations such as it cannot detect
unknown and new generation malware. In process of time,
researchers proposed new approaches including behavioral-,
heuristic-, and model checking-based detection. With these
approaches, datamining and machine learning (ML) algo-
rithms are also started to be used widely in malware detec-
tion. Recently, new approaches have been proposed such
as deep learning-, cloud-, mobile devices-, and IoT-based
detection. For known and some of unknown malware, heuris-
tic detection approach performs well. On the other hand,
for unknown and complicated malware; behavior-, model
checking-, and cloud-based approaches perform better. Deep
learning-, mobile devices-, and IoT-based approaches also
emerge to detect some portion of known and unknown
malware. It has not been proved exactly that one detec-
tion approach is more effective than the others. This is
because each method has its own advantages and disadvan-
tages, and in different situation one method can detect better
than another. Even though several new methods have been
proposed by using different malware detection approaches,
no method could detect all new generation and sophisticated
malware. This shows that building an effective method to
detect malware is a very challenging task, and there is a huge
demand for new studies and methods.
This paper presents the literature review in order to inves-
tigate the current situation of malware detection approaches.
The paper makes the following contributions:
• Explains new technological trends for malware creation
and new approaches to detect malware.
• Investigates the probability of detecting malware.
• Presents a summary of the current studies on malware
detection.
• Explains important approaches and methods for mal-
ware detection.
• Discusses current challenges and proposes new assump-
tions for malware detection approaches.
• Provides a systematic overview of malware detection
approaches and methods for further studies.
The rest of the paper is organized as follows: Section II
demonstrates problem definition. Malware detection tech-
niques and algorithms are explained in section III, and
malware detection approaches are explained in section IV.
Evaluation on malware detection approaches are presented in
section V. Finally, the conclusion and future works are given
in section VI.
II. PROBLEM DEFINITION
This section investigates the problem of malware and possi-
bilityofdetection.Itcanbesaidthatitisimpossibletodesign
an algorithm which can detect all malware. This is because
theproblemofdetectingthemalwarehasshownNP-complete
in many studies. This is important because before starting to
build an effective detection system, it is a good practice and
experience for researcher to understand the scope, limitation,
and possibility of malware detector. The possibility of detec-
tion malware is remaining problematic because theoretically
it is a hard problem, and practically malware creators using
complicated techniques such as obfuscation to make detect-
ing process very challenging.
A. DIFFICULTY OF PROBLEM IN THEORY
Since the first malware that appeared in the wild was a virus,
mostofthestudieshadbeendonetheoreticallywerebasedon
the detection of virus. According to early studies, the detec-
tion of virus is impossible [3]–[5] and NP-complete [6]–[9].
According to F. Cohen, the detection of computer virus is
an undecidable because detection process itself contains a
contradiction [3], [5], [6]. If the detection problem is seen as
a decision-making problem, D (decision-maker) will decide
whether P is a virus or not. According to Cohen, it cannot
be decided whether P is a virus because if P is a virus,
it will be marked by D as a virus and will not be able to
make changes to other programs, as it will not act as a virus.
If D decision maker did not identify P as a virus, P will
interact with other programs to spread and become infected.
6250 VOLUME 8, 2020
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
This decision process involves contradiction, and therefore
it is not possible to identify P as a virus. According to
M. Chess and R. White, there is no program that detects
all viruses without false positives (FPs) because viruses are
polymorphic and can be exist in different forms [5]. Accord-
ing to M. Adleman detecting a virus is quite intractable and
almost impossible [7]. This is because according to Gödel
numberings of the partial recursive functions, it is not pos-
sible to create detecting mechanism. To reliably identifying
a bounded-length mutating virus is NP-complete explained
in[8].Accordingtotheauthor,virusdetectorforcertainvirus
strain can be used to solve the satisfiability problem. Since
satisfiability problem is known to be NP-complete, so the
detectionofthemalwareisNP-complete.Zuoetal.claimthat
thereexistcomputerviruseswhosedetectingprocedureshave
sufficiently large time complexity, and there are undecidable
viruses which have no minimal detecting procedure [9].
B. DIFFICULTY OF PROBLEM IN PRACTICE
The new generation malware uses the common obfusca-
tion techniques such as encryption, oligomorphic, polymor-
phic, metamorphic, stealth, and packing methods to make
detection process more difficult. This kind of malware can
easily bypass protection software that is running in kernel
mode such as firewalls, antivirus software, etc. and some
malware instances can also present the characteristics of
multiple classes at the same time. This makes practically
almost impossible to detect all malware with single detection
approach. The definition of common obfuscation techniques
explain as follows:
• Encryption: In encryption, malware uses encryption to
hide malicious code block in its entire code [10]. Hence,
malware becomes invisible in the host.
• Oligomorphic: In oligomorphic method, a different key
is used when encrypting and decrypting malware pay-
load [11]. Thus, it is more difficult to detect malware
which uses oligomorphic method than encryption.
• Polymorphic: In polymorphic method, malware uses a
differentkeytoencryptanddecrypt[12]likewisethekey
used in oligomorphic method. However, the encrypted
payload portion contains several copies of the decoder
and can be encrypted in layered [13]. Thus, it is more
difficult to detect polymorphic malware when compared
to oligomorphic malware.
• Metamorphic: Metamorphic method does not use
encryption. Instead, it uses dynamic code hiding which
theopcodechangesoneachiterationwhenthemalicious
process is executed [14]. It is very difficult to detect
such malware because each new copy has a completely
different signature.
• Stealth: Stealth method also called code protection,
implements a number of counter techniques to prevent it
from being analyzed correctly [11]. For instance, it can
make changes on the system and keep it hidden from
detection systems.
• Packaging: Packaging is an obfuscation technique to
compress malware to prevent detection, or hiding the
actual code by using encryption [15], [16]. Due to this
technique, malware can easily bypass firewall and anti-
virus software. Packaged malware need to be unpacked
before being analyzed. The packers can be divided into
4differentgroupsincludecompressors,crypters,protec-
tors, and bundlers.
In this section, the limitations of malware detecting sys-
temshavebeensummarized.Currentstudiesdemonstratethat
it is almost impossible to write an algorithm to detect all
malware. This is because the computational complexity of
malware is not clear, and the detection of malware problem
is proved to be NP-complete. Besides, the use of new tech-
niques (obfuscation and packing) during malware creation
also makes detection process more challenging.
III. MALWARE DETECTION TECHNIQUES AND
ALGORITHMS
In recent years, datamining and ML algorithms have been
used extensively for malware detection. Malware detection
is the process of investigating the content of the program and
deciding whether the analyzed program malware or benign.
The malware detection process includes 3 stages: Malware
analysis, feature extraction, and classification.
A. MALWARE ANALYSIS
In order to understand the content and behaviors of malware,
it needs to be analyzed. Malware analysis is the process
of determining the functionality of malware and answers to
following questions [17], [18]. How malware works, which
machines and programs are affected, which data is being
damaged and stolen, etc. There are mainly two techniques
to analyze malware: static and dynamic [17]. Static analysis
examines the malware without running the actual code [19].
On the other hand, dynamic analysis examines the malware
behaviors while running its code. Malware analysis starts
withbasicstaticanalysisandfinisheswithadvanceddynamic
analysis. The malware is analyzed by using reverse engineer-
ing [20] and some other malware analysis tools to represent
the malware in different format. Reverse engineering process
can be seen in Figure 1.
FIGURE 1. A flow chart of reverse engineering process.
VOLUME 8, 2020 6251
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
B. MALWARE FEATURE EXTRACTION
Malware features are extracted by using data mining tech-
niques. Data mining is the process of extracting new mean-
ingfulinformationfromlargedatasetsordatabaseswhichhas
been unknown before this process. In recent years, by using
datamining new models and datasets have been created [21].
There are different models such as n-gram, and graph model
to create malware dataset and features.
1) THE n-gram MODEL
The n-gram is a feature extraction technique which has been
used widely in many areas as well as malware detection.
The n-gram can use both static and dynamic attributes to cre-
ate features. To create features from behaviors, n-gram group
the system calls or application programing interfaces (APIs)
in a consecutive order by specified n (n = 2,n = 3,n =
4,n = 6, etc.) values. Although the n-gram model has been
used widely in malware detection, it has some drawbacks
when determining features. This is because every sequential
static and dynamic attributes are not related to one another.
Thismakesclassificationandclusteringmorechallengingfor
later processes. Besides, n-gram generates enormous feature
space which increases the analysis time and decreases the
modelperformance.Forthesereasons,thereisahugedemand
to find out new models to achieve better performance than
n-gram.
2) GRAPH-BASED MODEL
The graph-based model is one of the commonly used tech-
niques to generate features as well. System calls made in
this method are converted into graph G (V, E) such that
V represents nodes which identify system calls and the E
represents edges which identify the relationship among the
system calls. Since the size of the graph increases over time,
sub-diagrams can be used to describe the graph. The sub-
diagram is defined in many studies as NP-Complete. This
meansthatitrequiresalotoftimetodefineeachsub-diagram.
After the whole diagram is expressed with fewer nodes and
edges, the programs are identified as malicious or benign.
3) MALWARE DATASET
As in other research areas, there are not many datasets pub-
lished previously which are accepted and widely used for
malware detection. In addition, most of the existing datasets
are not accessible for research, and in most cases the datasets
accessed are not in the appropriate formats for data mining
processes and ML algorithms. The datasets used in mal-
ware analysis can be listed as follows: NSL-KDD, Drebin,
Microsoft malware classification challenge, ClaMP (classifi-
cation of Malware with PE headers), AAGM, and EMBER
dataset.
• NSL-KDD dataset (2009): It is an updated version of
the KDD’99 dataset which consists of approximately
125,000 records and 41 features [22]. It shows the
network related attacks which are used for intrusion
detection system.
• Drebin dataset (2014): This dataset is created for smart
phones to examine the effectiveness of the existing anti-
virus software [23]. It consists of 5560 malware across
20 families and 123,453 benign samples.
• Microsoft malware classification challenge dataset
(2015): It has been published by Microsoft and consists
of 20,000 malware [24]. Malware has been analyzed
usingtheIDApacketdisassemblerandtheoutputshould
be processed using data mining prior to ML.
• ClaMP (Classification of Malware with PE headers)
dataset (2016): It consists of 5184 records and has
55 properties [25]. The dataset uses API arrays, contains
examples of malicious and benign software with their
features.
• AAGMdataset(2017):Itisanetwork-baseddatasetfor
android malware [26]. It consists of 400 malware and
1500 benign samples from 12 families [26].
• EMBERdataset(2018):Itconsistsof1millionrecords
and holds malware and benign features [27].
These datasets can be used for researches who want to get
some experience before proposing a new malware detection
approach.
C. MALWARE CLASSIFICATION
Machine learning (ML) is a set of algorithm that correctly
estimates the outcomes of the applications without being
explicitly programmed. The purpose of the ML is to convert
the input data into acceptable value intervals by using statisti-
calanalysis.ByusingML,manyoperationscanbeperformed
on related data such as classification, regression and cluster-
ing. ML algorithms have been used in malware detection for
many years [28]. Well-known ML algorithms are Bayesian
network (BN), naive Bayes (NB), C4.5 decision tree variant
(J48), logistic model trees (LMT), random forest tree (RF),
k-nearest neighbor (KNN), multilayer perceptron (MLP),
simple logistic regression (SLR), support vector machine
(SVM), and sequential minimal optimization (SMO). These
algorithms are used especially in behavior-based detection
and some of other detection approaches. Although each algo-
rithm has its own advantages and disadvantages, it cannot be
concluded that one algorithm is more efficient than another.
However, an algorithm can perform better than other algo-
rithms in terms of the distribution of the data, number of
features, and dependencies between properties.
IV. MALWARE DETECTION APPROACHES
In recent years, there has been a rapid increase in the num-
ber of academic studies on malware detection. In the early
days, signature-based detection method was widely used.
This method works fast and efficiently against the known
malware, but does not perform well against the zero-day
malware [21], [29]. In the process of time, researchers have
started to use techniques such as behavior-, heuristic-, and
6252 VOLUME 8, 2020
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
FIGURE 2. A flow chart of malware detection approaches and features.
model checking-based detection; and new techniques such as
deep learning-, cloud-, mobile devices-, and IoT-based detec-
tion. Overview of malware detection approaches, features,
and used techniques can be seen in Figure 2.
Ineachapproach,featureextractingmethodisdifferentone
from another. It could not have been proven one detection
method works better than another because each method has
its own advantages and disadvantages. By using behavior-,
heuristic-, and model checking-based detection approaches;
hugenumberofmalwarecanbedetectedwithafewbehaviors
and specifications. In addition, new malware can be detected
by using these approaches as well. However, they cannot
detectallmalware.Thereisgreatnecessitytofindthemethod
which effectively detects more complex and unknown mal-
ware. Before explaining each detection approach in details,
some well-known methods in each detection approach and
their related works are summarized in Table 2. Then, detailed
literature review is presented, and the pros and cons of each
study are explained.
A. SIGNATURE-BASED MALWARE DETECTION
Signature is a malware feature which encapsulates the
program structure and identifies each malware uniquely.
Signature- based detection approach is widely used within
commercial antivirus. This approach is fast and efficient to
detect known malware, but insufficient to detect unknown
malware. In addition, malware belonging to the same fam-
ily can easily escape the signature-based detection by using
obfuscation techniques. General view of signature-based
detection schema can be seen in Figure 3.
1) SIGNATURE GENERATION PROCESS
During the signature generation, first features are extracted
from executables (Figure 3). Then, signature generation
engine generates a signatures and stores them into signature
database. When sample program needs to be marked as mal-
ware or benign, signature of the related sample is extracted
as the same way before and compared with signatures on
the database. Based on the comparison, sample program is
VOLUME 8, 2020 6253
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
TABLE 2. Summary of related works on malware detection approaches.
marked as malware or benign. There are many different tech-
niques to create a signature such as string scanning, top-and-
tail scanning, entry point scanning, and integrity checking.
• String Scanning: Compares the byte sequence in
the analyzed file with the byte sequences previously
saved in the database. Byte signatures have been
6254 VOLUME 8, 2020
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
FIGURE 3. Signature-based malware detection schema.
TABLE 3. Example ClamAV byte signature.
TABLE 4. ‘‘90FF1683EE0483EB0175F6’’ Assembly byte sequence.
TABLE 5. Display of byte signatures in Yara format.
used extensively by antivirus scanners for many years.
They are often used to detect malware which belongs
to the same family with different signatures [61].
Table 3 shows the ClamAV byte signature [62].
‘‘90FF1683EE0483EB0175F6’’ is the hexadecimal rep-
resentation of the relevant code section and it is shown in
assembly language as in Table 4. The same byte signature
is shown in Yara format in Table 5 [62].
• Top-and-Tail Scanning: Instead of the whole file, only
the top and end points of the file are taken and certain
signatures are created [11]. It is a very convenient signa-
ture method to detect viruses that attach themselves to
the beginning and end of files.
• Entry Point Scanning: The entry point of a file indi-
cateswherethefirstrunstartswhenthatfilestartstorun.
Malware usually changes the entry point of a program,
so that malicious code being executed before the actual
code [11]. Therefore, certain malware can be detected
by extracting the signature from the sequences at the
program entry points.
• IntegrityChecking(HashSignatures):Integritycheck
generates a cryptographic checksum such as MD5 and
SHA-256 for each file in a system at regular intervals,
and it is used to identify possible changes that may be
caused by malware.
Different signature generation techniques have been sum-
marized. Eventhoughthese techniquesare quitefast andeffi-
cient to generate a signature, they are not resistant to malware
obfuscating techniques. For example, malware can easily
change the strings and program entry point in its instruction
set. By this, generated signature may mislead the detecting
schema.Toextractmorepowerfulandgeneralsignatures,dif-
ferenttechniquesandfeaturescanbeused.Detailedreviewof
signature-based malware detection approach and its methods
are summarized as follows:
2) RELATED WORKS FOR SIGNATURE-BASED DETECTION
F. Zolkipli and Jantan proposed a new malware detection
framework which is based on s-based detection, genetic
algorithm (GA), and signature generator [63]. Even though
the authors claim that this method can detect unknown mal-
ware, there is not enough information given in the paper
for proposed framework such as test results, number of
malware analyzed, and comparison of proposed method with
other existing studies. Tang et al. proposed a bioinformatics
technique to generate accurate exploit-based signatures for
polymorphic worms [64]. The technique involves three steps:
multiple sequence alignment to reward consecutive sub-
string extractions, noise elimination to remove noise effects,
and signature transformation to make the simplified regular
expression signature compatible with current IDSs.
The authors claim that suggested schema is noise-tolerant,
and more accurate and precise than those generated by
some other exploit-based signature generation schemas. This
is because it extracts more polymorphic worm characters
like one-byte invariants and distance restrictions between
invariant bytes. However, proposed schema is limited to
polymorphic worm and cannot be generalized to other
malware types.
Borojerdi and Abadi proposed a MalHunter detection sys-
tem which is a new method based on sequence clustering
and alignment [65]. It generates signatures automatically
based on malware behaviors for polymorphic malware. The
novel method works as follows: First, from different malware
samples, behavior sequences are generated. Then, based on
similar behavioral sequences, different groups are generated
and stored in the database. To detect malware sample, behav-
ior sequences are gathered and compared with sequences
which have been generated earlier and stored in the database.
Based on the comparison, the sample is marked as mal-
ware or benign. The test results showed that by choosing
the cluster radius 0.4 and similarity threshold 0.05, they
VOLUME 8, 2020 6255
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
achieved detection rate of 90.83% with a FPR of 0.80%.
The authors claim that proposed schema is resistant to
obfuscation techniques, and it can be used for the generic
detection of all types of polymorphic malware rather than
being limited to a specific malware type. The authors also
claim that the suggested system outperformed state-of-the-
art signature generation methods including Tang et al. [64],
Newsome et al. [66], and Perdisci et al. [67] previously
reported in the literature. The proposed method is limited to
polymorphicmalwareandithasbeentestedononlyhundreds
ofmalwarewhichisnotenoughtodeterminetheperformance
of proposed method.
Automatic string signatures generation (Hancock) is
explained in [41]. According to the paper, proposed schema
can automatically generate high-quality string signatures
with minimal FPs and maximal malware coverage. The pro-
posed method uses a set of library code identification tech-
niques, and diversity-based heuristics techniques to ensure
the contexts in which a signature is embedded in contain-
ing malware files similar to one another [41]. Although the
authors claim that Hancock can automatically generate string
signatures with a FPR below 0.1%, this FPR will be changed
based on benign samples that are analyzed. This is because
benign set is constantly growing, and getting some satisfy-
ing result on some part of benign cannot be generalized to
whole set. Thus, these problems need to be solved for further
studies. Santos et al. proposed n-grams-based file signatures
to detect malware [68]. First, for known files n-grams are
extracted for every file and used as a file signature. Then, for
any unknown instance, n-grams are generated, and by using
measuring function and k-nearest neighbor algorithm [69],
file is marked malware or benign. Paper demonstrated that
n-grams-based signatures can detect unknown malware to a
certain degree.
Efficient signature based malware detection on mobile
devices is proposed in [70]. First, signature has been cre-
ated. Second, hash table has been used to store the hash
values of signatures to increase scanning speed. Finally, sig-
nature matching algorithm is used to compare the signatures.
To eliminate the mismatches, the probability of occurrence
of signature bytes in non-malicious content has been used.
According to the authors, the results have shown that sug-
gestedschemaperformswellwhencomparedtotheClam-AV
scanner, and provides huge memory savings while main-
taining fast scanning speed. The proposed system was only
compared with Clam-AV scanner, which is not enough for
overallevaluation.Zhengetal.presentedtheDroidAnalytics,
anAndroidmalwareanalyticsystemwhichcanautomatically
collectmalware,generatesignaturesforapplications,identify
malicious code segment, and associate the malware under
study with various malware in the database [71]. In proposed
systemthree-levelsignaturegenerationschemahasbeenused
to identify each application. The authors assert that proposed
signature methodology provides significant advantages over
traditionalcryptographichashlikeMD5-basedsignature,and
resistant to packing and mutations. The proposed system has
not been compared with other studies in the literature, and
the evaluation metrics are not very high and are not explained
in detail.
3) EVALUATION OF SIGNATURE-BASED DETECTION
In the literature review, signature-based detection methods
have been summarized. Signature-based detection schema
has been used for antivirus vendors for many years and it
is quite fast and effective to detect known malware. This
approach is generally used to detect malware which belongs
to the same family. However, it fails to detect new gen-
eration malware which uses obfuscation and polymorphic
techniques. Besides, it is prone to many FPs and extracting
signature takes a lot of man-power.
Althoughprevioussignature-basedm
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are theconnected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
tualized
environment. If operating in such an environment, Amnesiaern appliances [5].
However, energy consumption in commercial buildings is more
complex than that in residential buildings [6].
While residential buildings mainly provide a sanctuary for
people, commercial buildings have widely varying purposes.
Nevertheless, commercial buildings are mainly designed for busi-
ness activities and expected to generate income for building
owners and their tenants. Therefore, energy-saving strategies are
needed to reduce operating costs on both sides. Specifically,
electricity consumption by commercial buildings is the highest
during 9:00–17:00, which is usually the highest price in time-price
based schemes. Moreover, Popescu et al. also found that energy-
efficient buildings benefit owners by increasing the property
values [7].
The building manager is responsible for managing building
performance, and one of the main building performance measures
is electricity consumption [8]. Additionally, in countries that have
recently increased requirements for green building certification,
the building manager must minimize energy consumption. Thus,
to reduce electricity consumption and CO 2 emissions, building
managers must understand energy consumption from the tenant
perspective. Therefore, building electricity consumption is both a
social problem and a technical problem [5].
Analyzing electricity consumption from the tenant perspective
requires very detailed data. To acquire such data, researchers have
proposed using sensors for detecting movement [9], thermostats
[10], cameras [11] or combinations of sensors that detect light, CO 2 ,
temperature, etc. [12]. In practice, however, implementing this
approach in commercial buildings is highly impractical. For priormance, and one of the main building performance measures
is electricity consumption [8]. Additionally, in countries that have
recently increased requirements for green building certification,
the building manager must minimize energy consumption. Thus,
to reduce electricity consumption and CO 2 emissions, building
managers must understand energy consumption from the tenant
perspective. Therefore, building electricity consumption is both a
social problem and a technical problem [5].
Analyzing electricity consumption from the tenant perspective
requires very detailed data. To acquire such data, researchers have
proposed using sensors for detecting movement [9], thermostats
[10], cameras [11] or combinations of sensors that detect light, CO 2 ,
temperature, etc. [12]. In practice, however, implementing this
approach in commercial buildings is highly impractical. For priormance, and one of the main building performance measures
is electricity consumption [8]. Additionally, in countries that have
recently increased requirements for green building certification,
the building manager must minimize energy consumption. Thus,
to reduce electricity consumption and CO 2 emissions, building
managers must understand energy consumption from the tenant
perspective. Therefore, building electricity consumption is both a
social problem and a technical problem [5].
Analyzing electricity consumption from the tenant perspective
requires very detailed data. To acquire such data, researchers have
proposed using sensors for detecting movement [9], thermostats
[10], cameras [11] or combinations of sensors that detect light, CO 2 ,
temperature, etc. [12]. In practice, however, implementing this
approach in commercial buildings is highly impractical. For privacy
reasons, some tenants may reject the idea of sensors installed in their
offices. Moreover, wiring costs are 45% and 75% of total installation
cost for new buildings and retrofitted buildings, respectively [13].
Analyzing data streams from numerous real-time sensors can also be
a heavy burden on building energy managers [14].
Smart meter use can reduce the required number of sensors and
eventually reduces data streamvolume. A smart meter is an electrical
meter that records electrical energy consumption at intervals of an
hour or less and sends the information back to the utility center for
monitoring and billing purposes [15]. Therefore, smart meters
provide more information compared to conventional meters, which
only provide data for billing purposes [15]. Moreover, a smart meter
management system is needed for an efficient smart grid system
[16]. Finally, customers benefit from improved reliability of utility
networks [17] and improved responsiveness of services, which
eventually improve and sustain the customer relationship [18].
Additionally, smart meter data can be utilized to provide power
quality (PQ) information to customers and utility companies. As the
quality is susceptible to any disturbance in power transmission
network, PQ is an important measure for customers [19]. Particularly,
for the buildings that use electricity from different companies, the
companies could develop PQ index [20] to provide fair information to
customer and use the index to monitor any disturbance in power
quality production. Consequently, for a fairer energy price, the price
can be adjusted in terms of power quality [21].
Smart meters can provide detailed data for the electricity
consumption of a customer in real-time or near real-time. Further,
in-home implementations combining smart meter and enabling
technologies such as in-home display have shown that smart
meters can reduce energy consumption [22]. Studies show that
the highest reductions occur when people are already at home at
17:00 (5 pm), which indicates that, with the right feedback, people
can reduce their electricity consumption [23]. For example, a study
by the Energy Saving Trust in 2009 showed that feedbacks that
had the largest contribution to smart meter use were those that
helped to reduce electricity use [24].
Anomalous electricity consumption data can help tenants identify
extraordinary consumption patterns [25]. In commercial buildings,
anomalous consumption may also result from activities such as over-
lighting [6], inefficient equipment or overtime work. Therefore,
anomalous feedback data can be further used to warn tenants to
minimize electricity use and to help them identify ineffective equip-
ment or over-lighting in office spaces. However, extracting meaningful
information from smart meter data is a formidable task [26].
Although several anomaly detection methods have been
researched, the primary objective has been detecting anomalous
consumption in automated building systems such as heating,
ventilation, and air conditioning (HVAC) systems [14,26–28].
However, the building must also support random use of office
equipment, lightings, heating, and air condition. Since HVAC
systems consume almost 50% of energy in a building [8], reduction
of energy use by non-HVAC systems can potentially reduce total
consumption by 50%. Office equipment consumes 15% of the total
energy consumed by an office. By 2020, this figure is expected to
increase twofold [29]. Therefore, potential savings in electricity
consumption by office spaces are also large.
Because no studies have considered anomaly detection in office
spaces, this study performed an experiment to develop a real-time
system for detecting anomalous electricity consumption in an
office space from the perspective of occupant activities. All
experimental data were retrieved from smart meters used to
monitor electricity consumption in an office space in a university
building. The main objective was to develop an anomaly detection
methodology that is applicable in large data stream of smart meter
data and real time environment. Therefore, the research results
have potential applications in a web-based early warning system.
Notably, the results application is not only limited to building
energy consumption domain, but also applicable to any anomaly
detection system that use time based sensor data as input.
Furthermore, the potential application includes gas flow detection,
water flow detection, and comfort level detection. The main
contributions of this research are the following:
? A formalized methodology for detecting anomalous patterns in
large real-time datasets for building office space energy
consumption.
? The method is performed in two stages. The prediction stage
helps building managers plan their electricity demand while
the anomaly detection stage helps building managers identify
tenant consumption patterns. In the case of a building that
generates its own electricity and has abnormally low energy
consumption, the building manager can connect to a smart grid
and sell the excess electricity to gain profit.
? Anomaly detection benefits tenants by helping them under-
stand how their office activities consume energy. They can then
modify their anomalous activities, analyze energy consump-
tion costs and benefits, and eventually reduce their wasteful
activities.
The remainder of this paper is organized as follows. Section 2
briefly introduces the study context by reviewing related
J.-S. Chou, A.S. Telaga / Renewable and Sustainable Energy Reviews 33 (2014) 400–411 401
literature, including studies of anomaly detection and some well-
known demand prediction techniques. Section 3 then describes
the research methodology, and the evaluation methods of pro-
posed models. Section 4 further explains the experiment per-
formed in this research. Section 5 then presents the experimental
results, and Section 6 analyzes the results and compares model
performance. Finally, Section 7 summarizes the findings and
conclusions.
2. Review of literature on research problem
Analyzing building electricity consumption data is important
because failure to do so can jeopardize building management by
causing excessive energy use and potential increases in carbon
taxes [30]. Although building energy consumption has been
studied intensively, further studies are needed to optimize artifi-
cial intelligence (AI) for prediction models and to integrate the
models in a Building Energy Management System (BEMS) [31].
In the future, most smart meter systems will be AI-based to enable
independent management of power consumption [32].
Electricity consumption in an office space is usually estimated
for a typical working day and working week. However, electricity
demand signatures differ according to occupant behavior and
during different periods, e.g., lunch time, regular workdays, and
seasonal holidays [26]. Therefore, an anomaly detection system for
an office space must detect anomalous consumption based on
these signatures and pattern changes during seasonal holidays.
Here, an anomalous condition is defined as an abnormal power
consumption usage. An anomalous state is defined as a deviation
from the normal electricity consumption of the tenant. Therefore,
the proposed anomaly detection model has two stages: power
consumption prediction method and anomaly detection. Because
electricity consumption data is a time series domain, the objective
was to develop a suitable time series anomaly detection method.
By defining an anomalous state as two standard deviations (SDs)
above or below the predicted power consumption, an anomaly can
be easily computed and flagged. The definition is based on
empirical rule of normal distribution that 95% of values lie within
roughly two SDs of the mean. Therefore, another 5% value outside
two SDs can be considered as an anomaly as depicted in Fig. 1.
Similar definition was used in Brown et al. that they defined
anomalous activity as consumption exceeding an SD of three in the
prediction results [33].
Studies of anomaly detection methods in the energy consump-
tion domain include Yi et al., who compared regression, entropy,
and clustering methods. The regression methods obtained the best
detection results [34]. Brown et al. further used K-nearest
neighborhood (K-NN) in fast kernel regression to predict electri-
city consumption [33]. However, both methods require huge
datasets, and the resulting models are static. Since they are prone
to pattern change, they are not the preferred models for on-line
prediction [35].
When using large data sets to solve problems and identify
pattern changes, researchers have combined sliding window
datasets with other techniques such as adaptive artificial neural
network (ANN) [36]. Even when the dataset is small, adaptive ANN
outperforms static ANN when using a real measurement dataset
and performs comparably to static ANN when using a static
dataset. Wrinch et al. applied Fourier transform with a sliding
window and found that a weekly window provided faster fault
detection compared to a monthly window [26]. Li et al. performed
a time-series auto-regressive integrated moving average (ARIMA)
analysis of a dataset for real-world daily shifts in water consump-
tion to detect meter stilting [27].
However, anomaly detection by Fourier transformation has a
high false positive rate due to the assumption of constant
periodicity of data [35]. The ARIMA method does not obtain a
good model if the duration of anomaly data is long [37]. Optimiz-
ing the hidden layer and time lag is also problematic when
applying ANN in time series domain [38]. Therefore, a suitable
method is needed to address these limitations.
Recent studies suggest that a combination of several individual
models can compensate for deficiencies of a model. Theoretically,
hybridization of unrelated models also reduces generalization
variance or error [39]. Since forecasting problems in real-world
time series data usually contain both linear and nonlinear compo-
nents [38], the hybrid model usually combines linear and non-
linear models. In the energy demand prediction domain, ARIMA
and ANN are the most common forecasting methods [40,41].
Individual ARIMA models have been widely used for linear time
series forecasting [39,41], and ANN has been successfully used to
solve nonlinear problems [42].
Zhang confirmed that a hybrid model combining ARIMA an
connected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
Malware
Technical
Details
General
Information
Source Code
Linux.Hydra
(1)
[7], [8] [8]–[11] [12]
Psyb0t (2)
[7], [13],
[14] [8]
[8]–[11], [15] not available
Chuck Norris
(3)
[7], [8], [15]
[8], [9], [11],
[15]
not available
Tsunami/Kaiten
(4)
[7], [8] [8], [9] [16]
Aidra (5) [8], [9] [9] [12]
Carna (6) [17] [9], [10] non available
Linux.Darlloz
(7)
[9], [18], [19]
[9], [10],
[18], [20]
not available
Linux.wifatch
(8)
[21] [11], [21] [22]
Bashlite (9) [8], [23] [9]–[11], [18]
[12]
Remaiten (10) [8], [18], [24] [9]–[11], [18] not available
Hajime (11) [18], [25]
[9], [11],
[18], [25]
not available
Mirai (12) [8], [26]–[28]
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features Listconnected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
Malware
Technical
Details
General
Information
Source Code
Linux.Hydra
(1)
[7], [8] [8]–[11] [12]
Psyb0t (2)
[7], [13],
[14] [8]
[8]–[11], [15] not available
Chuck Norris
(3)
[7], [8], [15]
[8], [9], [11],
[15]
not available
Tsunami/Kaiten
(4)
[7], [8] [8], [9] [16]
Aidra (5) [8], [9] [9] [12]
Carna (6) [17] [9], [10] non available
Linux.Darlloz
(7)
[9], [18], [19]
[9], [10],
[18], [20]
not available
Linux.wifatch
(8)
[21] [11], [21] [22]
Bashlite (9) [8], [23] [9]–[11], [18]
[12]
Remaiten (10) [8], [18], [24] [9]–[11], [18] not available
Hajime (11) [18], [25]
[9], [11],
[18], [25]
not available
Mirai (12) [8], [26]–[28]
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are theconnected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
Malware
Technical
Details
General
Information
Source Code
Linux.Hydra
(1)
[7], [8] [8]–[11] [12]
Psyb0t (2)
[7], [13],
[14] [8]
[8]–[11], [15] not available
Chuck Norris
(3)
[7], [8], [15]
[8], [9], [11],
[15]
not available
Tsunami/Kaiten
(4)
[7], [8] [8], [9] [16]
Aidra (5) [8], [9] [9] [12]
Carna (6) [17] [9], [10] non available
Linux.Darlloz
(7)
[9], [18], [19]
[9], [10],
[18], [20]
not available
Linux.wifatch
(8)
[21] [11], [21] [22]
Bashlite (9) [8], [23] [9]–[11], [18]
[12]
Remaiten (10) [8], [18], [24] [9]–[11], [18] not available
Hajime (11) [18], [25]
[9], [11],
[18], [25]
not available
Mirai (12) [8], [26]–[28]
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are theconnected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
Malware
Technical
Details
General
Information
Source Code
Linux.Hydra
(1)
[7], [8] [8]–[11] [12]
Psyb0t (2)
[7], [13],
[14] [8]
[8]–[11], [15] not available
Chuck Norris
(3)
[7], [8], [15]
[8], [9], [11],
[15]
not available
Tsunami/Kaiten
(4)
[7], [8] [8], [9] [16]
Aidra (5) [8], [9] [9] [12]
Carna (6) [17] [9], [10] non available
Linux.Darlloz
(7)
[9], [18], [19]
[9], [10],
[18], [20]
not available
Linux.wifatch
(8)
[21] [11], [21] [22]
Bashlite (9) [8], [23] [9]–[11], [18]
[12]
Remaiten (10) [8], [18], [24] [9]–[11], [18] not available
Hajime (11) [18], [25]
[9], [11],
[18], [25]
not available
Mirai (12) [8], [26]–[28]
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are theconnected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
Malware
Technical
Details
General
Information
Source Code
Linux.Hydra
(1)
[7], [8] [8]–[11] [12]
Psyb0t (2)
[7], [13],
[14] [8]
[8]–[11], [15] not available
Chuck Norris
(3)
[7], [8], [15]
[8], [9], [11],
[15]
not available
Tsunami/Kaiten
(4)
[7], [8] [8], [9] [16]
Aidra (5) [8], [9] [9] [12]
Carna (6) [17] [9], [10] non available
Linux.Darlloz
(7)
[9], [18], [19]
[9], [10],
[18], [20]
not available
Linux.wifatch
(8)
[21] [11], [21] [22]
Bashlite (9) [8], [23] [9]–[11], [18]
[12]
Remaiten (10) [8], [18], [24] [9]–[11], [18] not available
Hajime (11) [18], [25]
[9], [11],
[18], [25]
not available
Mirai (12) [8], [26]–[28]
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are theconnected devices have shown a tremendous and continuous
growth. Every year, new types of connected devices reach the
market. Taken together, they form the Internet of Things (IoT),
defined by Bertino et al. [1] as the aggregation of sensors,
actuators and services deployed by different organizations and
individuals to support a variety of applications. It is predicted
that by 2020, the number of IoT devices could reach 50 billions
[2].
They are omnipresent in multiple fields including home
automation [3], medicine [4], agriculture [5] or in smarts cities
[6]. As with any innovation, the growth of IoT devices also
raises several challenges. In particular, due to poor security
design, several attacks against IoT devices have taken place in
recent years. This is due in part to the fact that the development
of IoT firmware does not always draw upon the security
expertise accrued over the years by code developers working
on other platforms. This in turns makes IoT devices tempting
targets for malware developers.
In this survey, we analyze some of the most damaging
IoT malware and paint a features-based evolution of these
attacks. By malware, we describe malicious programs that infect
numerous devices rather targeting a single organization. We
focus specifically on 16 botnets, published between 2008 and
2018, that caused considerable damage to the IoT ecosystem.
Most of these botnets were used to launch DDoS attacks, but
we do not limit ourselves to this class of attack and instead
cast a wide net over all IoT malware. Other objectives of IoT
malware include industrial spying and crypto currency mining,
amongst other things.
Our analysis focuses on the features and capabilities of
each malware and highlights the relationships of feature
borrowing that can be observed between malware. To make
this relationship more salient, we propose two new visuals
representations of the evolution of IoT malware over time.
These representations make explicit the ways in which malware
developers borrow from each other. Furthermore, drawing upon
an analysis of the spread of features that we observe, we make
recommendations that will help better secure the IoT ecosystem
against malware.
By feature, we mean a distinctive functionality or capacity
implemented by malware to perform a specific task. Notably,
this includes the malicious behavior implemented by a malware,
the means used to achieve its goal, or to obfuscate its presence
as well as mechanisms used to improve its efficiency. For
example, if a malware is able to perform DDoS attack using
UDP flood, we state that it has the UDP flood feature (feature
number 1.4), regardless how it implements this attack.
1
The remainder of this paper is organized as follows: in
Section II we list and categorize the papers used in this survey.
In Section III, we described the features used to classify IoT
malware. Section V provides an analysis of the evolution of
IoT malware and of the pattern of shared features we observe.
Consequent recommendations on securing the IoT ecosystem
are given in Section VI. Concluding remarks are given in
Section VII.
II. R ELATED W ORKS
We begin by introducing and classifying some of the papers
that we relied upon in this survey. We selected 16 IoT malware,
focusing on those malware with the most impact and for which
the most data available. Our sample set dates back to 2008
and while we focus exclusively on IoT malware, we do not
limit ourselves to malware that performs DDoS attacks.
1 All our data, high resolution version of Figures 1, 2, 3 and our algorithms
are available at https://github.com/bvignau/Softawre-Phylogenic-classification.
458
2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)
978-1-7281-3925-8/19/$31.00 ©2019 IEEE
DOI 10.1109/QRS-C.2019.00088
Malware
Technical
Details
General
Information
Source Code
Linux.Hydra
(1)
[7], [8] [8]–[11] [12]
Psyb0t (2)
[7], [13],
[14] [8]
[8]–[11], [15] not available
Chuck Norris
(3)
[7], [8], [15]
[8], [9], [11],
[15]
not available
Tsunami/Kaiten
(4)
[7], [8] [8], [9] [16]
Aidra (5) [8], [9] [9] [12]
Carna (6) [17] [9], [10] non available
Linux.Darlloz
(7)
[9], [18], [19]
[9], [10],
[18], [20]
not available
Linux.wifatch
(8)
[21] [11], [21] [22]
Bashlite (9) [8], [23] [9]–[11], [18]
[12]
Remaiten (10) [8], [18], [24] [9]–[11], [18] not available
Hajime (11) [18], [25]
[9], [11],
[18], [25]
not available
Mirai (12) [8], [26]–[28]
[8]–[11],
[18], [23],
[26]–[28]
[12]
Amnesia (13) [29]
[9], [18],
[29], [30]
not available
BrickerBot
(14)
[18], [31]
[11], [26],
[32]
not available
IoTReaper
(15)
[33]–[35] [36], [37] not available
VPNFilter
(16)
[38]–[40] [41], [42] not available
TABLE I
C LASSIFICATION OF THE REFERENCES USED IN THIS PAPER .
For each malware, we sought papers (including academic
research and popular press articles) that contained general
information on the malware, such as the number of victims,
targeted devices, discovery date, impacts of the attack on society
etc. We also searched for papers with more technical details
such as the type of the attack (DDoS, crypto currency mining
etc.), the infection process, source code analysis or behavior
analysis. In some cases the source code was available allowing
us to analyze the structure of the botnet directly. The papers
used in this study are summarized and categorized in Table I.
Every malware studied in this paper is the topic of at
least two academic papers or technical reports. Moreover, we
excluded any malware for which there was insufficient publicly
available information to ascertain whether or not the malware
implements each the features considered in this study. Our
data set may not be complete, but it does contain the most
widespread malware, and those that produced the largest and
most damaging botnets. In this respect, we believe that our data
set contains those malware that are most likely to influence
future malware developers.
III. M ALWARE F EATURES
Our classification of IoT malware is derived from the features
present in each malware. As a consequence, we build upon a
more specialized taxonomy DDoS malware proposed by De
Donno et al. [8]. Their taxonomy is based on the analysis
of multiples features that describe DDoS attacks. It is not
limited to IoT malware and thus includes malware that runs on
other platforms, but only categorizes malware that performs
DDoS. We extend their taxonomy with the inclusion several
new features, such as crypto mining, infection process etc. thus
giving us a greater insights on the evolution of malware.
A. Features List
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are the most commonly used.
Out of a concern for legibility, we split the features in two
groups and produced two Feature propagation multigraphs.
Figure 2 shows the spread of features related to the type of
attack and Figure 3 shows the spread of features related to
the target architecture, efficiency and exploit method. Features
related to botnet architectures are omitted here.
Fig. 2. Feature propagation multigraph: attack type features. most commonly used.
Out of a concern for legibility, we split the features in two
groups and produced two Feature propagation multigraphs.
Figure 2 shows the spread of features related to the type of
attack and Figure 3 shows the spread of features related to
the target architecture, efficiency and exploit method. Features
related to botnet architectures are omitted here.
Fig. 2. Feature propagation multigraph: attack type features.
The features are described, numbered and grouped into
families below. The Table II maps each feature to a list of
malware that implement it.
1) Denial of Service Capabilities: Several botnets aim
to perform DDoS attacks. In this respect, Donno et al. [8]
differentiate between different strategies employed to perform
a DDoS attack, each of which we consider a different feature.
This includes different types of flood attacks (features 1.1-1.6),
the TCP XMAS (1.7) , DNS Waterboarding (1.8) and the DNS
amplification (1.9).
In our study we add Physical DoS (1.10) feature, which
consists in physically destroying object. This can be achieved
by wiping the firmware of the device, or by overusing it, thus
overheating of the object. The Firewall DoS (1.11) consists in
disconnecting the victim by adding rules to his firewall. For
example, adding a rule that drop all input and output packets
will make it impossible for the victim to connect to the network.
2) Data Stealing: Aside from DDoS attacks, a common
purpose of malware is to steal data from the target device.
For example, a DNS Spoof (2.1) consists in changing the
authoritative name server associated with the victim, thus
redirecting some of his web traffic to a malicious server. If
a user is redirected to a fake website, it becomes possible
to steal his credential or to infect him with other malware.
This type of attack is performed by the Chuck Norris Botnet
[15]. It responds to a request for facebook.com, providing
a fake website and asks the users to login in order to steal
his credentials. Data exfiltration (2.2) consist in stealing data
collected by IoT-connected devices and transmitting them to
the attacker in a convert manner.
3) Endpoint Exploit: This feature is used by malware to
infect other devices directly connected to any IoT device it has
already infected (3.1). This can be done by exploiting known
vulnerability in other devices, or by injecting malicious code in
network communication (if the infected device is a router). For
instance, through an analysis of network communications, the
VPNFilter bot is able to detect if a Windows executable file is
in the process of being exchanged. Researchers believe that this
malware could inject a binary payload in an executable file and
leverage on-the-fly patching of Windows executable to exploit
endpoints device [40]. This malware also performed a Man-in-
the-Middle attack (3.2) [43] in order to spoof communications
between IoT devices.
4) Industrial Spying: Malware that targets industrial plants
use several different strategies to spy on and control their
targets. In our sample, these features are mainly used by the
VPNFilter botnet [38]–[40] and include a SCADA monitoring
feature (4.1). SCADA systems are used in industrial plants
to acquire data from mechanical parts such as turbines and
to control them. SCADA systems are often attacked to slow
459
down industrial activities [44]. Moreover, VPNFilter was able
to map the local network of the infected device (4.2). Another
innovative feature of this malware is its ability to create a
reverse TCP-VPN to allow a remote attacker to access the
internal networks (4.3). Finally, malware that targets industrial
plants also need to obfuscate malicious traffic to avoid detection
while exfiltrating data or when the attackers use the VPN to
spy on and control local network devices (4.4).
5) Exploit: In the course of our study, we noticed that
malware use several different strategies to infect new devices.
The most common is the simple dictionary attack (5.1), in
which the botnet attempts to brute force the credentials of the
victim. Multiple botnets use this technique, only varying the
credentials dictionary. The second method used is the balanced
dictionary (5.2), introduced by the Mirai botnet [28]. Here,
the botnet selects a random subset of credentials from the
dictionary and only attempts those credentials. Each credential
has a different probability of being picked; chosen by the
attacker based on the most frequently used default password
for the device in question. This latter technique is far more
effective than the dictionary attack. Another strategy is to
exploit vulnerable devices is to make use of an unpatched
CVE. At first, each botnet relied upon a single CVE (5.3), but
the past two years have seen the emergence of botnets that
rely upon multiple CVE thus infecting more devices (5.4).
6) Target Architecture: IoT devices can run on any one of
several possible architectures. Early botnets mostly targeted
MIPS and MIPSEL devices (6.1). Then, starting in 2012, all
other architectures commonly used, such as ARM (6.2) or
x86/64 (6.3) became targeted, due to the adoption of cross
compilation capabilities. Recently, some botnets began to use
scripting languages such as BASH to reach multiple IoT devices
without the need to create multiples binary (6.4). On the other
hand, some malware is designed to attack and exploit IoT
devices from one specific constructor, taking advantage of an
unpatched vulnerability (6.5).
7) Scanning methods: Botnets employ several different
methods to scan the web in order to detect new targets and infect
them. The earliest one, used by Hydra, consisted in scanning
a pre-programmed list of IP addresses (7.1). Attackers later
automated this process by incorporating code that generates a
hit list of potential targets from a given subnet in the bot’s code
(7.2). In 2012, botnets began to use random IP scan, which are
stealthier and easier to implement (7.3). Most botnets scan the
Telnet protocol with ordinary probes. Mirai introduced a new
and far more rapid scanning method: it performs a stateless
scan and does not wait for a timeout before moving on to a
new IP [28] (7.4).
8) Botnet architecture: Following De Donno et al. [8], we
categorize botnets’ architectures in three categories. The first
one is the centralized form, in which a Command & Control
(C2) server uses IRC to communicate with the bots (8.1). The
second one is the P2P architecture, where there is no centralized
Command & Control (C2) server (8.2). The P2P protocols
used by this botnet are often derived from the BitTorrent or
uTorrent protocol. The final category includes botnets where a
centralized architecture uses a custom communication protocol
(8.3).
9) Anti-detection Features: To better avoid detection several
malware kill legitimates processes (9.1) and adopt the name of
those processes as their own. For example, the Hajime botnet
masquerades itself as the Telnet process [25]. Moreover several
botnets also delete their own binary files (9.2).
10) Efficiency Enhancing Features: Several malware include
other novel and interesting features that improve their efficiency.
The earliest one was port closing (10.1). Botnets close ports
in the interval 22 to 80 to avoid new infections and thus
monopolize the device’s entire computing power. Later, some
botnets began to delete other older botnets already present on
the device (10.2).
Because all malware must reside in the RAM, some botnets
such as Mirai, developed anti-reboot features. Such features
kill the watchdog process in order to avoid an auto-reboot
of the infected device (10.3). Later, the VPNFilter malware
successfully alters the firmware of infected device, allowing
the bot to persist even after a reboot (10.4).
11) DGA Algorithm: When a centralized botnet becomes
too prevalent, law enforcement will usually try to shut down
the C2 server. In most botnets, the IP address of the C2
server is hardcoded in the binary. Consequently, the server
can be shutdown as soon as security researchers obtain a
copy the binary code. To make the task of law enforcement
more complex, some malware include a Domain Generation
Algorithm [45] (11). Each day, they generate up to several
hundred pseudo-random domain names, only one of which is
actually valid. The attacker chooses any single one of them
as a rendezvous point to control his botnet. The bot will
have to attempt communication using each domain name to
communicate with the C2.
12) Code Modularity: Some malware integrate update and
code modularity features (12). For example, VPNFilter attempts
to download new modules each day, including scripts that it
will then execute. Consequently, the malware can perform
virtually any kind of attack.
13) Victim Scan: Starting in 2012, malware began to include
cross compiled binaries in order to infect multiple IoT binaries
at the same time. The earliest malware to include this feature
simply downloaded every variant of the binary on the device
and attempted to execute each of them. Later variants, such as
Remaiten or Mirai, scan the host to determine its architecture
and only send the correct binary (13). Malware also differ in
how they detect potential victims, with some variants using
TCP scan and other using vulnerability scans.
14) Virtualization Evasion: One important feature used
by the Amnesia botnet is the ability to detect virtualized
environment. If operating in such an environment, Amnesia
will delete itself as well as the entire file system of the target
(14). This feature was first used by more advanced malware,
such as those that target Windows PC and Smart phones and
makes it harder for security professional to study the malware’s
code.
460
15) Crypto Mining: Crypto mining capabilities (15) allow
malware to hijack the computing power of infected devices in
order mine crypto currencies. This is an emerging threat, which
originates in malware targeting PC and was first observed in
IoT malware in 2014 with the Linux.Darlloz malware.
IV. M ETHODOLOGY
Having identified the features that distinguish malware,
we now endeavor to draw a phylogenic classification of
malware, highlighting how each malware may have influenced
its successors. To this end, we propose two new graphic
representations of the relationships between malware, each
of which highlights a different aspect of the patterns of feature
borrowing between malware.
A. Phylogenic Graph
The first representation that we introduce is the Phylogenic
graph, which captures the number of features common between
different malware. In this graph, each malware is present as a
vertex, whose radius is proportional to the number of features
from Section III exhibited by this malware. An arc links two
vertices, from the oldest to the most recent, (1) if they share
at least one feature and (2) if the release date of the former
precedes that of the latter by at least six months. The latter
condition is added because, given the expected time needed
to develop new malware, it is prudent to assume that malware
released in an interval of less than six months have been
developed independently and any share features are likely
coincidental. Each arc is weighted with the number of common
features shared by the vertices it connects.
Finally, if multiple paths link two vertices, we only preserve
the arcs with the highest weight. This prunes the graph of
connections that can be considered redundant, as they refer to
the same features being borrowed from the same malware. For
example, Chuck Norris and Psyb0t both borrow four features
from Hydra. Chuck Norris additionally borrows six features
from Psyb0t: the four it borrowed directly from Hydra, plus
two others it borrowed from Psyb0t. As a consequence, a direct
connection between Chuck Norris and Hydra can be deemed
redundant and deleted from the graph.
B. Feature Propagation Multigraph
The phylogenic graph provides a striking visual representa-
tion of the relationship between malware. It does however,
obfuscate some important details, such as exactly which
features are shared by any two bots. Furthermore, some features
are shared by multiple bots, which leads to the presence of
several uninformative arcs. We thus propose an alternative
representation, the Feature propagation multigraph (FPM),
which illustrates how individual features spread in the malware
pool.
The feature propagation multigraph identifies each feature
with a distinct color. A vertex of that color identifies the first
malware to exhibit this feature and an edge of the same color
links it to every other malware that share this specific feature.
The feature propagation multigraph provides a more detailed
Feature malware feature malware
Syn Flood
(1.1)
1, 2, 3, 4, 5,
9, 10, 12, 13,
15
UDP Flood
(1.2)
2, 3, 4, 9, 10,
12, 13, 15
ICMP Flood
(1.3)
2
ACK Flood
(1.4)
3, 4, 5, 9, 10,
12, 13, 15
Push flood
(1.5)
4, 10, 12, 13,
15
HTTP Flood
(1.6)
4, 9, 10, 12,
13, 15
TCP XMAS
(1.7)
4, 10
DNS Water-
bording
(1.8)
12, 13, 15
DNS Ampli-
fication
(1.9)
12, 13, 15
Physical
DoS or
Permanent
DoS (1.10)
14, 16
Firewall DoS
(1.11)
16
DNS Spoof
(2.1)
3, 4
Data
exfiltration
(2.2)
16
End point
Exploit (3.1)
16
Man In The
Middle
attack (3.2)
16
SCADA
Monitoring
(4.1)
16
Local
network
mapping
(4.2)
16
Reverse TCP
VPN (4.3)
16
Malicious
traffic
obfuscation
(4.4)
16
dictionary
password
(5.1)
1, 2, 3, 4, 5,
7, 8, 9, 10,
11
Balanced
dictionary
password
(5.2)
12, 14
CVE Exploit
(5.3)
7, 9, 13
Multiple
CVE (5.4)
15, 16 MIPS (6.1)
1, 2, 3, 4, 5,
6, 7, 8, 9, 10,
11, 12, 16
ARM (6.2)
5, 6, 7, 8, 9,
10, 11, 12,
16
x86/64 (6.3)
5, 6, 7, 8,
11, 12, 16
Script (6.4) 14, 16
targeted
manufacturer
(6.5)
13, 15
Harcoded hit
list (7.1)
1
Network
class
automated
hit list (7.2)
2, 3, 4
Random
(7.3)
5, 6, 7, 8, 9,
10, 11, 12,
13, 14, 15,
16
Stateless
(7.4)
12, 14, 16
Centralized
(IRC CC)
(8.1)
1, 2, 3, 4, 5,
7, 10, 13
P2P (Decen-
tralized)
(8.2)
8, 11
dedicated
protocol
(Centralized
CC) (8.3)
6, 9, 12, 14,
15, 16
process
masquerade
(9.1)
10, 11, 12,
15
binary
removal
(9.2)
11, 12, 15
ports closing
(10.1)
4, 5, 7, 8, 9,
11, 12, 13,
15
other botnet
removal
(10.2)
5, 7, 8, 11,
12, 13, 15
Anti reboot
(10.3)
11, 12, 15,
16
Persistence
(10.4)
16
DGA
Algorithm
(11)
12, 16
code’s
modularity
or update
system (12)
11, 15, 16
victim archi-
tecture’s
scan (13)
10, 11, 12,
15, 16
virutalisation
evasion (14)
13
CryptoMining
(15)
7
TABLE II
M ALWARE ’ S FEATURES .
461
Fig. 1. Phylogenic graph.
view of the way in which malware developers introduce new
features and how they are used by other developers. It also
highlights which features are the most commonly used.
Out of a concern for legibility, we split the features in two
groups and produced two Feature propagation multigraphs.
Figure 2 shows the spread of features related to the type of
attack and Figure 3 shows the spread of features related to
the target architecture, efficiency and exploit method. Features
related to botnet architectures are omitted here.
Fig. 2. Feature propagation multigraph: attack type features.
ANN is better than either of the models used independently [38].
Hybrid models have been successfully applied in economic time
series forecasting [43], fuel wood price [44], wind speed forecast-
ing [45], and electricity price [46]. Although there is still no
consensus of best approach in combining ANN and ARIMA [42],
hybridization of ARIMA and ANN or other soft computing has been
proved to improve energy demand forecasting [40]. Until now,
however, these methods have only been applied to small data
streams. Their effectiveness in large data streams for electricity
consumption is still unknown and deserved further investigation.
In this sense, this study proposes a hybrid ANN and ARIMA model
with a sliding window for analyzing large data streams in the
power consumption domain.
3. Methodology
The experimental methodology was based on a case study.
First, a K-means algorithm, a data mining cluster analysis [47], was
used to categorize daily consumption patterns in a week. The
analysis of K-means algorithm results suggested that electricity
consumption patterns differ each day except on weekends.
A correlation analysis was then performed to determine whether
training data are better suited for a weekly or daily analysis. The
results were consistent with our observation that training data
were best presented by weekly window since the office occupants
were students who attended class on a weekly basis.
After arrangement of the consumption data, the data were
entered into an ANN–ARIMA hybrid model using NNAR (Neural
Network Auto Regressive), a function in forecast library of R
-3σ -2σ -σ σ 2σ 3σ
Normal Distribution
95% of values
Fig. 1. 2-Sigma rule of normal distribution.
J.-S. Chou, A.S. Telaga / Renewable and Sustainable Energy Reviews 33 (2014) 400–411 402
statistical software. The R statistical software is a comprehensive
software applicable to handle data manipulation, calculation and
graphical visualization [48]. Sliding windows for 4-week and
8-week datasets were used for training sets in the NNAR model
to form dynamic models. The resulted models then were stored in
database as a predicted consumption for next week electricity
consumption. Fig. 2 shows the flow chart of anomaly detection
process.
The anomalous states computed by calculating differences
between actual consumption and predicted consumption were
then flagged when time duration exceeded anomalous time
allowed. The prediction results were then evaluated using mean
absolute percentage error (MAPE), mean absolute error (MAE), and
root mean square error (RMSE) for accuracy evaluation purpose.
Therefore, three evaluation methods were utilized to represent
deviation between actual electricity consumption and predicted
consumption.
3.1. K-means algorithm
The K-means algorithm is one of the simplest unsupervised
learning algorithms for solving clustering problems [47]. This
algorithm is also one of the most popular and widely used
partition clustering methods. The procedure is simple; firstly the
algorithm classifies a set through a definite number of clusters.
After finding the cluster centers, the algorithm positions the
centers as remotely as possible. Finally, the algorithm affiliates
all data points from the dataset with the closest centers. The first
iteration is complete when no data points remain. The iterations
continue until all centers are determined.
The K-means algorithm searchers for the cluster centers
ðc 1 ;c 2 ;…;c k Þ such that the sum of the squared distances (called
distortion) of each data point (x i ) to its nearest cluster center (c k ) is
minimized (Eq. (1)), where d is the distance function of the
Euclidean distance [47]:
D¼ ∑
n
i ¼ 1
½ min dðx i c k Þ 2 ? k¼ 1;2;…;K ð1Þ
? Step 1: Assign cluster number K and initialize the centroids of
each cluster, ðc ð0Þ
1
;c ð0Þ
2
;…;c ð0Þ
k
Þ; each cluster center is an m-
dimensional vector 1, 2, …, c 0
i
¼ fc ð0Þ
i1
;c ð0Þ
i2
;…;c ð0Þ
im g.
? Step 2: Start the iterative procedure. Set iteration count t to 1.
? Step 3: Calculate the distance measure d ðt?1Þ
ki
between the kth
cluster center and the ith data set (data point in m space). Here,
the distance is defined as the Euclidean distance given by the
following equation:
d ðt?1Þ
ki
¼ jjx i ?c t?1
k
jj ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
∑
m
j ¼ 1
ðx ij ?c t?1
kj
Þ 2
s
ð2Þ
? Step 4: Assign each data object x i to its nearest cluster center c k ,
Start
Better presented
in daily pattern
Complete observed
data
K-Means
algorithm
Better presented
in weekly pattern
Data collection
End
|Result| > 2 SD
Calculate difference of
real time consumption
and consumption
forecasting
Result time >
Specified time
Anomalous
consumption
Normal consumption
A
A
Missing value ?
Interpolation
Following week
electricity
consumption
forecasting
(R statistical software)
Yes
No
Yes
No
No
No
Yesomputer systems and the Internet from the malware, the malware needs to be detected before it affects a
large number of systems. Recently, there have been made several studies on malware detection approaches.
However, the detection of malware still remains problematic. Signature-based and heuristic-based detection
approachesarefastandefficienttodetectknownmalware,butespeciallysignature-baseddetectionapproach
has failed to detect unknown malware. On the other hand, behavior-based, model checking-based, and
cloud-based approaches perform well for unknown and complicated malware; and deep learning-based,
mobile devices-based, and IoT-based approaches also emerge to detect some portion of known and unknown
malware. However, no approach can detect all malware in the wild. This shows that to build an effective
method to detect malware is a very challenging task, and there is a huge gap for new studies and methods.
This paper presents a detailed review on malware detection approaches and recent detection methods which
use these approaches. Paper goal is to help researchers to have a general idea of the malware detection
approaches, pros and cons of each detection approach, and methods that are used in these approaches.
INDEX TERMS Cyber security, malware classification, malware detection approaches, malware features.
I. INTRODUCTION
In recent years, almost every member of the society has been
using the Internet for daily life. This is because it is almost
impossible to do anything without the Internet including
socialinteractions,onlinebanking,healthrelatedtransaction,
and marketing. Since the Internet has been growing rapidly,
criminalshavestartedtocommitcrimesontheInternetrather
than in real world. Criminals are generally using malicious
software to launch cyber-attacks to the victim machines. Any
software which intentionally executes malicious payloads
on victim machines (computers, smart phones, computer
networks, etc.) is considered as malware. There are differ-
ent types of malware including virus, worm, Trojan horse,
rootkit, and ransomware. Each malware type and family is
designed to affect original victim machine in different ways
such as damaging the targeted system, allowing remote code
execution, stealing confidential data, etc. These days, the
classification of malware is getting harder because some
The associate editor coordinating the review of this manuscript and
approving it for publication was Ali Kashif Bashir .
malware instances can present the characteristics of multiple
classes at the same time.
Intheearlydays,malwarewaswrittenforsimplepurposes,
thus, it was easier to detect. This kind of malware can be
definedastraditional(simple)malware.However,thesedays,
the malware which can run in kernel mode, and is more
destructive and harder to detect than traditional malware can
bedefinedasnewgenerationmalware(next-generation).This
kind of malware can easily bypass protection software that is
running in kernel mode such as firewalls, antivirus software,
etc. Generally, traditional malware consists of one process
anddoesnotusecomplicatedtechniquestohideitself.Onthe
other hand, new generation malware uses multiple different
existing or new processes at the same time, and uses some
obfuscated techniques to hide itself and become persistent
in the system. New generation malware can launch more
destructive attacks such as targeted and persistent which have
never been seen before, and more than one type of malware is
used during the attacks. The comparison of traditional versus
new generation of malware can be seen in Table 1.
These days, the number, sophistication, and cost of mal-
ware inflicted on the world economy have been increasing
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
6249
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
TABLE 1. Traditional versus new generation malware.
incrementally. According to scientific and business reports,
approximately 1 million malware files are created every day,
and cybercrime will damage the world economy by approxi-
mately $6 trillion annually by 2021 [1]. Recent studies show
that mobile malware is on the rise. According to the McAfee
mobile threat report, there is a huge increase in backdoors,
fake applications and banking Trojans for mobile devices [2].
Besides, the malware attacks related to the social media,
healthcareindustry,cloudcomputing,internetofthings(IoT),
and cryptocurrencies are also on the rise. According to cyber-
security ventures, ransomware malware will cost around
$11.5 billion globally at the end of 2019 [1].
To protect legitimate users and companies from mal-
ware, malware need to be detected. Malware detection is
the process of determining whether a given program has
malicious intent or not. In early days, signature-based detec-
tion approach was used widely to detect malware. However,
this approach has some limitations such as it cannot detect
unknown and new generation malware. In process of time,
researchers proposed new approaches including behavioral-,
heuristic-, and model checking-based detection. With these
approaches, datamining and machine learning (ML) algo-
rithms are also started to be used widely in malware detec-
tion. Recently, new approaches have been proposed such
as deep learning-, cloud-, mobile devices-, and IoT-based
detection. For known and some of unknown malware, heuris-
tic detection approach performs well. On the other hand,
for unknown and complicated malware; behavior-, model
checking-, and cloud-based approaches perform better. Deep
learning-, mobile devices-, and IoT-based approaches also
emerge to detect some portion of known and unknown
malware. It has not been proved exactly that one detec-
tion approach is more effective than the others. This is
because each method has its own advantages and disadvan-
tages, and in different situation one method can detect better
than another. Even though several new methods have been
proposed by using different malware detection approaches,
no method could detect all new generation and sophisticated
malware. This shows that building an effective method to
detect malware is a very challenging task, and there is a huge
demand for new studies and methods.
This paper presents the literature review in order to inves-
tigate the current situation of malware detection approaches.
The paper makes the following contributions:
• Explains new technological trends for malware creation
and new approaches to detect malware.
• Investigates the probability of detecting malware.
• Presents a summary of the current studies on malware
detection.
• Explains important approaches and methods for mal-
ware detection.
• Discusses current challenges and proposes new assump-
tions for malware detection approaches.
• Provides a systematic overview of malware detection
approaches and methods for further studies.
The rest of the paper is organized as follows: Section II
demonstrates problem definition. Malware detection tech-
niques and algorithms are explained in section III, and
malware detection approaches are explained in section IV.
Evaluation on malware detection approaches are presented in
section V. Finally, the conclusion and future works are given
in section VI.
II. PROBLEM DEFINITION
This section investigates the problem of malware and possi-
bilityofdetection.Itcanbesaidthatitisimpossibletodesign
an algorithm which can detect all malware. This is because
theproblemofdetectingthemalwarehasshownNP-complete
in many studies. This is important because before starting to
build an effective detection system, it is a good practice and
experience for researcher to understand the scope, limitation,
and possibility of malware detector. The possibility of detec-
tion malware is remaining problematic because theoretically
it is a hard problem, and practically malware creators using
complicated techniques such as obfuscation to make detect-
ing process very challenging.
A. DIFFICULTY OF PROBLEM IN THEORY
Since the first malware that appeared in the wild was a virus,
mostofthestudieshadbeendonetheoreticallywerebasedon
the detection of virus. According to early studies, the detec-
tion of virus is impossible [3]–[5] and NP-complete [6]–[9].
According to F. Cohen, the detection of computer virus is
an undecidable because detection process itself contains a
contradiction [3], [5], [6]. If the detection problem is seen as
a decision-making problem, D (decision-maker) will decide
whether P is a virus or not. According to Cohen, it cannot
be decided whether P is a virus because if P is a virus,
it will be marked by D as a virus and will not be able to
make changes to other programs, as it will not act as a virus.
If D decision maker did not identify P as a virus, P will
interact with other programs to spread and become infected.
6250 VOLUME 8, 2020
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
This decision process involves contradiction, and therefore
it is not possible to identify P as a virus. According to
M. Chess and R. White, there is no program that detects
all viruses without false positives (FPs) because viruses are
polymorphic and can be exist in different forms [5]. Accord-
ing to M. Adleman detecting a virus is quite intractable and
almost impossible [7]. This is because according to Gödel
numberings of the partial recursive functions, it is not pos-
sible to create detecting mechanism. To reliably identifying
a bounded-length mutating virus is NP-complete explained
in[8].Accordingtotheauthor,virusdetectorforcertainvirus
strain can be used to solve the satisfiability problem. Since
satisfiability problem is known to be NP-complete, so the
detectionofthemalwareisNP-complete.Zuoetal.claimthat
thereexistcomputerviruseswhosedetectingprocedureshave
sufficiently large time complexity, and there are undecidable
viruses which have no minimal detecting procedure [9].
B. DIFFICULTY OF PROBLEM IN PRACTICE
The new generation malware uses the common obfusca-
tion techniques such as encryption, oligomorphic, polymor-
phic, metamorphic, stealth, and packing methods to make
detection process more difficult. This kind of malware can
easily bypass protection software that is running in kernel
mode such as firewalls, antivirus software, etc. and some
malware instances can also present the characteristics of
multiple classes at the same time. This makes practically
almost impossible to detect all malware with single detection
approach. The definition of common obfuscation techniques
explain as follows:
• Encryption: In encryption, malware uses encryption to
hide malicious code block in its entire code [10]. Hence,
malware becomes invisible in the host.
• Oligomorphic: In oligomorphic method, a different key
is used when encrypting and decrypting malware pay-
load [11]. Thus, it is more difficult to detect malware
which uses oligomorphic method than encryption.
• Polymorphic: In polymorphic method, malware uses a
differentkeytoencryptanddecrypt[12]likewisethekey
used in oligomorphic method. However, the encrypted
payload portion contains several copies of the decoder
and can be encrypted in layered [13]. Thus, it is more
difficult to detect polymorphic malware when compared
to oligomorphic malware.
• Metamorphic: Metamorphic method does not use
encryption. Instead, it uses dynamic code hiding which
theopcodechangesoneachiterationwhenthemalicious
process is executed [14]. It is very difficult to detect
such malware because each new copy has a completely
different signature.
• Stealth: Stealth method also called code protection,
implements a number of counter techniques to prevent it
from being analyzed correctly [11]. For instance, it can
make changes on the system and keep it hidden from
detection systems.
• Packaging: Packaging is an obfuscation technique to
compress malware to prevent detection, or hiding the
actual code by using encryption [15], [16]. Due to this
technique, malware can easily bypass firewall and anti-
virus software. Packaged malware need to be unpacked
before being analyzed. The packers can be divided into
4differentgroupsincludecompressors,crypters,protec-
tors, and bundlers.
In this section, the limitations of malware detecting sys-
temshavebeensummarized.Currentstudiesdemonstratethat
it is almost impossible to write an algorithm to detect all
malware. This is because the computational complexity of
malware is not clear, and the detection of malware problem
is proved to be NP-complete. Besides, the use of new tech-
niques (obfuscation and packing) during malware creation
also makes detection process more challenging.
III. MALWARE DETECTION TECHNIQUES AND
ALGORITHMS
In recent years, datamining and ML algorithms have been
used extensively for malware detection. Malware detection
is the process of investigating the content of the program and
deciding whether the analyzed program malware or benign.
The malware detection process includes 3 stages: Malware
analysis, feature extraction, and classification.
A. MALWARE ANALYSIS
In order to understand the content and behaviors of malware,
it needs to be analyzed. Malware analysis is the process
of determining the functionality of malware and answers to
following questions [17], [18]. How malware works, which
machines and programs are affected, which data is being
damaged and stolen, etc. There are mainly two techniques
to analyze malware: static and dynamic [17]. Static analysis
examines the malware without running the actual code [19].
On the other hand, dynamic analysis examines the malware
behaviors while running its code. Malware analysis starts
withbasicstaticanalysisandfinisheswithadvanceddynamic
analysis. The malware is analyzed by using reverse engineer-
ing [20] and some other malware analysis tools to represent
the malware in different format. Reverse engineering process
can be seen in Figure 1.
FIGURE 1. A flow chart of reverse engineering process.
VOLUME 8, 2020 6251
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
B. MALWARE FEATURE EXTRACTION
Malware features are extracted by using data mining tech-
niques. Data mining is the process of extracting new mean-
ingfulinformationfromlargedatasetsordatabaseswhichhas
been unknown before this process. In recent years, by using
datamining new models and datasets have been created [21].
There are different models such as n-gram, and graph model
to create malware dataset and features.
1) THE n-gram MODEL
The n-gram is a feature extraction technique which has been
used widely in many areas as well as malware detection.
The n-gram can use both static and dynamic attributes to cre-
ate features. To create features from behaviors, n-gram group
the system calls or application programing interfaces (APIs)
in a consecutive order by specified n (n = 2,n = 3,n =
4,n = 6, etc.) values. Although the n-gram model has been
used widely in malware detection, it has some drawbacks
when determining features. This is because every sequential
static and dynamic attributes are not related to one another.
Thismakesclassificationandclusteringmorechallengingfor
later processes. Besides, n-gram generates enormous feature
space which increases the analysis time and decreases the
modelperformance.Forthesereasons,thereisahugedemand
to find out new models to achieve better performance than
n-gram.
2) GRAPH-BASED MODEL
The graph-based model is one of the commonly used tech-
niques to generate features as well. System calls made in
this method are converted into graph G (V, E) such that
V represents nodes which identify system calls and the E
represents edges which identify the relationship among the
system calls. Since the size of the graph increases over time,
sub-diagrams can be used to describe the graph. The sub-
diagram is defined in many studies as NP-Complete. This
meansthatitrequiresalotoftimetodefineeachsub-diagram.
After the whole diagram is expressed with fewer nodes and
edges, the programs are identified as malicious or benign.
3) MALWARE DATASET
As in other research areas, there are not many datasets pub-
lished previously which are accepted and widely used for
malware detection. In addition, most of the existing datasets
are not accessible for research, and in most cases the datasets
accessed are not in the appropriate formats for data mining
processes and ML algorithms. The datasets used in mal-
ware analysis can be listed as follows: NSL-KDD, Drebin,
Microsoft malware classification challenge, ClaMP (classifi-
cation of Malware with PE headers), AAGM, and EMBER
dataset.
• NSL-KDD dataset (2009): It is an updated version of
the KDD’99 dataset which consists of approximately
125,000 records and 41 features [22]. It shows the
network related attacks which are used for intrusion
detection system.
• Drebin dataset (2014): This dataset is created for smart
phones to examine the effectiveness of the existing anti-
virus software [23]. It consists of 5560 malware across
20 families and 123,453 benign samples.
• Microsoft malware classification challenge dataset
(2015): It has been published by Microsoft and consists
of 20,000 malware [24]. Malware has been analyzed
usingtheIDApacketdisassemblerandtheoutputshould
be processed using data mining prior to ML.
• ClaMP (Classification of Malware with PE headers)
dataset (2016): It consists of 5184 records and has
55 properties [25]. The dataset uses API arrays, contains
examples of malicious and benign software with their
features.
• AAGMdataset(2017):Itisanetwork-baseddatasetfor
android malware [26]. It consists of 400 malware and
1500 benign samples from 12 families [26].
• EMBERdataset(2018):Itconsistsof1millionrecords
and holds malware and benign features [27].
These datasets can be used for researches who want to get
some experience before proposing a new malware detection
approach.
C. MALWARE CLASSIFICATION
Machine learning (ML) is a set of algorithm that correctly
estimates the outcomes of the applications without being
explicitly programmed. The purpose of the ML is to convert
the input data into acceptable value intervals by using statisti-
calanalysis.ByusingML,manyoperationscanbeperformed
on related data such as classification, regression and cluster-
ing. ML algorithms have been used in malware detection for
many years [28]. Well-known ML algorithms are Bayesian
network (BN), naive Bayes (NB), C4.5 decision tree variant
(J48), logistic model trees (LMT), random forest tree (RF),
k-nearest neighbor (KNN), multilayer perceptron (MLP),
simple logistic regression (SLR), support vector machine
(SVM), and sequential minimal optimization (SMO). These
algorithms are used especially in behavior-based detection
and some of other detection approaches. Although each algo-
rithm has its own advantages and disadvantages, it cannot be
concluded that one algorithm is more efficient than another.
However, an algorithm can perform better than other algo-
rithms in terms of the distribution of the data, number of
features, and dependencies between properties.
IV. MALWARE DETECTION APPROACHES
In recent years, there has been a rapid increase in the num-
ber of academic studies on malware detection. In the early
days, signature-based detection method was widely used.
This method works fast and efficiently against the known
malware, but does not perform well against the zero-day
malware [21], [29]. In the process of time, researchers have
started to use techniques such as behavior-, heuristic-, and
6252 VOLUME 8, 2020
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
FIGURE 2. A flow chart of malware detection approaches and features.
model checking-based detection; and new techniques such as
deep learning-, cloud-, mobile devices-, and IoT-based detec-
tion. Overview of malware detection approaches, features,
and used techniques can be seen in Figure 2.
Ineachapproach,featureextractingmethodisdifferentone
from another. It could not have been proven one detection
method works better than another because each method has
its own advantages and disadvantages. By using behavior-,
heuristic-, and model checking-based detection approaches;
hugenumberofmalwarecanbedetectedwithafewbehaviors
and specifications. In addition, new malware can be detected
by using these approaches as well. However, they cannot
detectallmalware.Thereisgreatnecessitytofindthemethod
which effectively detects more complex and unknown mal-
ware. Before explaining each detection approach in details,
some well-known methods in each detection approach and
their related works are summarized in Table 2. Then, detailed
literature review is presented, and the pros and cons of each
study are explained.
A. SIGNATURE-BASED MALWARE DETECTION
Signature is a malware feature which encapsulates the
program structure and identifies each malware uniquely.
Signature- based detection approach is widely used within
commercial antivirus. This approach is fast and efficient to
detect known malware, but insufficient to detect unknown
malware. In addition, malware belonging to the same fam-
ily can easily escape the signature-based detection by using
obfuscation techniques. General view of signature-based
detection schema can be seen in Figure 3.
1) SIGNATURE GENERATION PROCESS
During the signature generation, first features are extracted
from executables (Figure 3). Then, signature generation
engine generates a signatures and stores them into signature
database. When sample program needs to be marked as mal-
ware or benign, signature of the related sample is extracted
as the same way before and compared with signatures on
the database. Based on the comparison, sample program is
VOLUME 8, 2020 6253
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
TABLE 2. Summary of related works on malware detection approaches.
marked as malware or benign. There are many different tech-
niques to create a signature such as string scanning, top-and-
tail scanning, entry point scanning, and integrity checking.
• String Scanning: Compares the byte sequence in
the analyzed file with the byte sequences previously
saved in the database. Byte signatures have been
6254 VOLUME 8, 2020
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
FIGURE 3. Signature-based malware detection schema.
TABLE 3. Example ClamAV byte signature.
TABLE 4. ‘‘90FF1683EE0483EB0175F6’’ Assembly byte sequence.
TABLE 5. Display of byte signatures in Yara format.
used extensively by antivirus scanners for many years.
They are often used to detect malware which belongs
to the same family with different signatures [61].
Table 3 shows the ClamAV byte signature [62].
‘‘90FF1683EE0483EB0175F6’’ is the hexadecimal rep-
resentation of the relevant code section and it is shown in
assembly language as in Table 4. The same byte signature
is shown in Yara format in Table 5 [62].
• Top-and-Tail Scanning: Instead of the whole file, only
the top and end points of the file are taken and certain
signatures are created [11]. It is a very convenient signa-
ture method to detect viruses that attach themselves to
the beginning and end of files.
• Entry Point Scanning: The entry point of a file indi-
cateswherethefirstrunstartswhenthatfilestartstorun.
Malware usually changes the entry point of a program,
so that malicious code being executed before the actual
code [11]. Therefore, certain malware can be detected
by extracting the signature from the sequences at the
program entry points.
• IntegrityChecking(HashSignatures):Integritycheck
generates a cryptographic checksum such as MD5 and
SHA-256 for each file in a system at regular intervals,
and it is used to identify possible changes that may be
caused by malware.
Different signature generation techniques have been sum-
marized. Eventhoughthese techniquesare quitefast andeffi-
cient to generate a signature, they are not resistant to malware
obfuscating techniques. For example, malware can easily
change the strings and program entry point in its instruction
set. By this, generated signature may mislead the detecting
schema.Toextractmorepowerfulandgeneralsignatures,dif-
ferenttechniquesandfeaturescanbeused.Detailedreviewof
signature-based malware detection approach and its methods
are summarized as follows:
2) RELATED WORKS FOR SIGNATURE-BASED DETECTION
F. Zolkipli and Jantan proposed a new malware detection
framework which is based on s-based detection, genetic
algorithm (GA), and signature generator [63]. Even though
the authors claim that this method can detect unknown mal-
ware, there is not enough information given in the paper
for proposed framework such as test results, number of
malware analyzed, and comparison of proposed method with
other existing studies. Tang et al. proposed a bioinformatics
technique to generate accurate exploit-based signatures for
polymorphic worms [64]. The technique involves three steps:
multiple sequence alignment to reward consecutive sub-
string extractions, noise elimination to remove noise effects,
and signature transformation to make the simplified regular
expression signature compatible with current IDSs.
The authors claim that suggested schema is noise-tolerant,
and more accurate and precise than those generated by
some other exploit-based signature generation schemas. This
is because it extracts more polymorphic worm characters
like one-byte invariants and distance restrictions between
invariant bytes. However, proposed schema is limited to
polymorphic worm and cannot be generalized to other
malware types.
Borojerdi and Abadi proposed a MalHunter detection sys-
tem which is a new method based on sequence clustering
and alignment [65]. It generates signatures automatically
based on malware behaviors for polymorphic malware. The
novel method works as follows: First, from different malware
samples, behavior sequences are generated. Then, based on
similar behavioral sequences, different groups are generated
and stored in the database. To detect malware sample, behav-
ior sequences are gathered and compared with sequences
which have been generated earlier and stored in the database.
Based on the comparison, the sample is marked as mal-
ware or benign. The test results showed that by choosing
the cluster radius 0.4 and similarity threshold 0.05, they
VOLUME 8, 2020 6255
Ö. Aslan, R. Samet: Comprehensive Review on Malware Detection Approaches
achieved detection rate of 90.83% with a FPR of 0.80%.
The authors claim that proposed schema is resistant to
obfuscation techniques, and it can be used for the generic
detection of all types of polymorphic malware rather than
being limited to a specific malware type. The authors also
claim that the suggested system outperformed state-of-the-
art signature generation methods including Tang et al. [64],
Newsome et al. [66], and Perdisci et al. [67] previously
reported in the literature. The proposed method is limited to
polymorphicmalwareandithasbeentestedononlyhundreds
ofmalwarewhichisnotenoughtodeterminetheperformance
of proposed method.
Automatic string signatures generation (Hancock) is
explained in [41]. According to the paper, proposed schema
can automatically generate high-quality string signatures
with minimal FPs and maximal malware coverage. The pro-
posed method uses a set of library code identification tech-
niques, and diversity-based heuristics techniques to ensure
the contexts in which a signature is embedded in contain-
ing malware files similar to one another [41]. Although the
authors claim that Hancock can automatically generate string
signatures with a FPR below 0.1%, this FPR will be changed
based on benign samples that are analyzed. This is because
benign set is constantly growing, and getting some satisfy-
ing result on some part of benign cannot be generalized to
whole set. Thus, these problems need to be solved for further
studies. Santos et al. proposed n-grams-based file signatures
to detect malware [68]. First, for known files n-grams are
extracted for every file and used as a file signature. Then, for
any unknown instance, n-grams are generated, and by using
measuring function and k-nearest neighbor algorithm [69],
file is marked malware or benign. Paper demonstrated that
n-grams-based signatures can detect unknown malware to a
certain degree.
Efficient signature based malware detection on mobile
devices is proposed in [70]. First, signature has been cre-
ated. Second, hash table has been used to store the hash
values of signatures to increase scanning speed. Finally, sig-
nature matching algorithm is used to compare the signatures.
To eliminate the mismatches, the probability of occurrence
of signature bytes in non-malicious content has been used.
According to the authors, the results have shown that sug-
gestedschemaperformswellwhencomparedtotheClam-AV
scanner, and provides huge memory savings while main-
taining fast scanning speed. The proposed system was only
compared with Clam-AV scanner, which is not enough for
overallevaluation.Zhengetal.presentedtheDroidAnalytics,
anAndroidmalwareanalyticsystemwhichcanautomatically
collectmalware,generatesignaturesforapplications,identify
Received January 10, 2020, accepted February 5, 2020, date of publication February 10, 2020, date of current version February 18, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2973023
An Unsupervised Deep Learning Model for Early
Network Traffic Anomaly Detection
REN-HUNG HWANG
1,2 , (Senior Member, IEEE), MIN-CHUN PENG 1 , CHIEN-WEI HUANG 1 ,
PO-CHING LIN
1 , AND VAN-LINH NGUYEN 1,3 , (Member, IEEE)
1 Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi 62102, Taiwan
2 Advanced Institute of Manufacturing With High-Tech Innovations, National Chung Cheng University (CCU), Chiayi 62102, Taiwan
3 Department of Information Technology, TNU-University of Information and Communication Technology, Thai Nguyen 24119, Vietnam
Corresponding author: Van-Linh Nguyen (nvlinh@ictu.edu.vn)
This work was supported in part by the Advanced Institute of Manufacturing With High-Tech Innovations (AIM-HI) from the Featured
Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in
Taiwan, in part by the Ministry of Science and Technology of Taiwan, R.O.C. under Grant MOST 107-2218-E-194-014,
Grant 108-2221-E-194-022-MY3, and Grant MOST 108-2221-E-194-019-MY3, in part by the Taiwan Information Security Center,
National Sun Yat-sen University, under Grant TWISC@NSYSU, and in part by the TNU-University of Information and Communication
Technology, Vietnam.
ABSTRACT Various attacks have emerged as the major threats to the success of a connected world like
the Internet of Things (IoT), in which billions of devices interact with each other to facilitate human life.
By exploiting the vulnerabilities of cheap and insecure devices such as IP cameras, an attacker can create
hundreds of thousands of zombie devices and then launch massive volume attacks to take down any target.
For example, in 2016, a record large-scale DDoS attack launched by millions of Mirai-injected IP cameras
and smart printers blocked the accessibility of several high-profile websites. To date, the state-of-the-art
defense systems against such attacks rely mostly on pre-defined features extracted from the entire flows
or signatures. The feature definitions are manual, and it would be too late to block a malicious flow after
extracting the flow features. In this work, we present an effective anomaly traffic detection mechanism,
namely D-PACK, which consists of a Convolutional Neural Network (CNN) and an unsupervised deep
learning model (e.g., Autoencoder) for auto-profiling the traffic patterns and filtering abnormal traffic.
Notably, D-PACK inspects only the first few bytes of the first few packets in each flow for early detection.
Our experimental results show that, by examining just the first two packets in each flow, D-PACK still
performs with nearly 100% accuracy, while features an extremely low false-positive rate, e.g., 0.83%. The
design can inspire the emerging efforts towards online anomaly detection systems that feature reducing the
volume of processed packets and blocking malicious flows in time.
INDEX TERMS IoT security, anomaly detection, convolutional neural network, autoendcoder, online
DL-based anomaly detection.
I. INTRODUCTION
In recent years, with increasingly massive IoT applications
and connected devices, distributed denial-of-service (DDoS)
attacks have caught the attention of the security community
with a series of record-high attack magnitude. Given a small
proportion of billions of IoT devices, e.g., cheap and insecure
IPcameras,injectedtobezombies,anadversarycangenerate
a massive volume of flooding traffic to take down a target
suchasacriticalInternetservice.Althoughthiskindofattack
is by no means new, it still poses a tremendous threat to most
The associate editor coordinating the review of this manuscript and
approving it for publication was Fan Zhang.
state-of-the-art defense systems [1]–[4]. To stop malicious
traffic, including that from DDoS attacks, the first step is to
detect traffic anomaly as soon as possible by analyzing net-
work traffic atthe gateways, at edgeservers, or in ascrubbing
center [5].
To date, existing approaches such as signature-based
and statistical detection systems still have several flaws,
e.g., the rule maintenance cycle cannot keep up with
soaring attack variants [3]. When the ecosystem of
Internet-connected systems expands and the diversity of IoT
devices increases rapidly, it is inevitable that there are more
potential vulnerabilities for an attacker to exploit. As a result,
a signature-based detection system, which may be able to
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/
30387
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
detect well-known attacks with high accuracy, can quickly
lose its advantage because unknown attacks may appear
nearly per minute [1], [2]. Dealing with the explosion of the
attackvariants,theanomalydetectionapproaches,asopposed
to the signature-based ones, can significantly help. Unlike
signature-based approaches, anomaly detection systems can
monitor network flows and classify them as either normal
or anomalous ones; thus, new attack variants are less likely
to bypass the detection. Nonetheless, anomaly detection
approaches often face high false alarm rates, since the sys-
tems must be taught to recognize normal activities [6]. So far,
such systems are often designed with strict mathematical
models and a set of predefined features [7]. Fortunately, deep
learning (DL) promises to be the game-changer to help to
solve the learning problem, i.e., automatically building the
traffic profile. The most benefit of deep learning is to build
a thorough pattern that can precisely characterize specific
objects through automatically learning a large volume of data
and species.
DL-based approaches have been well investigated in many
fields over the years, including anomaly detection. How-
ever, many challenges remain, e.g., speeding up the detection
and auto-profiling the traffic patterns effectively, which are
also the target of this work. From the design perspective,
the detection systems should characterize normal network
flows and define well-represented traffic profiling. Based on
this profiling, the systems can identify and isolate anomalous
network activities. In the literature, the common profiling
method is building a pre-defined list of features [6], [8] from
flow statistics, e.g., sending rate, packet count or flow size,
and then using the DL models such as a convolutional neural
network (CNN) for learning [9]. However, defining a list
of well-represented features manually for effective learning
poses tremendous challenges, e.g., labor time, particularly if
the network has a diversity of application traffic. Recently,
a promising approach is to use CNN to automatically extract
such features directly from raw traffic, instead of from the
summarized data, e.g., [10]. In this work, we go further in
building the traffic patterns (e.g., of benign applications) by
examining only the first few bytes of the first few packets of
the flows. This approach promises to have many advantages,
particularly for online anomaly detection systems. For exam-
ple, the detection does not need to waste remarkable compu-
tation and time for checking redundant data and storage in
a whole long session, while a few first packets of the flows
are sufficient for the detection. As a result, our system has
a significant advantage of speeding up the detection. Note
that summarizing the traffic in a flow-based approach may
demand much memory space for flow tracking in a large
network, particularly if many long flows exist.
The proposed system, namely D-PACK, consists of two
main parts: (1) A CNN module is designed for auto-learning
the features from the raw data; (2) An unsupervised DL
model(autoencoder)trainedwiththeoutputdataof(1)targets
at building the profile of benign traffic and then precisely
judge whether the traffic in the examined flows is abnormal.
The experimental results show that D-PACK is competitive
and prominently outperforms prior studies in terms of accu-
racy, precision, recall, and F1-measure. Specifically, it can
detect malicious traffic with nearly 100% accuracy and less
than 1% FNR and FPR, even if it examines only two packets
from each flow and 80 bytes from each packet. To train the
system with the normal traffic characteristics and activities,
thetrainingissettorunatthetimeofdeployingthedevicesto
ensure the devices are in the clean state before any possible
compromising. The detection is also deployed close to the
devices (i.e., the traffic sources) to identify traffic anomaly.
In summary, the main contributions of this work are as
follows:
• We propose a CNN-based deep learning approach for
auto-learning the traffic features and profiling traffic
directly from the raw traffic with only a few first packets
per flow. Following this, the auto-learning approach can
significantly save the efforts to build traffic patterns for
a complex network where the diversity of application
traffic is the major challenge to conventional methods.
• We implement the proposal and evaluate it with both the
credible datasets and self-collected realistic ones. The
evaluationwiththedatasetsfrommultiplesourcesshows
that D-PACK can achieve nearly 100% accuracy and
precision in detecting malicious packets.
• Our design on packet-based deep learning classifica-
tion and detection promise to provide valuable informa-
tion and inspire the research community to overcome
the remaining challenges, particularly for speeding up
online DL-based anomaly detection.
The remainder of this paper is organized as follows.
Section II surveys the state-of-the-art work on traffic classi-
fication and deep learning detection approaches. Section III
presents our learning strategy and the detailed structure of
the auto-building traffic profile module, the key features
of this work. Our selected datasets and the detail of the
D-PACK framework are presented in Section IV. We show
the experimental design and results in Section V. Finally,
theconclusionandfutureworkaresummarizedinSectionVI.
II. RELATED WORK
The issue of detecting malicious network traffic has been
studiedextensively.Themainstreamapproachesfallintofour
primary classes [8]: port-based/rule-based, deep/stochastic
packet inspection, statistical, and behavioral techniques.
While the first three approaches are common and gain
high performance in intrusion detection over decades, it is
expected to see a silver lining with the rising trend of deep
learning to overcome the known flaws of existing studies,
particularlyinthelastapproach.Fromtheevaluationperspec-
tive, the behavioral approach may have poor performance at
several metrics, e.g., high false alarm, due to the complexity
of benign traffic profiling and the definition of ‘normal’
network activities.With thepotential of accumulatingknowl-
edge from large-scale raw data without manual interference,
deep learning is an effective approach to improve anomaly
30388 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 1. Summary of related anomaly detection strategies.
detection in the future [11]. In Table 1, we summarize several
well-known state-of-the-art DL-based traffic classification
methods, their performance on common datasets, and then
address our research position.
As shown in Table 1, most works are in favor of using
CNN/autoencoder to build the traffic classifier for anomaly
detection. Notably, these approaches rely on a set of prede-
fined features, e.g., statistical features [9], [16], [25], for data
preprocessing. However, the DL techniques in these systems
are supposed to vary due to the different interests in address-
ingspecificapplicationsanddefensestrategies [15], [21].For
example, the authors in [18], [20] select CNN for extracting
the features from the packet headers and payloads. Autoen-
coder,ontheotherhand,isproperfortrainingontheextracted
features [12], [16], [22]. Also, the bias and imbalance of
the traffic classes in the training datasets are a key factor to
motivate the authors to select a proper DL model. Finally,
while Table 1 reflects no quantitative measurement of which
method is better due to their different usages in the datasets
and further different metrics for evaluation, our summary
here aims to give an overview of the dominant trends of
applying DL for anomaly detection.
Unlikepriorresearch,wepursueanovelapproachtodetect
traffic anomaly. Instead of collecting the entire traffic flows
for finding the evidence of abnormal behavior, we pack the
first several packets per flow into segments of fixed lengths,
e.g.,80bytes.Thegoalistobuildasubsetofthedataandtrain
only on this trimmed version. This approach significantly
reduces the computation and memory space to process the
session flows, particularly the long ones. A closely related
work to ours is [13], in which the authors first collected
both normal and malicious traffic from an IoT environment
with devices infected by Bashlite and Mirai. The traffic is
trimmed by various time scales for experimental purposes,
including 100ms, 500ms, 1.5sec, 10sec, and 1min time win-
dows.Foreachtimewindow,asetofpre-defined23flowfea-
tures are extracted as the input to the autoencoder. However,
themethodstillconsumesquitemuchtimesincethesampling
is performed on the offline data and extracting the features is
an independent pre-processing step. In contrast, in this work,
we build a CNN model for auto-learning the features and
the sampling targets at just several packets per flow (instead
of sampling the whole flows at several check time points).
Compared with prior studies, this work features two major
differences: (1) D-PACK can build the profile of the traffic
by examining the first packets per flow, instead of checking
the total packets in the flows; (2) D-PACK can work directly
with raw packets (after data sanitization), i.e., building the
patterns, reading the input data and making the detection
decision. Finally, we believe that a detection approach by
trimming the data for inspection like ours is competitive with
the high detection accuracy achieved by prior studies for
VOLUME 8, 2020 30389
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
FIGURE 1. Illustration of the sampling to extract the segment of the first
3 packets from a flow of 10 packets.
the same attack types. This approach can motivate further
research on optimizing and accelerating the processing in
early anomaly detection systems.
III. LEARNING STRATEGY FOR EARLY CLASSIFICATION
AND DETECTION
This section gives an overview of the learning strategy that
targets at building a thorough traffic profile while dramati-
cally reduces the data volume for processing. This mecha-
nism also makes early anomaly detection possible, which is
the key feature of this work.
A. SAMPLING NETWORK FLOWS
The traffic volume can be enormous in a high-speed net-
work; thus, it is important to reduce a load of packet
capturing and analysis on the detection function for high
efficiency. According to the heavy-tailed nature of Internet
traffic [26], it was reported that keeping only a small por-
tion of each flow is sufficient for protocol identification or
retrospective analysis while reducing the total traffic volume
significantly [27], [28]. Therefore, we consider sampling the
flowsbyextractingthefirstnpacketsofeach,andeachpacket
is trimmed into a fixed length of l bytes, starting with the
header fields (with zero-padding if necessary; see the next
subsection for the detail). Note that the raw packets of a
flow is classified based on their 5-tuple information (source
IP, source port, destination IP, destination port, and transport
layer protocol). n and l may be flexibly adjusted according to
the network traffic characteristics at the time of deployment.
This sampling can significantly reduce the total amount of
traffic in the analysis, while the characteristics of the packets
are still representative to reveal whether the associated flows
are malicious or not for early anomaly detection. Our sam-
pling workflow is illustrated as Fig. 1.
As an example in Fig. 1, a flow consists of ten packets, and
we inspect only the first three packets and trim their lengths.
Since only several packets per flow are examined, the system
can inspect significantly fewer data in total, like the results
from in [27], [28]. This saving is even much more if the flow
is part of a long session. Notably, this saving is essential for
a system that requires early detection.
After the data extraction (from pcap) with trimming,
the next step is to read the data and form an understandable
format for the learning task. Since a DL system cannot be
fed with data of different lengths, short packets are padded
with zeros. We view the trimmed bytes in each flow as a
one-dimensional vector with n × l elements, and turn them
into the input of the CNN model for training. Like major DL
studies, a step of trace sanitization is also used to eliminate
the errors and repeated traffic.
B. AUTO-BUILDING THE TRAFFIC PROFILE
Building the pattern of benign traffic is the next important
task. Compared with traditional methods that extract traffic
features manually, an auto-learning approach does not con-
tain independent modules such as feature extraction and fea-
ture selection. The features are automatically learned, and the
traffic is directly passed to the classifier. Therefore, the non-
linear relationship between the raw input and the expected
output is determined, partially achieving the goal of end-
to-end learning.
To date, CNN has been mainly applied in the domain of
computer vision, e.g., image classification [29]. Recently,
there are also successful applications in the field of natural
language processing (NLP) [7], [11]. CNN is most suitable
for the kinds of data in the form of multiple arrays or the ones
with strong local correlations or whose features can appear
anywhere, even in which objects are invariant to translations
and distortions [19]. Specifically, 1D-CNN is good for data
like sequential data or language [7], [11]. 2D-CNN is good
for data like images. 3D-CNN is good for data like video or
volumetric images. 1D-CNN is also widely used for network
traffic analysis, e.g., [19], including this work.
It is common to visualize the extracted bytes from each
flow as the pixels of two-dimensional (grayscale) images
like those in Fig. 2, and then to apply 2D-CNN to traffic
classification. The authors [24] use this approach, although
they prefer to use a stacked auto-encoder (SAE) other than
2D-CNN. However, since a flow may consist of more than
one packet, a 2D-CNN filter may cover a region of irrelevant
bytes from two packets or more (e.g., the bytes in adjacent
rows of pixels are semantically irrelevant). Inspired by this
fact, our auto-profiling module is built on a 1D-CNN model
(i.e.,theinputtoCNNisaone-dimensionalimage).Asimilar
approach was taken in [18], but this work differs from theirs:
we set a fixed number of packets and bytes taken from a flow
to formthe one-dimensional image,regardless of whetherthe
bytes are from one or multiple packets.
FIGURE 2. Visualization of the traffic types in our dataset (Mirai-CCU).
The detail will be described in section IV.
The architecture of the 1D-CNN model is illustrated as
in Fig. 3. We assume that the first n packets per flow are
sampled, and each sampled packet is trimmed into the first
l bytes (primarily in the packet header). The data are padded
30390 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
FIGURE 3. CNN model for auto-building the traffic profile.
withzerosifthenumberofpacketsislessthannorthepacket
size is less than l bytes. Let p i be the ith packet after the
above trimming. The one-dimensional image is composed
of the bytes in p 1 ||p 2 ||...||p n as the input, where || is the
concatenation operator.
Let x i be a window of s bytes beginning from the ith byte
oftheinput,wherei = 1,...,n×l−s+1.Intheconvolution
operations, let m be the number of filters to be applied to the
input x i to produce a new feature. As a result, a feature h k
i
from the kth filter to the window x i is generated by
h k
i
= f (W k x i + b k ), (1)
where f is a ReLU function [18], W k is the weight vector
of the kth filter, and b k is a bias term or the offset of the
kth filter. The above parameters in this work will be summa-
rizedinTable5.Notethateachfilterisappliedtothepossible
windows of s bytes in the input to produce a feature map
(assuming the stride is 1 in Eq. 2):
h = [h 1 ,h 2 ,...,h nl−s+1 ]. (2)
We then apply a max-over-time pooling operation over the
feature map and take the maximum value max(h) as the
feature in the next layer. In this work, we use multiple
convolution layers and pooling layers to extract high-level
features. These features form the layer and are passed to a
fully connected dense layer whose output is the probability
distribution of the type of benign flows (e.g., Gmail, Skype).
It is noted that increasing the parameter n may offer more
statistical characteristics about the flow, but pours more data
into the system. The evaluation in Section V reveals clearly
this relationship. In this work, we attempt to use as few
packets as possible while still guarantee detection accuracy.
Therefore, the ideal configuration of n and l is the threshold
in which the system performance is balanced among several
measurements, e.g., high accuracy and low traffic volume for
processing. We found in the empirical experiments that, with
n = 2 and l = 80, the system can attain this target on most
of the selected datasets (see Section V).
In this work, we run the model on benign traffic to build
the traffic profile for the binary classifier, i.e., to classify
whether the flows are from benign traffic or not. In this case,
autoencoderisusedasthebinaryclassifier.Anexampleofthe
distribution of benign/malicious packets after binary classifi-
cation from our autoencoder is illustrated in Fig. 4. Notably,
the hidden layers of the learning module are designed to
connect directly with the input layers of the autoencoder
FIGURE 4. Packet distribution after binary classification, from left to
right: the normal traffic distribution, malicious traffic distribution and
common distribution.
network (see Section IV-B). This connection significantly
helps to achieve the goal of end-to-end learning, since the
learning and classification are under a connected and unified
DL network.
In summary, besides the auto-learning ability of the CNN
model on the raw packets, the learning strategy, along with
the sampling procedure to shorten the data for processing,
plays a decisive role in computation reduction and early
detection. Moreover, with the adjustable parameters, n and l,
the administrator can adjust the proper thresholds to balance
learning from as many features of the traffic as possible and
satisfyingthelimitedsystemresourcesorthedetectionspeed.
The effectiveness of this approach is revealed in Section V.
IV. AN UNSUPERVISED DEEP LEARNING MODEL
FOR EARLY ANOMALY DETECTION
Inthissection,wefirstcoverthedetailofourselecteddatasets
and then the architecture of the D-PACK detection frame-
work. The strategy for tuning the parameters to improve the
performance is also described.
A. DATASET
Lack of a variety of shareable traces dataset has hin-
dered the progress in traffic classification by deep learn-
ing. Researchers may create synthetic datasets through their
testbed, but the generated traffic may not reflect the Internet
traffic faithfully. Thus, the evaluation based on such traces
may not be credible. Over the decades, researchers have
been tempted to use famous public traffic datasets such as
KDD CUP 99 and NSL-KDD. The datasets provide useful
statistics on labeled features and both benign and malicious
flows as well, but they do not provide information at the
raw packet level, which is required in our approach. Also,
while the credible dataset from Microsoft Malware Classi-
fication Challenge [30] can provide a metadata manifest and
hexadecimal representation of the binary content of malware,
missing packet information in the data, unfortunately, makes
it unusable in this work.
USTC-TFC2016 [18] is a prominent dataset that matches
our requirements. Table 2 summarizes the statistics of benign
andmalicioustrafficinthedataset.Pertheirstatement,totally
ten types of malware traffic were collected from public web-
sitesinarealnetworkenvironmentfrom2011to2015.Along
with such malicious traffic, the benign part contains ten types
of normal traffic collected using IXIA BPS, a professional
VOLUME 8, 2020 30391
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 2. Summary of benign and malware traffic in
USTC-TFC2016 dataset.
network traffic simulation equipment. The size of this dataset
is 3.71GB in the pcap format.
For the Mirai-based DDoS traffic, we use the dataset from
Robert Gordon University, denoted by Mirai-RGU, and its
statisticsareshowninTable3.Thereadersarereferredto[31]
for the testbed used to collect the dataset. This dataset con-
tains Mirai botnet traffic such as scan, infect, control, attack
traffic, and normal IP camera traffic. The Mirai botnet traffic
consists of four main attack types: UDP flood, ACK flood,
DNS flood, and SYN flood attacks. The dataset includes
features such as time, source, destination, protocol, length,
and overall payloads.
TABLE 3. Summary of benign and malicious traffic by packet count in the
Mirai-RGU dataset [31].
In order to enrich the traffic activities and identify the
attack traffic, we have built a Mirai botnet in the campus of
NationalChungChengUniversity(CCU)fortesting(denoted
by Mirai-CCU), as shown in Fig. 5. The C&C server controls
sevenIoTdevices(i.e.,WiFiaccesspoints)andcollectsallthe
DDoSattacksfromMirai.Despitethesmalltestbed,weargue
that the detection performance in the experiments does not
deviate from that in a large testbed because the detection
refers only to the first few bytes in the first few packets of the
flows as the features, instead of the number of flows, packets
FIGURE 5. The testbed of our Mirai-based DDoS dataset in the campus of
National Chung Cheng University (CCU), in which the Mirai botnet is at
the WiFi APs in the bottom.
orbytesoveragivenperiodoftime.Itisimportanttonotethat
reproducing a large-scale Mirai-based botnet would be costly
and probably illegal; thus, we do not resort to that alternative.
The collected dataset consists of four DDoS attack types:
SYN flood, UDP flood, ACK flood, and HTTP flood. The
dataset covers over 304K malicious flows and its size is
277.1GB. Table 4 summarizes the collection of these four
types. Like [18], we also visualize these four attack types
in Fig. 2. For each type of attack, we randomly select nine
flows, and for each flow, a 2D grayscale image of 20*25 is
produced by selecting the first 100 bytes of the first five
packets (i.e., totally 500 bytes in a flow). Fig. 2 shows that
the same type of flows are similar in the visualization, but are
quite different between different flows.
TABLE 4. Mirai DDoS types collected in our testbed, namely Mirai-CCU.
B. UNSUPERVISED DL-BASED ANOMALY
DETECTION ARCHITECTURE
Fig. 6 shows the schematic diagram of the D-PACK frame-
work. After the pre-processing (left side), CNN is used
to automatically extract the flow features by classifying
flows into different types, e.g., 10 types in the USTC-
TFC2016 dataset. The network traffic is composed of raw
packets. The step of flow generation implies the packets
are grouped by 5-tuple. One may question that IP can be
either benign or malicious alternatively and then the classi-
fication on such data is meaningless. In this case, D-PACK
is a flow-based classifier, an IP source with both malicious
and benign flows does not affect D-PACK’s classification.
D-PACK will classify benign flows as benign and mali-
cious flows as malicious no matter what is the source IP.
30392 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
FIGURE 6. The architecture and workflow of D-PACK, including the preprocessing (left), training and auto-learning module (right).
FIGURE 7. The direct connection between one-dimensional CNN and
autoencoder through the hidden layers of the CNN model.
Also, n and l are referred to in Uniform Length Trimming.
To anonymize the source of the attack traffic, particularly in
the synthetic dataset, the identity information such as IP and
MAC addresses is randomized, while the same identity of all
the packets in the same flow is preserved. The next is the
detection model on the right-hand side, which consists of two
parts. The first part is the CNN for flow features extraction,
and the second is the autoencoder for classifying flows into
benign or malicious. The detailed design of the detection
model is illustrated in Fig. 7.
For classification, a threshold is set to distinguish benign
and malicious traffic based on the MSELoss distribution
of benign traffic. Note that, when detecting an attack,
theMSELossdistributiongeneratedbytheautoencodertrain-
ing set (i.e., benign flows) is used for determining the detec-
tion threshold. We hope that this design can reduce the
error caused by data dispersion and improve accuracy. Also,
MSELoss calculates the flow based on the blurred features,
FIGURE 8. The statistical results of benign and malicious classification
from CNN learning, including the MSELoss distribution of the testing set
(the red line is the threshold set by the classification).
and these features are treated as different vectors and put
into MSE to calculate loss attributes. To avoid the impact
of the extreme maximum value of the MSELoss, the maxi-
mum is compared with the 99th percentile of the MSELoss.
For threshold, if the difference between these two values
exceeds the triple standard deviation of the MSELoss distri-
bution, the 99th percentile is set as the detection threshold;
otherwise, the maximal MSELoss is set as the threshold.
To improve the classification performance, we also adopt the
approach to jointly optimize the loss functions of CNN and
autoencoder, as shown in Fig. 7. Fig. 8 illustrates an example
of the statistical results of MSELoss of benign and malicious
flows from autoencoder. The red line is the threshold set by
the above mechanism.
For the layer structure of the detection module, Table 5
shows the structural parameters of the design in detail.
VOLUME 8, 2020 30393
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 5. Structural parameters.
Note that the number of filters/neurons in the last layer
of CNN depends on the number of types of benign traf-
fic (e.g., 10 in the USTC-TFC2016 dataset), while the
other parameters are fixed for different traffic types. First,
the one-dimensional CNN filter gets the first l bytes of the
first n packets as the input (i.e., the input size is n × l); the
kernel size of the filter of the convolution layer is set to 6 (in
the header, the largest field is the MAC address). The hidden
layer (layer 5) in the CNN, connecting to the autoencoder
module, is used to learn the flow features. Specifically, layers
from 1 to 7 in Table 5 are the architecture of the CNN, and
layer 5 plus layers from 8 to 11 are the architecture of autoen-
coder. Summary, the structural parameters in Table 5 are the
parameters that we refer to the architecture mentioned in [18]
and improve them. Moreover, such parameters are what we
have found after many cross-validation and experiments.
Hyperparameters for tuning
The performance of the DL-based approaches is suscepti-
bletothechangesofthehyperparameterssuchasthelearning
rate. In this work, tuning the following parameters may sig-
nificantly help to improve the performance of the system.
1) n and l: As mentioned in Section III-A, these are the
key parameters for early detection while maintaining
high accuracy.
2) Batch normalization: Due to the depth of the deep
learning architecture, the batch normalization between
each layer can keep the parameter distribution stable,
accelerate the learning efficiency, ease the gradient
disappearance and avoid over-fitting.
3) Add additional dense layers for CNN: In general,
adding more hidden layers could improve the perfor-
manceofCNN.InourCNNarchitecture,itconsistsof3
hiddenlayers(layer5to7).Whatwehavelearnedfrom
our experiments is that adding the second layer with
size of 25 improves the performance significantly. Our
conjecture is that, besides the benefit of an additional
hidden layer, the size of 25 actually corresponds to the
number of header fields in a TCP/IP packet. Although
we may also encounter UDP/IP packets with fewer
header fields, from our observation, setting the size to
25 seems to be able to accommodate both TCP and
UDP packets.
4) All dense layers adopt layer-wise greedy pre-training
for initialization: The layer-wise greedy pre-training
design targets at mitigating the impact of vanishing
gradient problem and overfitting in the deep archi-
tecture. Fortunately, Unsupervised Greedy Layer-Wise
Pretraining model [32] genuinely works well with the
classification based on the autoencoder.
V. EVALUATION RESULTS
Similar to most existing deep learning research, our pro-
posed classification model has been implemented using
TensorFlow/Keras and Pytorch. The evaluations have been
allperformedontheGPU-enabledTensorFlow(Pytorch)run-
ning on a 64-bit Ubuntu 16.04 LTS server with an Intel Xeon
Silver 4116 CPU@2.10GHz, 256GB RAM, and NVIDIA
Tesla V100. We also use the Python package dpkt, a pcap
parser and creator, to convert the raw packets for training.
To perform the evaluations, we have sequentially tested
the system on USTC-TFC2016, Mirai-RGU, and Mirai-CCU
datasets (mentioned in Section IV-A). Training the model
is performed only on the benign traffic; however, to verify
the system on various conditions, the testing scenario will
involve three cases: the input data of only benign, benign
and malicious, and pure malicious traffic. Also, since our
approach aims to gain a significant reduction in the process-
ing time, we prefer to classify an incoming flow, whether
it is malicious or not, instead of considering its attack type
in detail. In practice, if the proposed system detects a mali-
cious flow, it will raise an alarm and redirect the packets to
some off-line computationally intensive traffic classification
systems for further analysis, while blocking the malicious
flow simultaneously. Therefore, in the following subsections,
several common metrics are used for performance evaluation
in terms of a binary classifier.
• True Positive (TP) – number of attack flows that are
correctly classified as an attack.
• False Positive (FP) – number of benign flows that are
incorrectly classified as an attack.
• True Negative (TN) – number of benign flows that are
correctly classified as normal.
• False Negative (FN) – number of attack flows that are
incorrectly classified as an normal.
The accuracy in Eq. 3 measures the proportion of the total
number of correct classifications. The precision, recall, and
F1-mesaurearedefinedinEq.4,Eq.5andEq.6,respectively.
The first two reflect the rate of correct classifications influ-
enced by incorrect ones, and the last is the overall measure
between the precision and the recall.
Accuracy =
TP + TN
TP + TN + FP + FN
(3)
Precision =
TP
TP + FP
(4)
Recall =
TP
TP + FN
(5)
30394 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
F1=
2TP
2TP + FP + FN
=
2 ∗ Precision ∗ Recall
Precision + Recall
(6)
The FAR in Eq. 7, also known as FPR, measures the rate
of benign flows incorrectly classified as malicious. The FNR
in Eq. 8 measures the rate of malicious flows incorrectly
classified as benign.
False Alarm Rate =
FP
FP + TN
(7)
False Negative Rate =
FN
TP + FN
(8)
In the following subsections, we present the detection
performance of D-PACK for three selected datasets in three
scenarios:theinputdatafortrainingandtestingcanconsistof
onlybenign,benignandmalicious,andpuremalicioustraffic.
In the first scenario, the classes and number of flows of the
training and testing sets are shown in Table 6. The training
data in the CNN and autoencoder module in this scenario
include only benign traffic. The testing data include benign
traffic from USTC-TFC 2016 and malicious traffic from
Mirai-CCU.
TABLE 6. Scenario 1: USTC-TFC 2016 (benign) and Mirai-CCU (malicious)
datasets.
In the case of auto-learning traffic features, the learning
performance of the CNN model on benign traffic is summa-
rized in the confusion matrix table in Fig. 9. The top number
in each cell of the confusion matrix is the number of flows
for testing in the benign traffic set. The learning module can
classify the benign traffic type with nearly 100% accuracy.
Table 7 shows the accuracy of D-PACK in the first testing
scenario, i.e., on the testing set A, which contains benign
flows from USTC-TFC 2016 and malicious flows from
Mirai-CCU. As we observe from Table 7, with only 40 bytes
per flow, the accuracy is nearly 100%. When the number
of packets per-flow and bytes per packet are increased for
inspection, e.g., 2 packets per-flow and 50 bytes per packet
or 3 packets per flow and 60 bytes per packet, the system can
achieve 100% accuracy, a very promising result. However,
we also notice that when we increase the number of packets
FIGURE 9. The learning performance of CNN for benign traffic.
TABLE 7. The accuracy of D-PACK running with various values of n and l
(scenario 1: testing set A).
TABLE 8. The performance of the framework in Scenario 1: testing set A
with n = 2 and l = 50.
per flow does not yield higher accuracy. This result indicates
inspecting more bytes per packet is better than more packets
per flow. This is promising for reducing the flow processing
timeaswellasthetraininganddetectingtime.Thebestresult
for the testing set A is with the configuration of n = 2 and
l = 50, which yields ideal performance, i.e., 100% accuracy
andnoFPR/FNR.Theperformancewiththefive-metricmea-
surements in this ideal case is presented in Table 8.
In the second scenario, the training data and testing data
are all from the USTC-TFC 2016 dataset. The ratio of benign
traffic in the training set and the testing set is 7:1, as shown
in Table 9. The malicious traffic only appears in the testing
set, making the ratio of the total amount of flows in the
training set and that of the testing set becomes 4:1. After
training, we have tested the system with the testing set B.
VOLUME 8, 2020 30395
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 9. Scenario 2: USTC-TFC 2016 dataset (both benign and malicious).
TABLE 10. The detection accuracy of running with variances of n and l
(testing set B).
Table 10 shows the system performance on the testing set
with variances of n and l. Compared with the first scenario,
the system gains better performance with the low values of n.
The performance with five metrics in Table 11 reinforces this
indication. However, similar to the previous case, increasing
the value of n and l does not mean that the system gets better
performance.
In the third scenario, the training and testing data are
from the Mirai-RGU dataset. Since this dataset classifies all
benign traffic into one type, namely, the normal type; thus,
we use both benign and malicious traffic to train the CNN,
but only the benign traffic to train the autoencoder, as shown
in Table 12. The testing data also include both benign and
malicious traffic from this dataset, as shown in the third
TABLE 11. The performance of the framework on the testing set B with
n = 2 and l = 50.
TABLE 12. Scenario 3: training and testing sets from Mirai-RGU.
TABLE 13. The detection accuracy when running with the Mirai dataset
for various values of n and l.
TABLE 14. Performance of the framework on the whole malicious traffic
with n = 2 and l = 80.
column of Table 12. The Mirai-RGU dataset contains nine
types of attack traffic with quite a variant number of flows.
The detection accuracy of running the framework on the
testing data with variances of n and l is shown in Table 13.
Compared with the first two scenarios, the performance is
slightly worse with the same configuration of n and l, but the
accuracyisstillhigherthan99.7%whentwopacketsper-flow
and more than 60 bytes per packet are examined. Moreover,
intheapplicationswhererecursivecommunicationsprobably
generate extremely long flows, the configuration (i.e., n =
2, l = 60) still gives the detection system significant advan-
tages in skipping tremendous traffic volume for processing.
Similar to the accuracy, the performance of the rest mea-
surements in this scenario also deteriorates slightly. In this
case, we set n = 2 and l = 80 for the sampling configuration.
The system gains nearly 99% for the first four measurements,
30396 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 15. Pre-processing capacity of our framework on various datasets.
while the FNR rises marginally but is still less than 1%,
as summarized in Table 14. The results reinforce our original
judgment that a well-designed learning strategy combined
with a slight adjustment of n,l may not significantly impact
the overall performance of the detection system while it
can significantly help to save traffic volume for processing
and speed up the detection. Admittedly, in the case of other
applications and datasets, e.g., malware binary, the values of
n and l can vary since their data structure for sampling may
need a tweak.
In summary, our experiments in all the scenarios demon-
strate that the performance of the proposed mechanism
either outperforms or is competitive to that of state-of-the-art
research works listed in Table 1.
A. TIME EFFICIENCY
The time efficiency in terms of the training time and the
detection time is also an important metric in our experiment.
The training time is the total time to complete the training
on the selected dataset. This time depends on the data pre-
processing, the training model (number of layers and dimen-
sions)andtheservercapacity.Therefore,itwouldbeunfairto
compare the execution with different hardware and software.
The pre-processing capacity of our system is summarized
inTable15.Thesystemcancapturethepackets,classifythem
into different flows, extract n packets per flow and discard
the rest with hundreds of thousands of the flows per second.
Sincethepre-processingtimeincludesreadingallthepackets
in the dataset, which demands much I/O time, and training
the deep learning model, which requires much CPU/GPU
processing time; thus, in some cases, it can only process tens
of thousands of flows. However, the pre-processing task shall
be done offline; thus, it is acceptable to have slightly longer
pre-processing time.
TABLE 16. Detection speed with different datasets.
Unlikethepre-processing,thedetectiononthesametraffic
type is supposed to be significantly faster because the clas-
sification can work on the raw traffic directly after training,
insteadofspendingtimeinthelearningtasks.Inourempirical
experiment, the detection can serve hundreds of thousands
of flows per second (as summarized in Table 16), no matter
which dataset it runs on. The processing capacity here is
defined as the total number of flows that can be classified
per second on a given testing dataset. With the processing
of hundreds of thousands of flows per second, our approach
can work for on-line monitoring since this speed can satisfy
most on-demand applications and in medium networks. For
the core networks, we may need more efforts to integrate this
system for potential deployment, since the network speed at
suchnodescanbeuptohundredsofgigabitspersecond.Note
that the system at the core networks can be equipped with
much more powerful hardware.
B. DISCUSSION
There is a trade-off between the number of trimmed pack-
ets, trimmed length, and the classification performance,
i.e., accuracy and detection time. Reducing the trimmed
length, e.g., from 80 bytes to 40 bytes, can potentially help
to reduce the detection time and the training time, but may
dramatically impact the accuracy. The accuracy also depends
on the considered attack type. In the evaluation, we found
that the ideal configuration is at n = 2 and l = 80.
However, promising research is to propose an algorithm to
VOLUME 8, 2020 30397
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
calculate a proper configuration automatically in a deployed
environment.
Moreover, the approach to consider the classification at
the packet level can open the door towards accelerating the
detection since we can schedule the packets for parallel pro-
cessing. However, the explicit shortcoming is to increase the
training time and resource usage (e.g., memory) due to a
large number of parameters and data size put into the training
model. Balancing the factor of acceptable training time but
still gaining high classification performance is a non-trivial
task and a potential research direction.
Finally, the DL-based classification approach is highly
susceptible to the data poisoning attack due to its depen-
dence on the training data. So far, we have found few attack
models targeting at evading the deep learning-based mali-
cious classification systems, including ours. However, this
can soon be changed when the popularity of deep learning
will attract more attackers to exploit its vulnerabilities for
hacking or monetization. Generating/preventing adversary
models against deep learning thus is a very interesting and
promising security research topic.
VI. CONCLUSION
In this work, we present a novel early malicious traffic detec-
tion framework, namely D-PACK, based on traffic sampling,
traffic auto-profiling (CNN), and an unsupervised DL model
(autoencoder). By targeting at examining as few packets and
numberofbytesfromeachpacketaspossible,oursystemcan
significantly reduce the traffic volume for processing. The
evaluation results show that D-PACK can detect malicious
traffic with nearly 100% accuracy and less than 1% FNR and
FPR,evenifitexaminesonlytwopacketsfromeachflowand
80 bytes from each packet. Moreover, it is supposed to con-
sume much less flow pre-processing time and detection time
than prior works because much fewer packets and bytes are
inspected. Thus, the important advantage of this framework
is to speed up the detection. We believe that this first attempt
can inspire the research community to consider further opti-
mization methods, particularly by exploiting the advantages
of deep learning to build effective online anomaly detection
systems without suffering significant detection delay.
REFERENCES
[1] M. Bacon. New Mirai Variant Attacks Apache Struts Vulnerability.
Accessed: Jun. 12, 2018. [Online]. Available: https://searchsecurity.
techtarget.com/news/252448779/New-Mirai-variant-attacks-Apache-
Struts-vulnerability
[2] S. Gatlan. Mirai Botnet Variants Targeting New Processors and
Architectures. Accessed: Apr. 9, 2019. [Online]. Available: https://www.
bleepingcomputer.com/news/security/mirai-botnet-variants-targeting-
new-processors-and-architectures
[3] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, ‘‘DDoS in the IoT:
Mirai and other botnets,’’ Computer, vol. 50, no. 7, pp. 80–84, 2017.
[4] R. Hallman, J. Bryan, G. Palavicini, J. Divita, and J. Romero-Mariona,
‘‘IoDDoS the Internet of distributed denial of service attacks—A case
study of the mirai malware and IoT-based botnets,’’ in Proc. 2nd Int. Conf.
Internet Things, Big Data Secur., vol. 1, 2017, pp. 47–58.
[5] P. Zilberman, R. Puzis, and Y. Elovici, ‘‘On network footprint of traffic
inspection and filtering at global scrubbing centers,’’ IEEE Trans. Depend.
Sec. Comput., vol. 14, no. 5, pp. 521–534, Sep. 2017.
[6] M. H. Bhuyan, D. K. Bhattacharyya, and J. K. Kalita, ‘‘Network anomaly
detection: Methods, systems and tools,’’ IEEE Commun. Surveys Tuts.,
vol. 16, no. 1, pp. 303–336, 2014.
[7] A. L. Buczak and E. Guven, ‘‘A survey of data mining and machine
learning methods for cyber security intrusion detection,’’ IEEE Commun.
Surveys Tuts., vol. 18, no. 2, pp. 1153–1176, 2016.
[8] S. Valenti, D. Rossi, A. Dainotti, A. Pescap, A. Finamore, and M. Mellia,
‘‘Reviewing traffic classification,’’ in DataTraffic Monitoring and Analy-
sis. Cham, Switzerland: Springer, 2013, pp. 123–147.
[9] E. Min, J. Long, Q. Liu, J. Cui, and W. Chen, ‘‘TR-IDS: Anomaly-based
intrusion detection through text-convolutional neural network and random
forest,’’ Secur. Commun. Netw., vol. 2018, pp. 1–9, Jul. 2018.
[10] W. Wang, M. Zhu, J. Wang, X. Zeng, and Z. Yang, ‘‘End-to-end encrypted
traffic classification with one-dimensional convolution neural networks,’’
in Proc. IEEE Int. Conf. Intell. Secur. Informat. (ISI), Jul. 2017, pp. 43–48.
[11] D. Berman, A. Buczak, J. Chavis, and C. Corbett, ‘‘A survey of deep
learning methods for cyber security,’’ Information, vol. 10, no. 4, p. 122,
Apr. 2019.
[12] E. Min, J. Long, Q. Liu, J. Cui, Z. Cai, and J. Ma, ‘‘SU-IDS: A semi-
supervised and unsupervised framework for network intrusion detection,’’
in Proc. 4th Int. Conf. Cloud Comput. Secur., 2018, pp. 322–334.
[13] Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky, D. Breitenbacher,
A. Shabtai, and Y. Elovici, ‘‘N-BaIoT: Network-based detection of IoT
botnet attacks using deep autoencoders,’’ IEEE Pervas. Comput., vol. 17,
no. 3, pp. 11–22, Jul./Sep. 2018.
[14] W. Wang, Y. Sheng, J. Wang, X. Zeng, X. Ye, Y. Huang, and M. Zhu,
‘‘HAST-IDS: Learning hierarchical spatial-temporal features using deep
neural networks to improve intrusion detection,’’ IEEE Access, vol. 6,
pp. 1792–1806, 2018.
[15] G. Aceto, D. Ciuonzo, A. Montieri, and A. Pescape, ‘‘Mobile encrypted
traffic classification using deep learning: Experimental evaluation, lessons
learned, and challenges,’’ IEEE Trans. Netw. Serv. Manage., vol. 16, no. 2,
pp. 445–458, Jun. 2019.
[16] M. Al-Qatf, Y. Lasheng, M. Al-Habib, and K. Al-Sabahi, ‘‘Deep learning
approach combining sparse autoencoder with SVM for network intrusion
detection,’’ IEEE Access, vol. 6, pp. 52843–52856, 2018.
[17] L. Vu, C. T. Bui, and Q. U. Nguyen, ‘‘A deep learning based method for
handling imbalanced problem in network traffic classification,’’ in Proc.
8th Int. Symp. Inf. Commun. Technol. (SoICT), 2017, pp. 333–339.
[18] W. Wang, M. Zhu, X. Zeng, X. Ye, and Y. Sheng, ‘‘Malware traffic clas-
sification using convolutional neural network for representation learning,’’
in Proc. Int. Conf. Inf. Netw. (ICOIN), 2017, pp. 712–717.
[19] Z. Chen, K. He, J. Li, and Y. Geng, ‘‘Seq2Img: A sequence-to-image
based approach towards IP traffic classification using convolutional neural
networks,’’ in Proc. IEEE Int. Conf. Big Data (Big Data), Dec. 2017,
pp. 1271–1276.
[20] M. Lotfollahi, M. J. Siavoshani, R. S. H. Zade, and M. Saberian, ‘‘Deep
packet: A novel approach for encrypted traffic classification using deep
learning,’’ Soft Comput., vol. 24, no. 3, pp. 1999–2012, Feb. 2020.
[21] M. Lopez-Martin, B. Carro, A. Sanchez-Esguevillas, and J. Lloret, ‘‘Net-
work traffic classifier with convolutional and recurrent neural networks for
Internet of Things,’’ IEEE Access, vol. 5, pp. 18042–18050, 2017.
[22] J. Hochst, L. Baumgartner, M. Hollick, and B. Freisleben, ‘‘Unsupervised
traffic flow classification using a neural autoencoder,’’ in Proc. IEEE 42nd
Conf. Local Comput. Netw. (LCN), Oct. 2017, pp. 523–526.
[23] I. Arnaldo, A. Cuesta-Infante, A. Arun, M. Lam, C. Bassias, and
K. Veeramachaneni, ‘‘Learning representations for log data in cyberse-
curity,’’ in Proc. Int. Conf. Cyber Secur. Cryptogr. Mach. Learn., 2017,
pp. 250–268.
[24] Y. Yu, J. Long, and Z. Cai, ‘‘Network intrusion detection through stacking
dilated convolutional autoencoders,’’ Secur. Commun. Netw., vol. 2017,
pp. 1–10, Nov. 2017.
[25] Y.Li,R.Ma,andR.Jiao,‘‘Ahybridmaliciouscodedetectionmethodbased
ondeeplearning,’’Int.J.Secur.Appl.,vol.9,no.5,pp.205–216,May2015.
[26] V. Paxson and S. Floyd, ‘‘Wide area traffic: The failure of Poisson model-
ing,’’ IEEE/ACM Trans. Netw., vol. 3, no. 3, pp. 226–244, Jun. 1995.
[27] B. Hullar, S. Laki, and A. Gyorgy, ‘‘Efficient methods for early pro-
tocol identification,’’ IEEE J. Sel. Areas Commun., vol. 32, no. 10,
pp. 1907–1918, Sep. 2014.
[28] G. Maier, R. Sommer, H. Dreger, A. Feldmann, V. Paxson, and
F. S Hneider, ‘‘Enriching network security analysis with time travel,’’
SIGCOMM Comput. Commun. Rev., vol. 38, no. 4, p. 183, Oct. 2008.
30398 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
[29] S. Albawi, T. A. Mohammed, and S. Al-Zawi, ‘‘Understanding of a
convolutional neural network,’’ in Proc. Int. Conf. Eng. Technol. (ICET),
Aug. 2017, pp. 1–6.
[30] R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi,
‘‘Microsoft malware classification challenge,’’ 2018, arXiv:1802.10135.
[Online]. Available: http://arxiv.org/abs/1802.10135
[31] C. D. Mcdermott, F. Majdani, and A. V. Petrovski, ‘‘Botnet detection in
the Internet of Things using deep learning approaches,’’ in Proc. Int. Joint
Conf. Neural Netw. (IJCNN), Jul. 2018, pp. 1–8.
[32] P. L. Y. Bengio, D. Popovici, and H. Larochelle, ‘‘Greedy layer-wise
training of deep networks,’’ in Proc. 19th Int. Conf. Neural Inf. Process.
Syst. (NIPS), 2006, pp. 153–160.
REN-HUNG HWANG (Senior Member, IEEE)
received the Ph.D. degree in computer science
from the University of Massachusetts, Amherst.
He joined the Department of Computer Science
and Information Engineering, National Chung
Cheng University (CCU), in 1993, where he is
currently a Distinguished Professor. He has pub-
lished more than 200 international journals and
conference papers. He has served as the Dean for
the College of Engineering, from 2014 to 2017.
He has received the IEEE Outstanding Paper Award from the IEEE UIC
2012, and the IEEE Best Paper Award from the IEEE IUCC 2014, the IEEE
SC2 2017, and the IEEE Ubi-Media 2018. His current research interests
include the Internet of Things, network security, cloud/edge/fog computing,
and software-defined networks.
MIN-CHUN PENG is currently pursuing the
Ph.D. degree with the Department of Computer
Science and Information Engineering, National
Chung Cheng University, Chiayi, Taiwan. His
research interests include information security and
deep learning, deep learning, cloud computing,
the Internet of Things, and information security.
CHIEN-WEI HUANG is currently pursuing the
master’s degree with the Department of Computer
Science and Information Engineering, National
Chung Cheng University, Chiayi, Taiwan. He is
working on L2, L3 network protocol. His research
interests include information security and deep
learning.
PO-CHING LIN received the Ph.D. degree in
computer science from National Chiao Tung Uni-
versity, Hsinchu, Taiwan, in 2008. He joined the
Department of Computer Science and Information
Engineering, National Chung Cheng University
(CCU), in August 2009, as a Faculty Member,
where he is currently an Associate Professor. His
research interests include network security, net-
work traffic analysis, and performance evaluation
of network systems.
VAN-LINH NGUYEN (Member, IEEE) received
the Ph.D. degree in computer science and infor-
mation engineering from National Chung Cheng
University (CCU), Taiwan, in 2019. He is cur-
rently an Assistant Professor with the Depart-
ment of Information Technology, TNU-University
of Information and Communication Technology,
Vietnam. His research interests include network
security, vehicular security, the Internet of Things,
deep learning, and edge computing.
VOLUME 8, 2020 30399
Received January 10, 2020, accepted February 5, 2020, date of publication February 10, 2020, date of current version February 18, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2973023
An Unsupervised Deep Learning Model for Early
Network Traffic Anomaly Detection
REN-HUNG HWANG
1,2 , (Senior Member, IEEE), MIN-CHUN PENG 1 , CHIEN-WEI HUANG 1 ,
PO-CHING LIN
1 , AND VAN-LINH NGUYEN 1,3 , (Member, IEEE)
1 Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi 62102, Taiwan
2 Advanced Institute of Manufacturing With High-Tech Innovations, National Chung Cheng University (CCU), Chiayi 62102, Taiwan
3 Department of Information Technology, TNU-University of Information and Communication Technology, Thai Nguyen 24119, Vietnam
Corresponding author: Van-Linh Nguyen (nvlinh@ictu.edu.vn)
This work was supported in part by the Advanced Institute of Manufacturing With High-Tech Innovations (AIM-HI) from the Featured
Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in
Taiwan, in part by the Ministry of Science and Technology of Taiwan, R.O.C. under Grant MOST 107-2218-E-194-014,
Grant 108-2221-E-194-022-MY3, and Grant MOST 108-2221-E-194-019-MY3, in part by the Taiwan Information Security Center,
National Sun Yat-sen University, under Grant TWISC@NSYSU, and in part by the TNU-University of Information and Communication
Technology, Vietnam.
ABSTRACT Various attacks have emerged as the major threats to the success of a connected world like
the Internet of Things (IoT), in which billions of devices interact with each other to facilitate human life.
By exploiting the vulnerabilities of cheap and insecure devices such as IP cameras, an attacker can create
hundreds of thousands of zombie devices and then launch massive volume attacks to take down any target.
For example, in 2016, a record large-scale DDoS attack launched by millions of Mirai-injected IP cameras
and smart printers blocked the accessibility of several high-profile websites. To date, the state-of-the-art
defense systems against such attacks rely mostly on pre-defined features extracted from the entire flows
or signatures. The feature definitions are manual, and it would be too late to block a malicious flow after
extracting the flow features. In this work, we present an effective anomaly traffic detection mechanism,
namely D-PACK, which consists of a Convolutional Neural Network (CNN) and an unsupervised deep
learning model (e.g., Autoencoder) for auto-profiling the traffic patterns and filtering abnormal traffic.
Notably, D-PACK inspects only the first few bytes of the first few packets in each flow for early detection.
Our experimental results show that, by examining just the first two packets in each flow, D-PACK still
performs with nearly 100% accuracy, while features an extremely low false-positive rate, e.g., 0.83%. The
design can inspire the emerging efforts towards online anomaly detection systems that feature reducing the
volume of processed packets and blocking malicious flows in time.
INDEX TERMS IoT security, anomaly detection, convolutional neural network, autoendcoder, online
DL-based anomaly detection.
I. INTRODUCTION
In recent years, with increasingly massive IoT applications
and connected devices, distributed denial-of-service (DDoS)
attacks have caught the attention of the security community
with a series of record-high attack magnitude. Given a small
proportion of billions of IoT devices, e.g., cheap and insecure
IPcameras,injectedtobezombies,anadversarycangenerate
a massive volume of flooding traffic to take down a target
suchasacriticalInternetservice.Althoughthiskindofattack
is by no means new, it still poses a tremendous threat to most
The associate editor coordinating the review of this manuscript and
approving it for publication was Fan Zhang.
state-of-the-art defense systems [1]–[4]. To stop malicious
traffic, including that from DDoS attacks, the first step is to
detect traffic anomaly as soon as possible by analyzing net-
work traffic atthe gateways, at edgeservers, or in ascrubbing
center [5].
To date, existing approaches such as signature-based
and statistical detection systems still have several flaws,
e.g., the rule maintenance cycle cannot keep up with
soaring attack variants [3]. When the ecosystem of
Internet-connected systems expands and the diversity of IoT
devices increases rapidly, it is inevitable that there are more
potential vulnerabilities for an attacker to exploit. As a result,
a signature-based detection system, which may be able to
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/
30387
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
detect well-known attacks with high accuracy, can quickly
lose its advantage because unknown attacks may appear
nearly per minute [1], [2]. Dealing with the explosion of the
attackvariants,theanomalydetectionapproaches,asopposed
to the signature-based ones, can significantly help. Unlike
signature-based approaches, anomaly detection systems can
monitor network flows and classify them as either normal
or anomalous ones; thus, new attack variants are less likely
to bypass the detection. Nonetheless, anomaly detection
approaches often face high false alarm rates, since the sys-
tems must be taught to recognize normal activities [6]. So far,
such systems are often designed with strict mathematical
models and a set of predefined features [7]. Fortunately, deep
learning (DL) promises to be the game-changer to help to
solve the learning problem, i.e., automatically building the
traffic profile. The most benefit of deep learning is to build
a thorough pattern that can precisely characterize specific
objects through automatically learning a large volume of data
and species.
DL-based approaches have been well investigated in many
fields over the years, including anomaly detection. How-
ever, many challenges remain, e.g., speeding up the detection
and auto-profiling the traffic patterns effectively, which are
also the target of this work. From the design perspective,
the detection systems should characterize normal network
flows and define well-represented traffic profiling. Based on
this profiling, the systems can identify and isolate anomalous
network activities. In the literature, the common profiling
method is building a pre-defined list of features [6], [8] from
flow statistics, e.g., sending rate, packet count or flow size,
and then using the DL models such as a convolutional neural
network (CNN) for learning [9]. However, defining a list
of well-represented features manually for effective learning
poses tremendous challenges, e.g., labor time, particularly if
the network has a diversity of application traffic. Recently,
a promising approach is to use CNN to automatically extract
such features directly from raw traffic, instead of from the
summarized data, e.g., [10]. In this work, we go further in
building the traffic patterns (e.g., of benign applications) by
examining only the first few bytes of the first few packets of
the flows. This approach promises to have many advantages,
particularly for online anomaly detection systems. For exam-
ple, the detection does not need to waste remarkable compu-
tation and time for checking redundant data and storage in
a whole long session, while a few first packets of the flows
are sufficient for the detection. As a result, our system has
a significant advantage of speeding up the detection. Note
that summarizing the traffic in a flow-based approach may
demand much memory space for flow tracking in a large
network, particularly if many long flows exist.
The proposed system, namely D-PACK, consists of two
main parts: (1) A CNN module is designed for auto-learning
the features from the raw data; (2) An unsupervised DL
model(autoencoder)trainedwiththeoutputdataof(1)targets
at building the profile of benign traffic and then precisely
judge whether the traffic in the examined flows is abnormal.
The experimental results show that D-PACK is competitive
and prominently outperforms prior studies in terms of accu-
racy, precision, recall, and F1-measure. Specifically, it can
detect malicious traffic with nearly 100% accuracy and less
than 1% FNR and FPR, even if it examines only two packets
from each flow and 80 bytes from each packet. To train the
system with the normal traffic characteristics and activities,
thetrainingissettorunatthetimeofdeployingthedevicesto
ensure the devices are in the clean state before any possible
compromising. The detection is also deployed close to the
devices (i.e., the traffic sources) to identify traffic anomaly.
In summary, the main contributions of this work are as
follows:
• We propose a CNN-based deep learning approach for
auto-learning the traffic features and profiling traffic
directly from the raw traffic with only a few first packets
per flow. Following this, the auto-learning approach can
significantly save the efforts to build traffic patterns for
a complex network where the diversity of application
traffic is the major challenge to conventional methods.
• We implement the proposal and evaluate it with both the
credible datasets and self-collected realistic ones. The
evaluationwiththedatasetsfrommultiplesourcesshows
that D-PACK can achieve nearly 100% accuracy and
precision in detecting malicious packets.
• Our design on packet-based deep learning classifica-
tion and detection promise to provide valuable informa-
tion and inspire the research community to overcome
the remaining challenges, particularly for speeding up
online DL-based anomaly detection.
The remainder of this paper is organized as follows.
Section II surveys the state-of-the-art work on traffic classi-
fication and deep learning detection approaches. Section III
presents our learning strategy and the detailed structure of
the auto-building traffic profile module, the key features
of this work. Our selected datasets and the detail of the
D-PACK framework are presented in Section IV. We show
the experimental design and results in Section V. Finally,
theconclusionandfutureworkaresummarizedinSectionVI.
II. RELATED WORK
The issue of detecting malicious network traffic has been
studiedextensively.Themainstreamapproachesfallintofour
primary classes [8]: port-based/rule-based, deep/stochastic
packet inspection, statistical, and behavioral techniques.
While the first three approaches are common and gain
high performance in intrusion detection over decades, it is
expected to see a silver lining with the rising trend of deep
learning to overcome the known flaws of existing studies,
particularlyinthelastapproach.Fromtheevaluationperspec-
tive, the behavioral approach may have poor performance at
several metrics, e.g., high false alarm, due to the complexity
of benign traffic profiling and the definition of ‘normal’
network activities.With thepotential of accumulatingknowl-
edge from large-scale raw data without manual interference,
deep learning is an effective approach to improve anomaly
30388 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 1. Summary of related anomaly detection strategies.
detection in the future [11]. In Table 1, we summarize several
well-known state-of-the-art DL-based traffic classification
methods, their performance on common datasets, and then
address our research position.
As shown in Table 1, most works are in favor of using
CNN/autoencoder to build the traffic classifier for anomaly
detection. Notably, these approaches rely on a set of prede-
fined features, e.g., statistical features [9], [16], [25], for data
preprocessing. However, the DL techniques in these systems
are supposed to vary due to the different interests in address-
ingspecificapplicationsanddefensestrategies [15], [21].For
example, the authors in [18], [20] select CNN for extracting
the features from the packet headers and payloads. Autoen-
coder,ontheotherhand,isproperfortrainingontheextracted
features [12], [16], [22]. Also, the bias and imbalance of
the traffic classes in the training datasets are a key factor to
motivate the authors to select a proper DL model. Finally,
while Table 1 reflects no quantitative measurement of which
method is better due to their different usages in the datasets
and further different metrics for evaluation, our summary
here aims to give an overview of the dominant trends of
applying DL for anomaly detection.
Unlikepriorresearch,wepursueanovelapproachtodetect
traffic anomaly. Instead of collecting the entire traffic flows
for finding the evidence of abnormal behavior, we pack the
first several packets per flow into segments of fixed lengths,
e.g.,80bytes.Thegoalistobuildasubsetofthedataandtrain
only on this trimmed version. This approach significantly
reduces the computation and memory space to process the
session flows, particularly the long ones. A closely related
work to ours is [13], in which the authors first collected
both normal and malicious traffic from an IoT environment
with devices infected by Bashlite and Mirai. The traffic is
trimmed by various time scales for experimental purposes,
including 100ms, 500ms, 1.5sec, 10sec, and 1min time win-
dows.Foreachtimewindow,asetofpre-defined23flowfea-
tures are extracted as the input to the autoencoder. However,
themethodstillconsumesquitemuchtimesincethesampling
is performed on the offline data and extracting the features is
an independent pre-processing step. In contrast, in this work,
we build a CNN model for auto-learning the features and
the sampling targets at just several packets per flow (instead
of sampling the whole flows at several check time points).
Compared with prior studies, this work features two major
differences: (1) D-PACK can build the profile of the traffic
by examining the first packets per flow, instead of checking
the total packets in the flows; (2) D-PACK can work directly
with raw packets (after data sanitization), i.e., building the
patterns, reading the input data and making the detection
decision. Finally, we believe that a detection approach by
trimming the data for inspection like ours is competitive with
the high detection accuracy achieved by prior studies for
VOLUME 8, 2020 30389
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
FIGURE 1. Illustration of the sampling to extract the segment of the first
3 packets from a flow of 10 packets.
the same attack types. This approach can motivate further
research on optimizing and accelerating the processing in
early anomaly detection systems.
III. LEARNING STRATEGY FOR EARLY CLASSIFICATION
AND DETECTION
This section gives an overview of the learning strategy that
targets at building a thorough traffic profile while dramati-
cally reduces the data volume for processing. This mecha-
nism also makes early anomaly detection possible, which is
the key feature of this work.
A. SAMPLING NETWORK FLOWS
The traffic volume can be enormous in a high-speed net-
work; thus, it is important to reduce a load of packet
capturing and analysis on the detection function for high
efficiency. According to the heavy-tailed nature of Internet
traffic [26], it was reported that keeping only a small por-
tion of each flow is sufficient for protocol identification or
retrospective analysis while reducing the total traffic volume
significantly [27], [28]. Therefore, we consider sampling the
flowsbyextractingthefirstnpacketsofeach,andeachpacket
is trimmed into a fixed length of l bytes, starting with the
header fields (with zero-padding if necessary; see the next
subsection for the detail). Note that the raw packets of a
flow is classified based on their 5-tuple information (source
IP, source port, destination IP, destination port, and transport
layer protocol). n and l may be flexibly adjusted according to
the network traffic characteristics at the time of deployment.
This sampling can significantly reduce the total amount of
traffic in the analysis, while the characteristics of the packets
are still representative to reveal whether the associated flows
are malicious or not for early anomaly detection. Our sam-
pling workflow is illustrated as Fig. 1.
As an example in Fig. 1, a flow consists of ten packets, and
we inspect only the first three packets and trim their lengths.
Since only several packets per flow are examined, the system
can inspect significantly fewer data in total, like the results
from in [27], [28]. This saving is even much more if the flow
is part of a long session. Notably, this saving is essential for
a system that requires early detection.
After the data extraction (from pcap) with trimming,
the next step is to read the data and form an understandable
format for the learning task. Since a DL system cannot be
fed with data of different lengths, short packets are padded
with zeros. We view the trimmed bytes in each flow as a
one-dimensional vector with n × l elements, and turn them
into the input of the CNN model for training. Like major DL
studies, a step of trace sanitization is also used to eliminate
the errors and repeated traffic.
B. AUTO-BUILDING THE TRAFFIC PROFILE
Building the pattern of benign traffic is the next important
task. Compared with traditional methods that extract traffic
features manually, an auto-learning approach does not con-
tain independent modules such as feature extraction and fea-
ture selection. The features are automatically learned, and the
traffic is directly passed to the classifier. Therefore, the non-
linear relationship between the raw input and the expected
output is determined, partially achieving the goal of end-
to-end learning.
To date, CNN has been mainly applied in the domain of
computer vision, e.g., image classification [29]. Recently,
there are also successful applications in the field of natural
language processing (NLP) [7], [11]. CNN is most suitable
for the kinds of data in the form of multiple arrays or the ones
with strong local correlations or whose features can appear
anywhere, even in which objects are invariant to translations
and distortions [19]. Specifically, 1D-CNN is good for data
like sequential data or language [7], [11]. 2D-CNN is good
for data like images. 3D-CNN is good for data like video or
volumetric images. 1D-CNN is also widely used for network
traffic analysis, e.g., [19], including this work.
It is common to visualize the extracted bytes from each
flow as the pixels of two-dimensional (grayscale) images
like those in Fig. 2, and then to apply 2D-CNN to traffic
classification. The authors [24] use this approach, although
they prefer to use a stacked auto-encoder (SAE) other than
2D-CNN. However, since a flow may consist of more than
one packet, a 2D-CNN filter may cover a region of irrelevant
bytes from two packets or more (e.g., the bytes in adjacent
rows of pixels are semantically irrelevant). Inspired by this
fact, our auto-profiling module is built on a 1D-CNN model
(i.e.,theinputtoCNNisaone-dimensionalimage).Asimilar
approach was taken in [18], but this work differs from theirs:
we set a fixed number of packets and bytes taken from a flow
to formthe one-dimensional image,regardless of whetherthe
bytes are from one or multiple packets.
FIGURE 2. Visualization of the traffic types in our dataset (Mirai-CCU).
The detail will be described in section IV.
The architecture of the 1D-CNN model is illustrated as
in Fig. 3. We assume that the first n packets per flow are
sampled, and each sampled packet is trimmed into the first
l bytes (primarily in the packet header). The data are padded
30390 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
FIGURE 3. CNN model for auto-building the traffic profile.
withzerosifthenumberofpacketsislessthannorthepacket
size is less than l bytes. Let p i be the ith packet after the
above trimming. The one-dimensional image is composed
of the bytes in p 1 ||p 2 ||...||p n as the input, where || is the
concatenation operator.
Let x i be a window of s bytes beginning from the ith byte
oftheinput,wherei = 1,...,n×l−s+1.Intheconvolution
operations, let m be the number of filters to be applied to the
input x i to produce a new feature. As a result, a feature h k
i
from the kth filter to the window x i is generated by
h k
i
= f (W k x i + b k ), (1)
where f is a ReLU function [18], W k is the weight vector
of the kth filter, and b k is a bias term or the offset of the
kth filter. The above parameters in this work will be summa-
rizedinTable5.Notethateachfilterisappliedtothepossible
windows of s bytes in the input to produce a feature map
(assuming the stride is 1 in Eq. 2):
h = [h 1 ,h 2 ,...,h nl−s+1 ]. (2)
We then apply a max-over-time pooling operation over the
feature map and take the maximum value max(h) as the
feature in the next layer. In this work, we use multiple
convolution layers and pooling layers to extract high-level
features. These features form the layer and are passed to a
fully connected dense layer whose output is the probability
distribution of the type of benign flows (e.g., Gmail, Skype).
It is noted that increasing the parameter n may offer more
statistical characteristics about the flow, but pours more data
into the system. The evaluation in Section V reveals clearly
this relationship. In this work, we attempt to use as few
packets as possible while still guarantee detection accuracy.
Therefore, the ideal configuration of n and l is the threshold
in which the system performance is balanced among several
measurements, e.g., high accuracy and low traffic volume for
processing. We found in the empirical experiments that, with
n = 2 and l = 80, the system can attain this target on most
of the selected datasets (see Section V).
In this work, we run the model on benign traffic to build
the traffic profile for the binary classifier, i.e., to classify
whether the flows are from benign traffic or not. In this case,
autoencoderisusedasthebinaryclassifier.Anexampleofthe
distribution of benign/malicious packets after binary classifi-
cation from our autoencoder is illustrated in Fig. 4. Notably,
the hidden layers of the learning module are designed to
connect directly with the input layers of the autoencoder
FIGURE 4. Packet distribution after binary classification, from left to
right: the normal traffic distribution, malicious traffic distribution and
common distribution.
network (see Section IV-B). This connection significantly
helps to achieve the goal of end-to-end learning, since the
learning and classification are under a connected and unified
DL network.
In summary, besides the auto-learning ability of the CNN
model on the raw packets, the learning strategy, along with
the sampling procedure to shorten the data for processing,
plays a decisive role in computation reduction and early
detection. Moreover, with the adjustable parameters, n and l,
the administrator can adjust the proper thresholds to balance
learning from as many features of the traffic as possible and
satisfyingthelimitedsystemresourcesorthedetectionspeed.
The effectiveness of this approach is revealed in Section V.
IV. AN UNSUPERVISED DEEP LEARNING MODEL
FOR EARLY ANOMALY DETECTION
Inthissection,wefirstcoverthedetailofourselecteddatasets
and then the architecture of the D-PACK detection frame-
work. The strategy for tuning the parameters to improve the
performance is also described.
A. DATASET
Lack of a variety of shareable traces dataset has hin-
dered the progress in traffic classification by deep learn-
ing. Researchers may create synthetic datasets through their
testbed, but the generated traffic may not reflect the Internet
traffic faithfully. Thus, the evaluation based on such traces
may not be credible. Over the decades, researchers have
been tempted to use famous public traffic datasets such as
KDD CUP 99 and NSL-KDD. The datasets provide useful
statistics on labeled features and both benign and malicious
flows as well, but they do not provide information at the
raw packet level, which is required in our approach. Also,
while the credible dataset from Microsoft Malware Classi-
fication Challenge [30] can provide a metadata manifest and
hexadecimal representation of the binary content of malware,
missing packet information in the data, unfortunately, makes
it unusable in this work.
USTC-TFC2016 [18] is a prominent dataset that matches
our requirements. Table 2 summarizes the statistics of benign
andmalicioustrafficinthedataset.Pertheirstatement,totally
ten types of malware traffic were collected from public web-
sitesinarealnetworkenvironmentfrom2011to2015.Along
with such malicious traffic, the benign part contains ten types
of normal traffic collected using IXIA BPS, a professional
VOLUME 8, 2020 30391
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 2. Summary of benign and malware traffic in
USTC-TFC2016 dataset.
network traffic simulation equipment. The size of this dataset
is 3.71GB in the pcap format.
For the Mirai-based DDoS traffic, we use the dataset from
Robert Gordon University, denoted by Mirai-RGU, and its
statisticsareshowninTable3.Thereadersarereferredto[31]
for the testbed used to collect the dataset. This dataset con-
tains Mirai botnet traffic such as scan, infect, control, attack
traffic, and normal IP camera traffic. The Mirai botnet traffic
consists of four main attack types: UDP flood, ACK flood,
DNS flood, and SYN flood attacks. The dataset includes
features such as time, source, destination, protocol, length,
and overall payloads.
TABLE 3. Summary of benign and malicious traffic by packet count in the
Mirai-RGU dataset [31].
In order to enrich the traffic activities and identify the
attack traffic, we have built a Mirai botnet in the campus of
NationalChungChengUniversity(CCU)fortesting(denoted
by Mirai-CCU), as shown in Fig. 5. The C&C server controls
sevenIoTdevices(i.e.,WiFiaccesspoints)andcollectsallthe
DDoSattacksfromMirai.Despitethesmalltestbed,weargue
that the detection performance in the experiments does not
deviate from that in a large testbed because the detection
refers only to the first few bytes in the first few packets of the
flows as the features, instead of the number of flows, packets
FIGURE 5. The testbed of our Mirai-based DDoS dataset in the campus of
National Chung Cheng University (CCU), in which the Mirai botnet is at
the WiFi APs in the bottom.
orbytesoveragivenperiodoftime.Itisimportanttonotethat
reproducing a large-scale Mirai-based botnet would be costly
and probably illegal; thus, we do not resort to that alternative.
The collected dataset consists of four DDoS attack types:
SYN flood, UDP flood, ACK flood, and HTTP flood. The
dataset covers over 304K malicious flows and its size is
277.1GB. Table 4 summarizes the collection of these four
types. Like [18], we also visualize these four attack types
in Fig. 2. For each type of attack, we randomly select nine
flows, and for each flow, a 2D grayscale image of 20*25 is
produced by selecting the first 100 bytes of the first five
packets (i.e., totally 500 bytes in a flow). Fig. 2 shows that
the same type of flows are similar in the visualization, but are
quite different between different flows.
TABLE 4. Mirai DDoS types collected in our testbed, namely Mirai-CCU.
B. UNSUPERVISED DL-BASED ANOMALY
DETECTION ARCHITECTURE
Fig. 6 shows the schematic diagram of the D-PACK frame-
work. After the pre-processing (left side), CNN is used
to automatically extract the flow features by classifying
flows into different types, e.g., 10 types in the USTC-
TFC2016 dataset. The network traffic is composed of raw
packets. The step of flow generation implies the packets
are grouped by 5-tuple. One may question that IP can be
either benign or malicious alternatively and then the classi-
fication on such data is meaningless. In this case, D-PACK
is a flow-based classifier, an IP source with both malicious
and benign flows does not affect D-PACK’s classification.
D-PACK will classify benign flows as benign and mali-
cious flows as malicious no matter what is the source IP.
30392 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
FIGURE 6. The architecture and workflow of D-PACK, including the preprocessing (left), training and auto-learning module (right).
FIGURE 7. The direct connection between one-dimensional CNN and
autoencoder through the hidden layers of the CNN model.
Also, n and l are referred to in Uniform Length Trimming.
To anonymize the source of the attack traffic, particularly in
the synthetic dataset, the identity information such as IP and
MAC addresses is randomized, while the same identity of all
the packets in the same flow is preserved. The next is the
detection model on the right-hand side, which consists of two
parts. The first part is the CNN for flow features extraction,
and the second is the autoencoder for classifying flows into
benign or malicious. The detailed design of the detection
model is illustrated in Fig. 7.
For classification, a threshold is set to distinguish benign
and malicious traffic based on the MSELoss distribution
of benign traffic. Note that, when detecting an attack,
theMSELossdistributiongeneratedbytheautoencodertrain-
ing set (i.e., benign flows) is used for determining the detec-
tion threshold. We hope that this design can reduce the
error caused by data dispersion and improve accuracy. Also,
MSELoss calculates the flow based on the blurred features,
FIGURE 8. The statistical results of benign and malicious classification
from CNN learning, including the MSELoss distribution of the testing set
(the red line is the threshold set by the classification).
and these features are treated as different vectors and put
into MSE to calculate loss attributes. To avoid the impact
of the extreme maximum value of the MSELoss, the maxi-
mum is compared with the 99th percentile of the MSELoss.
For threshold, if the difference between these two values
exceeds the triple standard deviation of the MSELoss distri-
bution, the 99th percentile is set as the detection threshold;
otherwise, the maximal MSELoss is set as the threshold.
To improve the classification performance, we also adopt the
approach to jointly optimize the loss functions of CNN and
autoencoder, as shown in Fig. 7. Fig. 8 illustrates an example
of the statistical results of MSELoss of benign and malicious
flows from autoencoder. The red line is the threshold set by
the above mechanism.
For the layer structure of the detection module, Table 5
shows the structural parameters of the design in detail.
VOLUME 8, 2020 30393
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 5. Structural parameters.
Note that the number of filters/neurons in the last layer
of CNN depends on the number of types of benign traf-
fic (e.g., 10 in the USTC-TFC2016 dataset), while the
other parameters are fixed for different traffic types. First,
the one-dimensional CNN filter gets the first l bytes of the
first n packets as the input (i.e., the input size is n × l); the
kernel size of the filter of the convolution layer is set to 6 (in
the header, the largest field is the MAC address). The hidden
layer (layer 5) in the CNN, connecting to the autoencoder
module, is used to learn the flow features. Specifically, layers
from 1 to 7 in Table 5 are the architecture of the CNN, and
layer 5 plus layers from 8 to 11 are the architecture of autoen-
coder. Summary, the structural parameters in Table 5 are the
parameters that we refer to the architecture mentioned in [18]
and improve them. Moreover, such parameters are what we
have found after many cross-validation and experiments.
Hyperparameters for tuning
The performance of the DL-based approaches is suscepti-
bletothechangesofthehyperparameterssuchasthelearning
rate. In this work, tuning the following parameters may sig-
nificantly help to improve the performance of the system.
1) n and l: As mentioned in Section III-A, these are the
key parameters for early detection while maintaining
high accuracy.
2) Batch normalization: Due to the depth of the deep
learning architecture, the batch normalization between
each layer can keep the parameter distribution stable,
accelerate the learning efficiency, ease the gradient
disappearance and avoid over-fitting.
3) Add additional dense layers for CNN: In general,
adding more hidden layers could improve the perfor-
manceofCNN.InourCNNarchitecture,itconsistsof3
hiddenlayers(layer5to7).Whatwehavelearnedfrom
our experiments is that adding the second layer with
size of 25 improves the performance significantly. Our
conjecture is that, besides the benefit of an additional
hidden layer, the size of 25 actually corresponds to the
number of header fields in a TCP/IP packet. Although
we may also encounter UDP/IP packets with fewer
header fields, from our observation, setting the size to
25 seems to be able to accommodate both TCP and
UDP packets.
4) All dense layers adopt layer-wise greedy pre-training
for initialization: The layer-wise greedy pre-training
design targets at mitigating the impact of vanishing
gradient problem and overfitting in the deep archi-
tecture. Fortunately, Unsupervised Greedy Layer-Wise
Pretraining model [32] genuinely works well with the
classification based on the autoencoder.
V. EVALUATION RESULTS
Similar to most existing deep learning research, our pro-
posed classification model has been implemented using
TensorFlow/Keras and Pytorch. The evaluations have been
allperformedontheGPU-enabledTensorFlow(Pytorch)run-
ning on a 64-bit Ubuntu 16.04 LTS server with an Intel Xeon
Silver 4116 CPU@2.10GHz, 256GB RAM, and NVIDIA
Tesla V100. We also use the Python package dpkt, a pcap
parser and creator, to convert the raw packets for training.
To perform the evaluations, we have sequentially tested
the system on USTC-TFC2016, Mirai-RGU, and Mirai-CCU
datasets (mentioned in Section IV-A). Training the model
is performed only on the benign traffic; however, to verify
the system on various conditions, the testing scenario will
involve three cases: the input data of only benign, benign
and malicious, and pure malicious traffic. Also, since our
approach aims to gain a significant reduction in the process-
ing time, we prefer to classify an incoming flow, whether
it is malicious or not, instead of considering its attack type
in detail. In practice, if the proposed system detects a mali-
cious flow, it will raise an alarm and redirect the packets to
some off-line computationally intensive traffic classification
systems for further analysis, while blocking the malicious
flow simultaneously. Therefore, in the following subsections,
several common metrics are used for performance evaluation
in terms of a binary classifier.
• True Positive (TP) – number of attack flows that are
correctly classified as an attack.
• False Positive (FP) – number of benign flows that are
incorrectly classified as an attack.
• True Negative (TN) – number of benign flows that are
correctly classified as normal.
• False Negative (FN) – number of attack flows that are
incorrectly classified as an normal.
The accuracy in Eq. 3 measures the proportion of the total
number of correct classifications. The precision, recall, and
F1-mesaurearedefinedinEq.4,Eq.5andEq.6,respectively.
The first two reflect the rate of correct classifications influ-
enced by incorrect ones, and the last is the overall measure
between the precision and the recall.
Accuracy =
TP + TN
TP + TN + FP + FN
(3)
Precision =
TP
TP + FP
(4)
Recall =
TP
TP + FN
(5)
30394 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
F1=
2TP
2TP + FP + FN
=
2 ∗ Precision ∗ Recall
Precision + Recall
(6)
The FAR in Eq. 7, also known as FPR, measures the rate
of benign flows incorrectly classified as malicious. The FNR
in Eq. 8 measures the rate of malicious flows incorrectly
classified as benign.
False Alarm Rate =
FP
FP + TN
(7)
False Negative Rate =
FN
TP + FN
(8)
In the following subsections, we present the detection
performance of D-PACK for three selected datasets in three
scenarios:theinputdatafortrainingandtestingcanconsistof
onlybenign,benignandmalicious,andpuremalicioustraffic.
In the first scenario, the classes and number of flows of the
training and testing sets are shown in Table 6. The training
data in the CNN and autoencoder module in this scenario
include only benign traffic. The testing data include benign
traffic from USTC-TFC 2016 and malicious traffic from
Mirai-CCU.
TABLE 6. Scenario 1: USTC-TFC 2016 (benign) and Mirai-CCU (malicious)
datasets.
In the case of auto-learning traffic features, the learning
performance of the CNN model on benign traffic is summa-
rized in the confusion matrix table in Fig. 9. The top number
in each cell of the confusion matrix is the number of flows
for testing in the benign traffic set. The learning module can
classify the benign traffic type with nearly 100% accuracy.
Table 7 shows the accuracy of D-PACK in the first testing
scenario, i.e., on the testing set A, which contains benign
flows from USTC-TFC 2016 and malicious flows from
Mirai-CCU. As we observe from Table 7, with only 40 bytes
per flow, the accuracy is nearly 100%. When the number
of packets per-flow and bytes per packet are increased for
inspection, e.g., 2 packets per-flow and 50 bytes per packet
or 3 packets per flow and 60 bytes per packet, the system can
achieve 100% accuracy, a very promising result. However,
we also notice that when we increase the number of packets
FIGURE 9. The learning performance of CNN for benign traffic.
TABLE 7. The accuracy of D-PACK running with various values of n and l
(scenario 1: testing set A).
TABLE 8. The performance of the framework in Scenario 1: testing set A
with n = 2 and l = 50.
per flow does not yield higher accuracy. This result indicates
inspecting more bytes per packet is better than more packets
per flow. This is promising for reducing the flow processing
timeaswellasthetraininganddetectingtime.Thebestresult
for the testing set A is with the configuration of n = 2 and
l = 50, which yields ideal performance, i.e., 100% accuracy
andnoFPR/FNR.Theperformancewiththefive-metricmea-
surements in this ideal case is presented in Table 8.
In the second scenario, the training data and testing data
are all from the USTC-TFC 2016 dataset. The ratio of benign
traffic in the training set and the testing set is 7:1, as shown
in Table 9. The malicious traffic only appears in the testing
set, making the ratio of the total amount of flows in the
training set and that of the testing set becomes 4:1. After
training, we have tested the system with the testing set B.
VOLUME 8, 2020 30395
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 9. Scenario 2: USTC-TFC 2016 dataset (both benign and malicious).
TABLE 10. The detection accuracy of running with variances of n and l
(testing set B).
Table 10 shows the system performance on the testing set
with variances of n and l. Compared with the first scenario,
the system gains better performance with the low values of n.
The performance with five metrics in Table 11 reinforces this
indication. However, similar to the previous case, increasing
the value of n and l does not mean that the system gets better
performance.
In the third scenario, the training and testing data are
from the Mirai-RGU dataset. Since this dataset classifies all
benign traffic into one type, namely, the normal type; thus,
we use both benign and malicious traffic to train the CNN,
but only the benign traffic to train the autoencoder, as shown
in Table 12. The testing data also include both benign and
malicious traffic from this dataset, as shown in the third
TABLE 11. The performance of the framework on the testing set B with
n = 2 and l = 50.
TABLE 12. Scenario 3: training and testing sets from Mirai-RGU.
TABLE 13. The detection accuracy when running with the Mirai dataset
for various values of n and l.
TABLE 14. Performance of the framework on the whole malicious traffic
with n = 2 and l = 80.
column of Table 12. The Mirai-RGU dataset contains nine
types of attack traffic with quite a variant number of flows.
The detection accuracy of running the framework on the
testing data with variances of n and l is shown in Table 13.
Compared with the first two scenarios, the performance is
slightly worse with the same configuration of n and l, but the
accuracyisstillhigherthan99.7%whentwopacketsper-flow
and more than 60 bytes per packet are examined. Moreover,
intheapplicationswhererecursivecommunicationsprobably
generate extremely long flows, the configuration (i.e., n =
2, l = 60) still gives the detection system significant advan-
tages in skipping tremendous traffic volume for processing.
Similar to the accuracy, the performance of the rest mea-
surements in this scenario also deteriorates slightly. In this
case, we set n = 2 and l = 80 for the sampling configuration.
The system gains nearly 99% for the first four measurements,
30396 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
TABLE 15. Pre-processing capacity of our framework on various datasets.
while the FNR rises marginally but is still less than 1%,
as summarized in Table 14. The results reinforce our original
judgment that a well-designed learning strategy combined
with a slight adjustment of n,l may not significantly impact
the overall performance of the detection system while it
can significantly help to save traffic volume for processing
and speed up the detection. Admittedly, in the case of other
applications and datasets, e.g., malware binary, the values of
n and l can vary since their data structure for sampling may
need a tweak.
In summary, our experiments in all the scenarios demon-
strate that the performance of the proposed mechanism
either outperforms or is competitive to that of state-of-the-art
research works listed in Table 1.
A. TIME EFFICIENCY
The time efficiency in terms of the training time and the
detection time is also an important metric in our experiment.
The training time is the total time to complete the training
on the selected dataset. This time depends on the data pre-
processing, the training model (number of layers and dimen-
sions)andtheservercapacity.Therefore,itwouldbeunfairto
compare the execution with different hardware and software.
The pre-processing capacity of our system is summarized
inTable15.Thesystemcancapturethepackets,classifythem
into different flows, extract n packets per flow and discard
the rest with hundreds of thousands of the flows per second.
Sincethepre-processingtimeincludesreadingallthepackets
in the dataset, which demands much I/O time, and training
the deep learning model, which requires much CPU/GPU
processing time; thus, in some cases, it can only process tens
of thousands of flows. However, the pre-processing task shall
be done offline; thus, it is acceptable to have slightly longer
pre-processing time.
TABLE 16. Detection speed with different datasets.
Unlikethepre-processing,thedetectiononthesametraffic
type is supposed to be significantly faster because the clas-
sification can work on the raw traffic directly after training,
insteadofspendingtimeinthelearningtasks.Inourempirical
experiment, the detection can serve hundreds of thousands
of flows per second (as summarized in Table 16), no matter
which dataset it runs on. The processing capacity here is
defined as the total number of flows that can be classified
per second on a given testing dataset. With the processing
of hundreds of thousands of flows per second, our approach
can work for on-line monitoring since this speed can satisfy
most on-demand applications and in medium networks. For
the core networks, we may need more efforts to integrate this
system for potential deployment, since the network speed at
suchnodescanbeuptohundredsofgigabitspersecond.Note
that the system at the core networks can be equipped with
much more powerful hardware.
B. DISCUSSION
There is a trade-off between the number of trimmed pack-
ets, trimmed length, and the classification performance,
i.e., accuracy and detection time. Reducing the trimmed
length, e.g., from 80 bytes to 40 bytes, can potentially help
to reduce the detection time and the training time, but may
dramatically impact the accuracy. The accuracy also depends
on the considered attack type. In the evaluation, we found
that the ideal configuration is at n = 2 and l = 80.
However, promising research is to propose an algorithm to
VOLUME 8, 2020 30397
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
calculate a proper configuration automatically in a deployed
environment.
Moreover, the approach to consider the classification at
the packet level can open the door towards accelerating the
detection since we can schedule the packets for parallel pro-
cessing. However, the explicit shortcoming is to increase the
training time and resource usage (e.g., memory) due to a
large number of parameters and data size put into the training
model. Balancing the factor of acceptable training time but
still gaining high classification performance is a non-trivial
task and a potential research direction.
Finally, the DL-based classification approach is highly
susceptible to the data poisoning attack due to its depen-
dence on the training data. So far, we have found few attack
models targeting at evading the deep learning-based mali-
cious classification systems, including ours. However, this
can soon be changed when the popularity of deep learning
will attract more attackers to exploit its vulnerabilities for
hacking or monetization. Generating/preventing adversary
models against deep learning thus is a very interesting and
promising security research topic.
VI. CONCLUSION
In this work, we present a novel early malicious traffic detec-
tion framework, namely D-PACK, based on traffic sampling,
traffic auto-profiling (CNN), and an unsupervised DL model
(autoencoder). By targeting at examining as few packets and
numberofbytesfromeachpacketaspossible,oursystemcan
significantly reduce the traffic volume for processing. The
evaluation results show that D-PACK can detect malicious
traffic with nearly 100% accuracy and less than 1% FNR and
FPR,evenifitexaminesonlytwopacketsfromeachflowand
80 bytes from each packet. Moreover, it is supposed to con-
sume much less flow pre-processing time and detection time
than prior works because much fewer packets and bytes are
inspected. Thus, the important advantage of this framework
is to speed up the detection. We believe that this first attempt
can inspire the research community to consider further opti-
mization methods, particularly by exploiting the advantages
of deep learning to build effective online anomaly detection
systems without suffering significant detection delay.
REFERENCES
[1] M. Bacon. New Mirai Variant Attacks Apache Struts Vulnerability.
Accessed: Jun. 12, 2018. [Online]. Available: https://searchsecurity.
techtarget.com/news/252448779/New-Mirai-variant-attacks-Apache-
Struts-vulnerability
[2] S. Gatlan. Mirai Botnet Variants Targeting New Processors and
Architectures. Accessed: Apr. 9, 2019. [Online]. Available: https://www.
bleepingcomputer.com/news/security/mirai-botnet-variants-targeting-
new-processors-and-architectures
[3] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, ‘‘DDoS in the IoT:
Mirai and other botnets,’’ Computer, vol. 50, no. 7, pp. 80–84, 2017.
[4] R. Hallman, J. Bryan, G. Palavicini, J. Divita, and J. Romero-Mariona,
‘‘IoDDoS the Internet of distributed denial of service attacks—A case
study of the mirai malware and IoT-based botnets,’’ in Proc. 2nd Int. Conf.
Internet Things, Big Data Secur., vol. 1, 2017, pp. 47–58.
[5] P. Zilberman, R. Puzis, and Y. Elovici, ‘‘On network footprint of traffic
inspection and filtering at global scrubbing centers,’’ IEEE Trans. Depend.
Sec. Comput., vol. 14, no. 5, pp. 521–534, Sep. 2017.
[6] M. H. Bhuyan, D. K. Bhattacharyya, and J. K. Kalita, ‘‘Network anomaly
detection: Methods, systems and tools,’’ IEEE Commun. Surveys Tuts.,
vol. 16, no. 1, pp. 303–336, 2014.
[7] A. L. Buczak and E. Guven, ‘‘A survey of data mining and machine
learning methods for cyber security intrusion detection,’’ IEEE Commun.
Surveys Tuts., vol. 18, no. 2, pp. 1153–1176, 2016.
[8] S. Valenti, D. Rossi, A. Dainotti, A. Pescap, A. Finamore, and M. Mellia,
‘‘Reviewing traffic classification,’’ in DataTraffic Monitoring and Analy-
sis. Cham, Switzerland: Springer, 2013, pp. 123–147.
[9] E. Min, J. Long, Q. Liu, J. Cui, and W. Chen, ‘‘TR-IDS: Anomaly-based
intrusion detection through text-convolutional neural network and random
forest,’’ Secur. Commun. Netw., vol. 2018, pp. 1–9, Jul. 2018.
[10] W. Wang, M. Zhu, J. Wang, X. Zeng, and Z. Yang, ‘‘End-to-end encrypted
traffic classification with one-dimensional convolution neural networks,’’
in Proc. IEEE Int. Conf. Intell. Secur. Informat. (ISI), Jul. 2017, pp. 43–48.
[11] D. Berman, A. Buczak, J. Chavis, and C. Corbett, ‘‘A survey of deep
learning methods for cyber security,’’ Information, vol. 10, no. 4, p. 122,
Apr. 2019.
[12] E. Min, J. Long, Q. Liu, J. Cui, Z. Cai, and J. Ma, ‘‘SU-IDS: A semi-
supervised and unsupervised framework for network intrusion detection,’’
in Proc. 4th Int. Conf. Cloud Comput. Secur., 2018, pp. 322–334.
[13] Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky, D. Breitenbacher,
A. Shabtai, and Y. Elovici, ‘‘N-BaIoT: Network-based detection of IoT
botnet attacks using deep autoencoders,’’ IEEE Pervas. Comput., vol. 17,
no. 3, pp. 11–22, Jul./Sep. 2018.
[14] W. Wang, Y. Sheng, J. Wang, X. Zeng, X. Ye, Y. Huang, and M. Zhu,
‘‘HAST-IDS: Learning hierarchical spatial-temporal features using deep
neural networks to improve intrusion detection,’’ IEEE Access, vol. 6,
pp. 1792–1806, 2018.
[15] G. Aceto, D. Ciuonzo, A. Montieri, and A. Pescape, ‘‘Mobile encrypted
traffic classification using deep learning: Experimental evaluation, lessons
learned, and challenges,’’ IEEE Trans. Netw. Serv. Manage., vol. 16, no. 2,
pp. 445–458, Jun. 2019.
[16] M. Al-Qatf, Y. Lasheng, M. Al-Habib, and K. Al-Sabahi, ‘‘Deep learning
approach combining sparse autoencoder with SVM for network intrusion
detection,’’ IEEE Access, vol. 6, pp. 52843–52856, 2018.
[17] L. Vu, C. T. Bui, and Q. U. Nguyen, ‘‘A deep learning based method for
handling imbalanced problem in network traffic classification,’’ in Proc.
8th Int. Symp. Inf. Commun. Technol. (SoICT), 2017, pp. 333–339.
[18] W. Wang, M. Zhu, X. Zeng, X. Ye, and Y. Sheng, ‘‘Malware traffic clas-
sification using convolutional neural network for representation learning,’’
in Proc. Int. Conf. Inf. Netw. (ICOIN), 2017, pp. 712–717.
[19] Z. Chen, K. He, J. Li, and Y. Geng, ‘‘Seq2Img: A sequence-to-image
based approach towards IP traffic classification using convolutional neural
networks,’’ in Proc. IEEE Int. Conf. Big Data (Big Data), Dec. 2017,
pp. 1271–1276.
[20] M. Lotfollahi, M. J. Siavoshani, R. S. H. Zade, and M. Saberian, ‘‘Deep
packet: A novel approach for encrypted traffic classification using deep
learning,’’ Soft Comput., vol. 24, no. 3, pp. 1999–2012, Feb. 2020.
[21] M. Lopez-Martin, B. Carro, A. Sanchez-Esguevillas, and J. Lloret, ‘‘Net-
work traffic classifier with convolutional and recurrent neural networks for
Internet of Things,’’ IEEE Access, vol. 5, pp. 18042–18050, 2017.
[22] J. Hochst, L. Baumgartner, M. Hollick, and B. Freisleben, ‘‘Unsupervised
traffic flow classification using a neural autoencoder,’’ in Proc. IEEE 42nd
Conf. Local Comput. Netw. (LCN), Oct. 2017, pp. 523–526.
[23] I. Arnaldo, A. Cuesta-Infante, A. Arun, M. Lam, C. Bassias, and
K. Veeramachaneni, ‘‘Learning representations for log data in cyberse-
curity,’’ in Proc. Int. Conf. Cyber Secur. Cryptogr. Mach. Learn., 2017,
pp. 250–268.
[24] Y. Yu, J. Long, and Z. Cai, ‘‘Network intrusion detection through stacking
dilated convolutional autoencoders,’’ Secur. Commun. Netw., vol. 2017,
pp. 1–10, Nov. 2017.
[25] Y.Li,R.Ma,andR.Jiao,‘‘Ahybridmaliciouscodedetectionmethodbased
ondeeplearning,’’Int.J.Secur.Appl.,vol.9,no.5,pp.205–216,May2015.
[26] V. Paxson and S. Floyd, ‘‘Wide area traffic: The failure of Poisson model-
ing,’’ IEEE/ACM Trans. Netw., vol. 3, no. 3, pp. 226–244, Jun. 1995.
[27] B. Hullar, S. Laki, and A. Gyorgy, ‘‘Efficient methods for early pro-
tocol identification,’’ IEEE J. Sel. Areas Commun., vol. 32, no. 10,
pp. 1907–1918, Sep. 2014.
[28] G. Maier, R. Sommer, H. Dreger, A. Feldmann, V. Paxson, and
F. S Hneider, ‘‘Enriching network security analysis with time travel,’’
SIGCOMM Comput. Commun. Rev., vol. 38, no. 4, p. 183, Oct. 2008.
30398 VOLUME 8, 2020
R.-H. Hwang et al.: Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection
[29] S. Albawi, T. A. Mohammed, and S. Al-Zawi, ‘‘Understanding of a
convolutional neural network,’’ in Proc. Int. Conf. Eng. Technol. (ICET),
Aug. 2017, pp. 1–6.
[30] R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi,
‘‘Microsoft malware classification challenge,’’ 2018, arXiv:1802.10135.
[Online]. Available: http://arxiv.org/abs/1802.10135
[31] C. D. Mcdermott, F. Majdani, and A. V. Petrovski, ‘‘Botnet detection in
the Internet of Things using deep learning approaches,’’ in Proc. Int. Joint
Conf. Neural Netw. (IJCNN), Jul. 2018, pp. 1–8.
[32] P. L. Y. Bengio, D. Popovici, and H. Larochelle, ‘‘Greedy layer-wise
training of deep networks,’’ in Proc. 19th Int. Conf. Neural Inf. Process.
Syst. (NIPS), 2006, pp. 153–160.
REN-HUNG HWANG (Senior Member, IEEE)
received the Ph.D. degree in computer science
from the University of Massachusetts, Amherst.
He joined the Department of Computer Science
and Information Engineering, National Chung
Cheng University (CCU), in 1993, where he is
currently a Distinguished Professor. He has pub-
lished more than 200 international journals and
conference papers. He has served as the Dean for
the College of Engineering, from 2014 to 2017.
He has received the IEEE Outstanding Paper Award from the IEEE UIC
2012, and the IEEE Best Paper Award from the IEEE IUCC 2014, the IEEE
SC2 2017, and the IEEE Ubi-Media 2018. His current research interests
include the Internet of Things, network security, cloud/edge/fog computing,
and software-defined networks.
MIN-CHUN PENG is currently pursuing the
Ph.D. degree with the Department of Computer
Science and Information Engineering, National
Chung Cheng University, Chiayi, Taiwan. His
research interests include information security and
deep learning, deep learning, cloud computing,
the Internet of Things, and information security.
CHIEN-WEI HUANG is currently pursuing the
master’s degree with the Department of Computer
Science and Information Engineering, National
Chung Cheng University, Chiayi, Taiwan. He is
working on L2, L3 network protocol. His research
interests include information security and deep
learning.
PO-CHING LIN received the Ph.D. degree in
computer science from National Chiao Tung Uni-
versity, Hsinchu, Taiwan, in 2008. He joined the
Department of Computer Science and Information
Engineering, National Chung Cheng University
(CCU), in August 2009, as a Faculty Member,
where he is currently an Associate Professor. His
research interests include network security, net-
work traffic analysis, and performance evaluation
of network systems.
VAN-LINH NGUYEN (Member, IEEE) received
the Ph.D. degree in computer science and infor-
mation engineering from National Chung Cheng
University (CCU), Taiwan, in 2019. He is cur-
rently an Assistant Professor with the Depart-
ment of Information Technology, TNU-University
of Information and Communication Technology,
Vietnam. His research interests include network
security, vehicular security, the Internet of Things,
deep learning, and edge computing.
VOLUME 8, 2020 30399
 code segment, and associate the malware under
study with various malware in the database [71]. In proposed
systemthree-levelsignaturegenerationschemahasbeenused
to identify each application. The authors assert that proposed
signature methodology provides significant advantages over
traditionalcryptographichashlikeMD5-basedsignature,and
resistant to packing and mutations. The proposed system has
not been compared with other studies in the literature, and
the evaluation metrics are not very high and are not explained
in detail.
3) EVALUATION OF SIGNATURE-BASED DETECTION
In the literature review, signature-based detection methods
have been summarized. Signature-based detection schema
has been used for antivirus vendors for many years and it
is quite fast and effective to detect known malware. This
approach is generally used to detect malware which belongs
to the same family. However, it fails to detect new gen-
eration malware which uses obfuscation and polymorphic
techniques. Besides, it is prone to many FPs and extracting
signature takes a lot of man-power.
Althoughprevioussignature-basedm
Yes
Stored procedure in database
Fig. 2. Anomaly detection flowchart.
J.-S. Chou, A.S. Telaga / Renewable and Sustainable Energy Reviews 33 (2014) 400–411 403
? Step 5: Update each cluster center c ðtÞ
k
as the mean of all x i that
are closest according to the following equation:
c t k ¼
∑ x j A k x i
n k
ð3Þ
where n k is number of data items in the kth cluster.
? Step 6: Use Eq. (3) to calculate distortion D, which depicts the
sum of all intra cluster distances. A low D is preferable.
? Step 7: If the value of D has converged, return the final cluster
centers ðc ð0Þ
1
;c ð0Þ
2
;…;c ð0Þ
k
Þ. Otherwise, set t ¼ tþ1, and return to
step 3.
3.2. Artificial neural networks
Artificial neural networks (ANNs) are information-
processing units that function similarly to neurons in the
human brain except that a neural network consists of artificial
neurons [49]. The structure of an ANN contains many such
neurons connected systematically. The feed-forward neural
networks used here are also known as multilayer perceptrons
(MP). The quantifiable data used for problem solving are fed
into the input layer and then processed by the self-updating
and self-learning model in the hidden layer. The resulting
solution is then sent to the output layer. The mathematical
model for MP is:
z j ¼ φ b j þ ∑
n
i3554 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Botnet Identification in DDoS Attacks With
Multiple Emulation Dictionaries
Michele Cirillo , Graduate Student Member, IEEE, Mario Di Mauro , Member, IEEE,
Vincenzo Matta , Member, IEEE, and Marco Tambasco
Abstract—In a Distributed Denial of Service (DDoS) attack,
a network (botnet) of dispersed agents (bots) sends requests to
a website to saturate its resources. Since the requests are sent
by automata, the typical way to detect them is to look for
some repetition pattern or commonalities between requests of
the same user or from different users. For this reason, recent
DDoS variants exploit communication layers that offer broader
possibility in terms of admissible request patterns, such as, e.g.,
the application layer. In this case, the malicious agents can pick
legitimate messages from an emulation dictionary, and each indi-
vidual agent sends a relatively low number of admissible requests,
so as to make its activity non suspicious. This problem has been
recently addressed under the assumption that all the members
of the botnet use the same emulation dictionary. This situation
is an idealization of what occurs in practice, since different
clusters of agents are typically sharing only part of a global
emulation dictionary. The diversity among the emulation dictio-
naries across different clusters introduces significant complexity
in the botnet identification challenge. This work tackles this issue
and provides the following main contributions. We obtain an
analytical characterization of the message innovation rate of the
DDoS attack with multiple emulation dictionaries. Exploiting this
result, we design a botnet identification algorithm equipped with
a cluster expurgation rule, which, under appropriate technical
conditions, is shown to provide exact classification of bots and
normal users as the observation window size increases. Then,
an experimental campaign over real network traces is conducted
to assess the validity of the theoretical analysis, as well as to
examine the effect of a number of non-ideal effects that are
unavoidably observed in practical scenarios.
Index Terms—Distributed denial of service, DDoS, cyber-
security, botnet, traffic emulation.
I. I NTRODUCTION
N
ETWORKS are consistently exposed to a variety of
dangerous cyber-threats. Providing reliable processing
and inference strategies to contrast these threats is a critical
part of the network security chain [2]–[8]. This work focuses
Manuscript received November 25, 2020; revised February 22, 2021;
accepted May 3, 2021. Date of publication May 21, 2021; date of current
version June 21, 2021. This article was presented in part at the Proceedings
of ICASSP [1]. The associate editor coordinating the review of this manuscript
and approving it for publication was Dr. Mika Ylianttila. (Corresponding
author: Vincenzo Matta.)
Michele Cirillo, Mario Di Mauro, and Vincenzo Matta are with the Depart-
ment of Information and Electrical Engineering and Applied Mathematics
(DIEM), University of Salerno, 84084 Fisciano, Italy, and also with the
National Inter-University Consortium for Telecommunications (CNIT), Italy
(e-mail: micirillo@unisa.it; mdimauro@unisa.it; vmatta@unisa.it).
Marco Tambasco is with Ericsson Telecomunicazioni S.p.A., 84016 Pagani,
Italy (e-mail: marco.tambasco@ericsson.com).
This article has supplementary downloadable material available at https://
doi.org/10.1109/TIFS.2021.3082290, provided by the authors.
Digital Object Identifier 10.1109/TIFS.2021.3082290
on the design and analysis of inferential strategies for
the mitigation of Distributed Denial of Service (DDoS)
attacks.
DDoS attacks are powerful cyber-threats that can pro-
voke significant damages to data networks. These attacks are
launched by a network (the botnet) of malicious agents (the
bots) controlled by a remote entity (the botmaster). The bots
try to bypass the network Intrusion Detection System (IDS) by
implementing a “drop-by-drop” strategy, where i) each indi-
vidual bot sends a relatively low number of legitimate requests
to a target site; and ii) the global rate of requests produced
by the entire botnet is so large to saturate the computational
resources of the target. In order to mitigate the impact of these
attacks, the network administrator should be able to identify
and then ban the bots. Unfortunately, the distributed nature of
DDoS attacks, as opposed to traditional non-distributed denial
of service, makes the botnet highly strewn across the overall
network that mixes legitimate and malicious users. As a result,
detection of each single bot is a demanding task.
A. Motivating Example
A recent and famous example of real-world DDoS attack
is Mirai, which has already caused noteworthy damages,
particularly exploiting the vulnerabilities of poorly secured
IoT devices [9]–[11]. The Mirai botnet is able to use different
layers of the protocol stack to launch different types of attacks,
including SYN-flood, ACK-flood, TCP STOMP attacks, DNS
attacks, UDP attacks, and HTTP attacks [12]. According to
a recent report of a recognized cyber-security provider, “the
HTTP attack included in Mirai is a highly flexible attack
with several customizations that could prove difficult to defend
against without the right tools” [12]. The main difficulties in
facing this type of attack arise from the fact that the botnet can
craft a number of legitimate HTTP requests that do not appear
suspicious to the network administrator. The main element that
the network administrator can leverage to face the attack is
the limited amount of HTTP requests across different bots,
which induces a suspicious similarity among the bots’ traffic
patterns. Therefore, the power of this attack grows with the
increasing availability of crafted messages, and for this reason
the HTTP protocol is particularly convenient to the attacker.
In our work, this aspect is made formal by introducing an
emulation dictionary, i.e., a set of legitimate messages that
the bots can send to the target site.
1556-6021 © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3555
An even more dangerous evolution of Mirai regards the
implementation of coordinated attacks, where a common
target is attacked by different groups of bots, with each group
being coordinated by a different Command and Control (C&C)
center [13]. There are two main elements of novelty arising
in this scenario: i) the HTTP requests crafted by the spatially
dispersed C&C centers will exhibit a certain degree of diver-
sity, which makes the DDoS identification task more difficult,
because diversity across bots reduces similarity between bots’
patterns; and ii) the HTTP requests of different C&C centers
cannot be totally different, because each center learns and
crafts legitimate requests from the same web content that
is effectively present on the target site. These fundamental
elements of novelty find correspondence in the main novelty
presented in our work, that is the introduction of multiple
clusters of bots, with each cluster using its own emulation
dictionary (diversity), and with different emulation dictionaries
sharing part of their requests (partial overlap).
B. Related Work
In recent years, several useful works addressed the problem
of devising countermeasures toward DDoS identification and
mitigation — we invite the Reader to consult [14] and [15] for
an overview on the subject. We now provide a brief summary
of related works.
1) Classical DDoS: We start by listing some recent articles
relevant to DDoS attacks that do not take place specifically
at the application layer. Accordingly, these articles are not
strictly related to our work, nonetheless we feel it useful to
report them as relevant references in the general context of
DDoS attacks. A popular approach to tackle DDoS attacks
and bot identification is based on statistical methods aimed at
revealing anomalous patterns, e.g., repetition patterns, unusual
traffic rates. The DDoS identification strategy devised in [16]
relies on the detection of anomalies observed in the entropy
and in the frequency-sorted distribution of selected packet
attributes. In a similar vein, a technique based on entropy
detection is proposed in [17], where the degree of random-
ness associated to suitable packet attributes is elected as the
critical marker of a DDoS. A hierarchical method aimed
at capturing shifts within spatio-temporal traffic patterns is
designed in [18]. Such shifts are then exploited to reveal a
DDoS flooding attack. The framework Umbrella is proposed
in [19], focusing on amplification DDoS attacks and offer-
ing to the victims the possibility to customize the level of
defense. In [20], the generalized entropy and the information
distance metrics are used to reveal low-rate DDoS attacks,
where dissimilarity between legitimate and malicious traffic
is evaluated. The case of low-rate shrew DDoS attacks (TCP
flows constrained to sustain a small fraction of their ideal rate
at low attack costs) is tackled in [21], where a model amenable
to control the TCP congestion window at the target website
is exploited. In [22], the Authors propose a fingerprinting
approach relying on the analysis of packet-level features in
a traffic flow (e.g., length, number of transmissions). The
obtained fingerprints are used to generate “normal” profiles,
and then a clustering-based detection algorithm decides about
the legitimacy of an unknown fingerprint possibly associated to
a DDoS source. In the context of virtualized network domains,
a defense mechanism named CoFence is introduced in [23]
to handle SYN flood DDoS attacks through resource sharing.
The resource sharing mechanism is modeled as a Stackelberg
game, where all domains aim to maximize their own utility.
Finally, the Authors in [24] propose a virtualized monitoring
system to analyze SYN flood attacks. Due to the huge number
of SYN requests, the monitoring system subsamples each
flow probabilistically, leading to a critical interplay between
sampling rate and DDoS detection rate.
2) Application-Layer DDoS: Since DDoS attacks are typi-
cally based on the repetition of predefined actions or patterns,
their power can be greatly amplified when they are imple-
mented at the application layer of the TCP/IP protocol stack
(L7-DDoS) [25]–[28].
In particular, L7-DDoS attacks can be broadly categorized
in two classes [29]: i) Request Flooding Attack, where the
attack flows exhibit a request rate higher than legitimate traffic;
ii) Asymmetric Workload Attack, where the attacker sends
few requests that require a computationally expensive response
from the server. Our work focuses on class i). Nevertheless,
it is useful to illustrate briefly the main features of class ii).
Asymmetric workload attacks are typically designed to
put under strain complex servers such as database systems,
where few specific SQL-based queries can force the data-
base to perform many nested and computationally expensive
operations. The work in [30] is focused on detecting such
asymmetric L7-DDoS attacks by exploiting the Probabilistic
Timed Automata (PTA) framework, where server resources are
represented by states and requests by transitions. A measure
of the workload is associated to each state to quantify the
amount of computation required by the server to satisfy a
specific request. The same Authors propose a generalization of
their original method in [30], called Multiplexed Asymmetric
Attacks [31], where the idea is to exploit the Multiplexing and
Server Push functionalities of the HTTP/2 protocol to carry
more requests simultaneously. One strength of asymmetric
workload attacks is that they typically rely on few malicious
agents to perform the requests and, hence, a botnet needs
comparably less resources w.r.t. request flooding attacks. At
the same time, the presence itself of few requests can be a
weakness of asymmetric attacks. In fact, an IDS can zoom
on in agents that send computationally expensive requests and
monitor them to detect repetition patterns and other kind of
suspicious behavior.
In contrast, the request flooding attacks in class i) become
particularly difficult to detect when the bots are able to craft
a large number of different requests, so as to emulate the
legitimate activity of a normal network user. Unfortunately,
there exist several real-world examples showing the relevance
and power of L7-DDoS attacks based on request flooding.
One is the case of Logitravel, a worldwide travel agency that
experienced an attack with peaks reaching approximately 9
million requests per minute, corresponding to about 150000
requests per second, and a maximum load 50 times larger
than the normal load [32]. Another example is a recent attack
performed using the sophisticated malware Mirai illustrated
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3556 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
in Sec. I-A. The popularity of request flooding attacks is
even growing since nowadays they can be easily implemented
through the Malware-as-a-Service (MaaS) paradigm, a service
recently appeared into the Dark Web, which allows to rent
powerful botnets for a low fee [33].
The above observations explain the noteworthy interest of
the scientific community on L7-DDoS flooding attacks. As
mentioned in Sec. I-A, different protocols of the application
layer can become carriers for such attacks. One example is
the DNS flooding attack launched through the Domain Name
System protocol. In particular, recent variants of DNS flooding
attacks exploit the vulnerabilities of specific environments,
such as the Internet of Things (IoT) or the Software Defined
Network (SDN) environment. With reference to the IoT con-
text, a bot mitigation strategy is proposed in [34], which
relies on the hierarchical connections among DNS servers.
In the context of SDN environments, in [35] a strategy named
WisdomSDN is conceived to detect illegitimate DNS requests
and responses. Actually, since standard DNS queries are built
through a very limited set of messages, one typical way to
counter such attacks is to instruct an IDS to perform a content
control of each query, so as to detect repetitive behavior and
ban the associated users.
In comparison, HTTP flooding attacks are more challenging
to defend against, due to the botnet possibility of building an
extremely high number of messages, e.g., GET/POST requests.
In [36], a sketch-based approach to detect HTTP flooding
attacks is proposed. A sketch is a data structure based on hash
tables, used to aggregate high dimensional data streams. The
idea in [36] is based on the fact that through the sketches
it is possible to detect significant changes, interpreted as
occurrences of attacks, in massive data streams. The problem
of detecting HTTP flooding attacks is faced also in [37],
where the Authors propose an Abnormal Traffic Detection
Module (ATDM) able to: i) organizingthe HTTP request flows
as time series; and ii) predicting the traffic intensity based on
previous observations. Then, an abnormal behavior is declared
when the distance between predictions and actual intensities
exceeds a suitable threshold.
Recently, the concept of L7-DDoS attacks characterized by
the possibility of emulating normal users by crafting a rich
variety of legitimate traffic patterns was put forth in [38]–[40].
The model adopted in [38]–[40] introduces an emulation
dictionary that is learned continually and, hence, enriched
continually by the botmaster, through monitoring and collec-
tion of legitimate surfing activity performed on the target site.
The bots can access the emulation dictionary of admissible
messages in order to emulate the behavior of a normal network
user. By “admissible”, we mean here that the bot requests
should be referred to content that is effectively present on the
target website. Usually, to launch the attack, some malicious
code is installed on the compromised machines. Then, the code
installed on a given bot starts sending requests taken from a
certain set of legitimate messages. To this end, the botmaster
controlling a given cluster of bots must put in the emulation
dictionary a set of messages corresponding to content that is
effectively available on the target site. This operation needs
continuous monitoring and learning from the botmaster, for
at least two reasons. First, richer sets of requests give to
the botnet more power of emulating normal users. Second,
tracking the evolution of a target website is especially relevant
in relation to content that changes dynamically over time,
e.g., due to intrinsic characteristics of the website, advertising,
or protection mechanisms. For example, on an e-commerce
portal, new products can be promoted over time, and the
botmaster is interested in enriching the emulation dictionary
with the corresponding new pages to maximize the degree of
innovation and, hence, of emulation.
Notably, the attacks studied in [38]–[40] are particularly
challenging, since they assume that if one looks at the indi-
vidual request pattern of a bot, there is no way to distinguish it
from a legitimate pattern, i.e., bot patterns are individually not
anomalous. Accordingly, in [38]–[40] a strategy is proposed
that is able to identify the botnet by exploiting dependence
across bot patterns.
3) Coordinated DDoS: The botnet identification strategies
proposed in [38]–[40] assume either that the emulation dic-
tionary is one and the same for all bots [38], [39] or that
different groups of bots can use completely disjoint dictionar-
ies [40]. These assumptions appear somehow restrictive, since
in practice it is expected that none of these two extreme scenar-
ios is verified, for different reasons, including: decentralized
control of the botnet, decentralized learning of the emulation
dictionary,imperfect communication.In comparison,it is more
realistic to assume that, inside the botnet, there exist clusters
of bots that pick messages from the same emulation dictionary,
but that at the same time a certain degree of diversity exists
among the dictionaries of different clusters. Such augmented
diversity implies in turn an augmented variability in the traffic
patterns produced by the botnet, making it more difficult to
distinguish them from legitimate users.
The presence of multiple emulation dictionaries spread
across the network reflects some sophisticated and challenging
DDoS scenarios, where a huge botnet is partitioned into
several groups or clusters, each of which under the control
of a different C&C center. Such a flexible organization is
aimed at concurrently maximizing the damage against a target
and minimizing the possibility of being revealed. Moreover,
a decentralized C&C infrastructure, a.k.a. Peer-to-Peer botnet,
has been proven to offer a strong robustness as compared
to centralized solutions where hindering a central server is
sufficient to mitigate or stop the threat [41].
Recent works on coordinated DDoS attacks focus on the
case where communication among bots controlled by the same
C&C center induces a community structure. In [42], [43]
the PeerHunter strategy is devised to perform a behavioral
analysis that maps bots and legitimate applications, or different
types of bots, into different communities. In [44], the Authors
characterize the communication among network nodes in
terms of an undirected graph, and graph metrics such as the
node degree and the conductance are used to identify bot
communities. Similar concepts are exploited in [45], where an
algorithm named BotCLAM is able to pinpoint distinct botnet
communities within a communication graph.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3557
TABLE I
N OTATION
C. Main Contributions
In order to defeat an attacker, one must necessarily assume
to have some advantage over it. Accordingly, the DDoS
identification methods exploited in the references listed in the
previous section rely on one or more among the following
assumptions: i) existence of patterns that each bot repeats
several times; ii) other anomalous behavior of the individual
bots, e.g., malformed or suspicious HTTP requests; iii) a
communication structure among group of bots, i.e., a network
graph, giving rise to distinct communities inside the botnet.
In comparison, in this work we consider the worst-case
scenario addressed in [39], where none of these assumptions
is verified, since: i) each individual bot has a fairly rich
emulation dictionary so as to avoid suspicious repetitions;
ii) the patterns formed by the individual bots are assumed
to appear perfectly legitimate to a network administrator;
iii) no detectable communication structure exists among the
bots. Under this demanding setting, the techniques listed in
Sec. I-B cannot perform properly, for example, evaluating
the entropy of a user’s request pattern does not reveal any
meaningful information as regards its nature (bot or normal).
Likewise, estimating a community graph is hopeless in the
absence of data related to the existence of links between
pairs of bots. As a result, under the setting considered in this
work, a critical information useful to discriminate a botnet
from normal users is the similarity between the activities
of distinct bots, arising because the emulation dictionary is
constrained to grow over time up to a limited rate. Unfor-
tunately, the techniques available to exploit such information
consider only the cases where all bots craft their legitimate
requests from the same emulation dictionary [38], [39], or the
straightforward extension where different groups of bots use
completely disjoint dictionaries [40]. As explained before,
and motivated by the example in Sec. I-A, recent evolutions
of DDoS attacks leverage the possibility of distributing the
attack across separate clusters of bots coordinated by separate
C&C centers. This relevant evolution introduces the additional
challenge of infusing a botnet identification algorithm with the
capability of handling the diversity across distinct emulation
dictionaries. In summary, the main contribution of this work
is to provide a theoretical analysis, supported by experiments
carried out on datasets containing the activity of real-world
users, to characterize a botnet identification strategy for the
demanding setting of DDoS attacks with multiple emulation
dictionaries.
II. DD O S W ITH M ULTIPLE E MULATION D ICTIONARIES
Let N = {1,2,..., N} denote the monitored network made
of N users, legitimate and/or bots. We start by introducing
some useful quantities related to the network activity. For a
given subnet S ⊆ N, we denote by N S (t) the overall number
of transmissions taking place in S up to a given time t. The
transmission activity of S will be then summarized by the
empirical transmission rate:
?
λ S (t) ?
N S (t)
t
, (1)
whose asymptotic (t → ∞) value, when it exists, is denoted
by λ S . We remark that this indicator is useful to quantify
the amount of transmissions, but it does not convey any
information about the content of the transmitted messages.
In an application-layer DDoS attack, the message content
becomes critical to enable faithful discrimination between bots
and legitimate users. Thus, we introduce a second indicator
pertaining to the variability of the message content, namely,
the Message Innovation Rate (MIR). Letting D S (t) be the set
of all the distinct messages sent up to t by users belonging to
subnet S, the empirical MIR is defined as:
? ρ S (t) ?
|D S (t)|
t
. (2)
When it exists, the limiting MIR is denoted by ρ S . We
remark that the above two descriptors, ? λ S (t) and ? ρ S (t), are
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3558 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
relative to generic users, i.e., they apply to both normal users
or bots.
The third and last descriptor we are going to introduce per-
tains only to the bot activity. Let B ⊆ N denote the ensemble
of all bots disseminated across the network. We assume that
the botmaster has collected a set of messages available for the
purpose of emulating legitimate traffic patterns. The botmaster
distributes fairly the dictionary across the botnet, in such
a way that different clusters of bots receive approximately
equal-sized portions of the dictionary. Formally, thebotnet is
partitioned into C clusters and at time t the bots belonging
to the i-th cluster can access an emulation dictionary E i (t),
whose cardinality grows over time at rate:
α ? lim
t→∞
|E i (t)|
t
, i = 1,2,...,C, (3)
which is accordingly referred to as Emulation Dictionary Rate
(EDR). In order to send apparently legitimate requests, a bot
belonging to the i-th cluster picks admissible messages from
E i (t). In order to guarantee a non-suspicious innovation rate,
the botmaster must steadily learn new admissible messages,
which means that the cardinality of the emulation dictionary
must increase over time.
One fundamental feature of this work is that we allow
for non-negligible interaction between distinct clusters. More
specifically, the emulation dictionaries of two clusters i and j
have an intersection given by:
E ij (t) ? E i (t) ∩ E j (t), (4)
whose overlap degree is quantified as:
lim
t→∞
|E ij (t)|
|E i (t)|
= lim
t→∞
|E ij (t)|
|E j (t)|
= ω ij = ω ji ∈ (0,1), (5)
yielding, in view of (3), the EDR of the intersection:
lim
t→∞
|E ij (t)|
t
= α ω ij . (6)
One example of the scenario with multiple dictionaries is
illustrated in Fig. 1, with reference to three clusters.
Our model allows intersection among more than two dictio-
naries — see the top of Fig. 1. Nevertheless, in the following
we will show an algorithm able to identify any arbitrary
number of clusters resorting only to successive pairwise
checks. For this reason, only the pairwise overlap degrees
ω ij , shown in the bottom of Fig. 1, will play a role in the
analysis of the botnet identification algorithm. In order to
avoid misunderstanding, we remark that the meaning of the
forthcoming analysis is not that our strategy applies only
to pairs of clusters, but that a pairwise characterization is
sufficient to identify any arbitrary number of clusters.
III. C LUSTER I NTERACTION
Preliminarily, it is useful to introduce the following function,
for α,λ > 0:
R(α,λ) ?
αλ
α + λ .
(7)
In [39] it is shown that this function corresponds to the
MIR of a botnet that uses one and the same emulation
Fig. 1. Top. Illustration of the DDoS attack with multiple emulation
dictionaries. Bottom. Pairwise overlaps relative to the setting displayed in
the top.
dictionary, with EDR α and transmission rate λ, under either
a synchronous or Poisson scheduling. For later use, we report
also the following inequality, holding for any choice of positive
α,λ 1 ,λ 2 [39]:
R(α,λ 1 + λ 2 ) ≤ R(α,λ 1 ) + R(α,λ 2 ), (8)
which reflects the fact that the innovation rate of a botnet
made of two components transmitting at rates λ 1 and λ 2 , and
using the same emulation dictionary with EDR α, is upper
bounded by the sum of the innovation rates of the individual
components.
The following theorem establishes the coupling effect
between clusters that arises from the nonzero overlap between
their emulation dictionaries.
Theorem 1 (Pairwise MIR): Let B i and B j be subnets made
of bots belonging to cluster i and j, respectively. Assume that
the transmission policies of all bots are either deterministic
and synchronous (i.e., all bots transmit at regular intervals)
or governed by independent Poisson processes. In both cases,
the transmission rates are allowed to vary across bots. Then,
the limiting MIR of the joint subnet B i ∪ B j is:
? ρ B i ∪ B j (t)
m.s.
−−→ ρ B i ∪ B j = ω ij R(α,λ B i + λ B j )
+(1 − ω ij )[R(α,λ B i ) + R(α,λ B j )], (9)
where the symbol
m.s.
−−→ denotes mean-square convergence as
t → ∞.
Proof: See the Supplemental Material [46].
Equation (9) admits a clear interpretation. The MIR of the
botnet B i ∪ B j , which aggregates bots from clusters i and
j, is a convex combination, with weights ω ij and 1 − ω ij ,
of two types of MIRs. A fraction ω ij of the aggregate MIR is
given by the MIR corresponding to a botnet with transmission
rate λ B i +λ B j , whose members pick messages from the same
emulation dictionary. In comparison, a fraction 1−ω ij of the
aggregate MIR is given by the sum of the MIRs corresponding
to B i and B j . This fraction represents messages not picked
from the intersection between the two emulation dictionaries.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3559
It is also useful to compare (9) with the MIRs corresponding
to the cases of total overlap and absence of overlap, respec-
tively. We have from (8) and (9):
R(α,λ B i + λ B j ) ≤ ρ B i ∪ B j ≤ R(α,λ B i ) + R(α,λ B j ). (10)
In other words, the aggregate botnet B i ∪ B j is: i) more
innovative than a botnet where both clusters pick messages
from the same emulation dictionary (left inequality in (10),
total overlap); and ii) less innovative than a botnet where
the clusters pick messages from disjoint dictionaries (right
inequality in (10), no overlap at all).
IV. B OTNET I DENTIFICATION A LGORITHM
A botnet identification algorithm nicknamed BotBuster was
proposed in [39]. This algorithm is able to detect a botnet
possibly hidden in the network under the assumption that
there is a single emulation dictionary common to all bots
(i.e., no multi-cluster allowed), and with detection error that
vanishes as the observation time grows. We now manage to
illustrate how efficient botnet identification can be achieved
under the multi-cluster setting addressed in this work.
To this aim, we build an algorithm nicknamed BotClus-
terBuster, which is composed of two stages. The first stage
pertains to the formation of candidate bot clusters. The routine
implemented at this stage is inherited from BotBuster, which,
as said, was designed for the single-cluster case. Proving
that this routine can be useful in the multi-cluster setting as
well, requires significant effort and a novel analysis that relies
primarily on the results contained in Theorem 1. The second
stage pertains to cluster expurgation, a procedure necessary
to discard possibly false clusters from the set of candidates
produced in the first stage.
A. Cluster Formation
The core of BotClusterBuster is a pairwise comparison
between a pivot element (a single node or an estimated botnet)
and a test node. The final goal is to decide whether or not
the pivot and the test node form a botnet. Let us start by
considering a pivot node p, and a test node τ.
First, the algorithm computes the empirical MIRs corre-
sponding to node p, to node τ, and to their union, namely,
? ρ {p} (t), ? ρ {τ} (t), and ? ρ {p,τ} (t) — see (2). Now, the EDR is
not known beforehand, and when it is estimated from the
data one gets distinct values for the two nodes p and τ,
either because one or both nodes correspond to normal users,
or because of estimation errors. Therefore, it is necessary to
compute a common reference EDR. This is not an easy task,
since, e.g., intuitive solutions such as the average between
the EDRs of the individual nodes might lead to inconsistent
results — see [39]. In order to overcome this issue, in [39] a
Replacement and Reassignment (R&R) procedure is proposed.
This procedure relies on the intuition that, if some messages
from the node with higher estimated EDR are fictitiously
reassigned to the other node, the resulting EDRs tend to move
close to each other, until a common EDR? α(t) is reached. Once
this reference EDR is obtained, BotClusterBuster computes
the MIR that would correspond to a botnet with one and
TABLE II
B EHAVIOR OF THE MIR FOR THE C ASES D ESCRIBED IN THE M AIN T EXT
the same emulation dictionary (total overlap) having reference
EDR ? α(t), namely,
? ρ tot (t) ? R
? ? α(t), ?
λ {p,τ} (t) ? . (11)
We further introduce the sum MIR:
? ρ sum (t) ? ? ρ {p} (t) + ? ρ {τ} (t). (12)
Let us now delve into the analysis of the possible cases
that the algorithm encounters when testing nodes p and τ.
Depending on the nature of these nodes, there are three
possibilities — see the summary in Table II.
Case I: If p OR τ are normal, we have that:
? ρ {p,τ} (t) ≈ ? ρ sum (t), (13)
which intuitively stems from the fact that low correlation is
observed between normal users and between normal users and
bots. Moreover, it can be shown that [39]:
? ρ tot (t) ≤ ? ρ sum (t). (14)
Case II: If p AND τ are bots from the same cluster, for
sufficiently large t we have ? α(t) ≈ α and ? λ {p,τ} (t) ≈ λ p +λ τ ,
yielding:
? ρ {p,τ} (t) ≈ ? ρ tot (t) ≈ R(α,λ p + λ τ ). (15)
Case III: If p AND τ are bots from distinct clusters i and
j, from Theorem 1 we have:
? ρ {p,τ} (t)
≈ ω ij R(α,λ p + λ τ ) + (1 − ω ij )[R(α,λ p ) + R(α,λ τ )]
≈ ω ij ? ρ tot (t) + (1 − ω ij )? ρ sum (t), (16)
where in the second approximate equality we exploited the
relationship ? ρ tot (t) ≈ R(α,λ p + λ τ ), which can be proved
as in case II. Indeed, by examining the R&R procedure it is
readily seen that convergence of ? α(t) to α is not affected by
the fact that p and τ use distinct emulation dictionaries.
Assume now that we set a threshold equal to, for θ ∈ (0,1):
γ(t) = θ ? ρ tot (t) + (1 − θ)? ρ sum (t), (17)
and that the algorithm adopts the following rule:
? ρ {p,τ} (t) ≤ γ(t) ⇒ form an estimated botnet {p,τ}. (18)
Let us examine how such classification rule works under the
aforementioned three cases — see Fig. 2. When p or τ are
normal users (case I), from (13), (17) and (18) we conclude
that the algorithm rejects the hypothesis that {p,τ} is a botnet,
since the empirical MIR ? ρ {p,τ} (t) will be sufficiently close to
the upper boundary ? ρ sum (t). Likewise, when p and τ are bots
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3560 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Fig. 2. Time evolution of the relevant MIRs, for the three cases described in the main text.
sharing the same emulation dictionary (case II), from (15), (17)
and (18) we conclude that the algorithm accepts the hypothesis
that {p,τ} is a botnet, since the empirical MIR ? ρ {p,τ} (t) will
be sufficiently close to the lower boundary ? ρ tot (t). Finally, let
us examine the situation where p and τ are bots from distinct
clusters (case III). Assume that:
θ > ω ij . (19)
In this case, we see from (16), (17) and (18) that the
algorithm rejects the hypothesis that {p,τ} is a botnet, since
? ρ {p,τ} (t) will stay above the threshold. In summary, we see
that under condition (19) the algorithm ends up estimating a
botnet only when p and τ belong to the same cluster.
Iterating the above procedure yields the BotClusterBuster
algorithm, whose pseudo-code is reported at the top of this
page. The algorithm starts with node 1 as a pivot. If nodes 1
and 2 are classified as a botnet,
?
B(1;t) = {1,2}, otherwise
?
B(1;t) = {1}. At the end of the loop, the algorithm returns a
candidate botnet cluster
?
B(1;t) (in case the candidate cluster
has cardinality equal to 1, it is discarded). The loop is iterated
across the whole set of pivots, yielding a sequence of candidate
clusters, namely,
?
B(1;t), ? B(2;t),..., ? B(N;t).
We remark that the analysis of cases I–III is basically
unchanged if we replace the pivot node p with a subnet of bots
belonging to the same cluster. Accordingly, since for large t
the pairwise checks are all correct, they can produce either
empty sets or subnets of bots belonging to the same cluster.
In particular: i) if the initial pivot node is a normal user,
BotClusterBuster produces an empty cluster; ii) if the initial
pivot node is a bot from a certain cluster, BotClusterBuster
produces a candidate cluster matching the cluster the pivot
belongs to. Thus, provided that (19) is verified, as t → ∞ the
algorithm ends up estimating all the botnets corresponding to
the different clusters, reaching the twofold goal of discriminat-
ing bots from normal users and identifying the local structure
of the individual clusters.
In the absence of errors, the results produced by our algo-
rithm should not be affected by the initial pivot, in the follow-
ing sense. When the pivot is a normal user, BotClusterBuster
should produce an empty cluster. When the pivot is a bot, Bot-
ClusterBuster should end up with the cluster pertaining to that
bot. However, we notice that: i) we cannot know beforehand
how many clusters exist and, hence, we cannot select before-
hand one pivot for each cluster; and ii) in real-world data
some pivots can exhibit anomalous behavior, for example, over
Algorithm 1
?
B(t) = BotClusterBuster (traffic patterns
until time t, θ, β)
N = {1,2,..., N}
for p ∈ N do
?
B(p;t) = {p}
for τ ∈ N \ {p} do
γ(t) = θ? ρ tot (t) + (1 − θ)? ρ sum (t)
if ? ρ ?
B (p;t)∪{τ} (t) ≤ γ(t) then
?
B(p;t) = ? B(p;t)
? {τ}
end
if | ? B(p;t)| = 1 then
?
B(p;t) = ∅
% begin cluster expurgation
if
?
λ ?
B (p;t) (t) ≤ β ?
λ N (t) then
?
B(p;t) = ∅
% end cluster expurgation
end
?
B(t) =
N
?
p=1
?
B(p;t)
a particular realization, one legitimate user can be particularly
lazy in producing new messages and, hence, using it as pivot
can bias significantly the algorithm output. For these reasons,
to avoid biasing the results, in BotClusterBuster all pivots
have the same dignity, namely, the algorithm produces a set of
candidate botnets for each pivot node in {1,2,..., N}. Then,
the ensemble of candidate clusters is scanned and expurgated
using the strategy illustrated in the next section.
In accordance with what was found in [39], the nested loopy
structure of BotClusterBuster yields a computational complex-
ity scaling quadratically with the network size, which can be
conveniently distributed over multiple machines by means of
parallel implementations. In comparison to the problem of
finding a subset of nodes fulfilling an assigned condition,
which would lead in general to a combinatorial complexity,
a quadratic complexity arises because BotClusterBuster can
work in terms of pairwise checks. The question of whether
one can further reduce the complexity and still preserve botnet
identification consistency is open.
B. Cluster Expurgation
According to the analysis reported in the previous section,
the first stage of BotClusterBuster ends up delivering one
(possibly empty) candidate cluster per each initial pivot node.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3561
The most natural way to build the final estimated botnet is to
retain all the non-empty botnet clusters, namely, to consider
their union (union-rule). From a theoretical standpoint such
rule would provide perfect botnet identification. However,
in practice there are several non-ideal effects that can induce
coupling between normal users and/or between normal users
and bots. First of all, our analysis guarantees convergence
of certain relevant quantities for sufficiently long time, and
in practice we must face issues related to finite observation
windows. Second, the condition that normal users are mutually
independent and independent from bots (yielding an aggregate
MIR approximately equal to ? ρ sum (t), hence resulting into an
easy threshold up-crossing)cannot be perfectly met in practice.
Occasionally, we can have normal users that appear correlated
to other normal users or to some bots. As a matter of fact,
the algorithm usually delivers the true clusters plus some
false micro-clusters containing legitimate network users, due
to spurious correlations arising during the pairwise checks.
In the traditional single-cluster setting, this issue is easily
remediated by retaining only the estimated botnet with largest
cardinality (max-rule). This rule would obviously fail in the
multi-cluster scenario, since it will surely discard all but one
cluster.
In order to face this issue, the BotClusterBuster algorithm
implements a cluster expurgation strategy, aimed at: i) retain-
ing the true clusters, while ii) discarding the false ones. We
now propose a cluster expurgation strategy aimed at reaching
these goals. To this end, it is useful to highlight two important
“physical” aspects related to the bot clusters. First of all,
the power of a (symmetric) DDoS attack is determined by its
global transmission rate, λ B , relative to the global transmission
rate, i.e., λ B should be typically at least on the same order
of λ N . Second, the rate of an individual candidate cluster
must occupy a certain fraction of the overall botnet rate and,
hence, of the overall transmission rate. These two aspects can
be combined by establishing that the algorithm retains the
candidate cluster
?
B(p;t) if, and only if:
?
λ ?
B (p;t) (t) > β ?
λ N (t), (20)
where β ∈ (0,1) is the cluster expurgation hyperparameter
that determines the fraction of the total transmission rate below
which a cluster is reputed to be spurious. Finally, the estimate
of the entire botnet is produced by applying the union operator
to the survived clusters.
In order to select an appropriate value for β, we now relate
it to two physical parameters that are strictly tied with the
aforementioned two physical aspects. With regard to aspect
i), we say that we are under a meaningful DDoS attack if:
λ B = κ λ N \ B = κ (λ N − λ B ) ⇒ λ B =
κ
1 + κ
λ N , (21)
namely, if the global botnet activity is κ times the activity of
the normal users, with κ being typically at least equal to 1.
With regard to aspect ii), in order to deserve countermeasures,
a botnet cluster must sustain a reasonable part of the global
attack rate, namely,
λ B i ≥ ξλ B , (22)
for some ξ ∈ (0,1). Joining (21) with (22), the algorithm
retains the candidate cluster
?
B(p;t) if, and only if:
?
λ ?
B (p;t) (t) >
ξκ
1 + κ
?
λ N (t), (23)
which, in view of (20), creates the following link between the
cluster expurgation threshold β and the physical parameters κ
and ξ:
β = ξ
κ
1 + κ
. (24)
Needless to say, the adopted choice for cluster expurgation
is not unique, and other criteria are possible. For example,
perhaps the simplest one is to identify a minimum cluster
size and retain only clusters that exceed that size. However,
compared against our choice, the latter rule seems a bit less
related to physical considerations, and more based on an
absolute criterion, rather than relative to the network activity
observed on the data.
It is useful to comment on the role of the parameters
κ and ξ. Actually, the value of κ determines a safeguard
level at which we judge a botnet dangerous in terms of
resource saturation. Likewise, the value of ξ determines to
what extent we can tolerate to miss some small bot cluster.
Remarkably, setting these parameters introduces a flexible
degree of customization that is more related to the type of
service and users’ expectation for a particular application. For
example, the typical choice of a network administrator facing a
DDoS attack are: i) avoiding that the destination site crashes;
ii) guaranteeing proper service to the legitimate users. Under
these conditions, it is preferable not to be indulgent in cluster
acceptance, so as to reduce the likelihood of banning normal
users, perhaps at the price of losing some bots. Finally, it is
important to remark that, to guarantee proper functioning of
BotClusterBuster, the network administrator does not need
a detailed knowledge of the attack characteristics. In other
words, it is not necessary to estimate precise values of κ and
ξ. Rather, it is sufficient to make a conservative choice so as
to set a cluster expurgation threshold β < ξκ/(1 + κ). This
particular aspect will be illustrated in detail in Sec. VI-A.
V. P RACTICAL I SSUES
In real-world settings, we cannot expect that the technical
conditions used to prove our mathematical claims are perfectly
met. For this reason, in this section we examine some relevant
scenarios that are not covered by the previous analysis, and
verify whether BotClusterBuster can deliver satisfying perfor-
mance even under these perturbed conditions.
A. Violation of Condition (19)
The choice of the parameter θ in (19) can be determined
by different factors. Preliminarily, we notice that the case
ω ij ≈ 1 (total overlap) is of scarce interest here, since it
basically corresponds to the single cluster case already dealt
with in [39]. Thus, let us assume that ω ij takes on some
intermediate value. On one hand, we could conservatively
set the threshold parameter θ close to 1 in order to be sure
that (19) holds true. On the other hand, if θ collapses to 1,
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3562 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Fig. 3. Botnet identifiability vs. cluster identifiability.
the threshold γ(t) collapses to the lower boundary ? ρ tot (t),
thus reducing the likelihood that the estimated MIR ? ρ {p,τ} (t)
stays below the threshold. Accordingly, there is a certain
flexibility in the choice of θ that should be taken into account
in practice. For this reason, it makes sense to examine whether
the algorithm is robust to violation of (19).
In presence of this violation, it is readily seen that, among
cases I–III described before, only case III changes. In fact,
provided that θ is not collapsing to 0 or 1, in cases I
and II the estimated MIR ? ρ {p,τ} (t) stays above or below
the threshold, respectively. In contrast, when case III is in
force, nodes p and τ belong to distinct clusters with partially
overlapped emulation dictionaries, which implies that, since
(19) is violated, the threshold γ(t) becomes larger than the
MIR associated to the botnet {p,τ} — see (16) and (17).
Accordingly, the algorithm would classify the pair {p,τ} as a
botnet even if p and τ belong to distinct clusters. In principle,
this is not a problem, since what we need is to distinguish
bots from normal users, and not to separate the bot clusters.
This property is illustrated in Fig. 3, where we see the two
possible behaviors of the algorithm, depending on whether θ
is greater or smaller than the overlap degree ω ij . In summary,
if θ < ω ij , the algorithm is able to identify membership to the
overall botnet, while if θ > ω ij the algorithm is able to identify
the additional attribute of membership to the individual cluster.
Unfortunately, the analysis in this section is not sufficient
to establish rigorously the consistency of BotClusterBuster
under violation of (19). This is because, due to the impos-
sibility of discriminating the individual clusters, when the
algorithm progresses the intermediate pivot botnets can be
mixed, i.e., comprising bots of different clusters. The technical
analysis of this case appears to be nontrivial. Nevertheless,
we will show that the dichotomy illustrated in Fig. 3 is cor-
roborated by the numerical analysis conducted in Sec. V-C as
well as by the results observed in our experimental campaign
illustrated in Sec. VI. This dichotomy becomes especially
relevant once we note that the degree of overlap between
pairs of dictionaries is expected to be seldom available in
practical applications. Accordingly, we have at least two useful
conclusions arising from Fig. 3. On one hand, we conclude
that achieving individual cluster identification should not be so
hard since condition (19) does not require detailed knowledge
of the degree of overlap ω ij , a rough prediction is sufficient,
so as to let θ > ω ij . Therefore, a pragmatic choice for the
network administrator is to set a relatively high value of θ
(i.e., 0.9, 0.95), which means that condition (19) would be
violated only if two dictionaries are extremely overlapped.
Under these conditions, BotClusterBuster will be able to dis-
tinguish properly all clusters, but for the clusters featuring very
overlapped emulation dictionaries, which would be eventually
merged since they are in fact akin to a single cluster with the
same emulation dictionary. On the other hand, we remark that,
as we will clearly see in the experimental analysis, only the
identifiability of individual clusters is affected by the choice of
θ. Accordingly, the final goal of the network administrator of
banning all bots belonging to the botnet, is actually preserved
even when condition (19) is violated. In summary,we conclude
that the choice of the threshold parameter θ is not critical for
proper functioning of BotClusterBuster.
B. Clusters’ Asymmetries
Another assumption adopted so far pertains to the equal
distribution of the emulation dictionaries across the network.
Assume instead that different clusters are assigned unbalanced
emulation dictionaries, yielding different EDRs, namely, for
i = 1,2,...,C:
α i = lim
t→∞
|E i (t)|
t
. (25)
Likewise, we now allow for variable overlap degrees.
Formally, the common intersection E ij (t) of the dictionaries
pertaining to clusters i and j has a degree of overlap with
E i (t) and E j (t) given by, respectively:
ω ij = lim
t→∞
|E ij (t)|
|E i (t)|
, ω ji = lim
t→∞
|E ij (t)|
|E j (t)|
. (26)
We notice that simultaneous verification of (25) and (26)
entails the following relationship:
α ij ? lim
t→∞
|E ij (t)|
t
= α i ω ij = α j ω ji . (27)
Actually, the proof of Theorem 1 does not require any
symmetry assumption. In particular, the proof reported in the
Supplemental Material [46] is carried out under the aforemen-
tioned asymmetric scenario, and the resulting MIR referred to
clusters i and j is:
ρ B i ∪ B j = R(α ij ,λ B i ω ij + λ B j ω ji )
+(1 − ω ij )R(α i ,λ B i ) + (1 − ω ji )R(α j ,λ B j ).
(28)
Despite the fact that the limiting MIR corresponding to
partially overlapped dictionaries can be precisely evaluated
using (28), in the asymmetric scenario it is hard to exploit
this relationship to prove consistency of BotClusterBuster.
In fact, the asymmetry introduced by the unknown parame-
ters α i ,α j ,ω ij ,ω ji , precludes the simple extension of the
arguments used in Sec. IV-A to examine cases I–III. For
example, when α i = α j we cannot claim that the reference
EDR ? α(t) obtained from the R&R procedure converges to
some known value. As a result, we are no longer in the
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3563
Fig. 4. Graphical illustration of the scenario described in Sec. V-C, with
two subnetworks, S a = S 1a ∪S 2a and S b = S 1b ∪S 2b , each one containing
bots belonging to clusters 1 and 2.
position of establishing the limiting behavior of ? ρ tot (t), and,
hence, of the threshold γ(t). Nevertheless, we have collected
numerous numerical evidences where, for various choices of
the parameters characterizing the aforementioned asymmetric
scenario, the following inequality is observed:
? ρ S a ∪ S b (t) > ? ρ tot (t) = R(? α(t),λ S a + λ S b ), (29)
for two subnets S 1 and S 2 , each one containing bots belonging
to distinct clusters i and j. Since i) Eq. (29) implies that the
empirical MIR corresponding to S a ∪S b is larger than the MIR
associated to the reference EDR ? α(t); and ii) the empirical
MIR ? ρ S a ∪ S b (t) is obviously upper bounded by the sum of the
individual MIRs, we conclude that under these conditions the
evolution of BotClusterBuster would be basically unchanged.
C. Numerical Analysis
As remarked in Secs. V-A and V-B, a rigorous treatment
of the non-ideal scenarios described in these sections is
definitely nontrivial. For this reason, we now focus on a
numerical analysis aimed at capturing the expected behavior
of BotClusterBuster under these non-ideal scenarios.
We have examined the MIR arising from pairs of subnets of
mixed type, i.e., each one containing bots from two distinct
clusters, and for several sets of parameters. The considered
scenario is illustrated in Fig. 4. We have two subnets:
S a = S 1a ∪ S 2a , S b = S 1b ∪ S 2b , (30)
where each subnet is made of bots from both clusters 1 and 2.
The subscripts 1 and 2 are used accordingly to denote subnets
belonging to the pertinent clusters. Now, let α 1 and λ 1 =
λ S 1a + λ S 1b be, respectively, the EDR and the transmission
rate of the botnet S 1a ∪S 1b coming from cluster 1. Likewise,
α 2 and λ 2 = λ S 2a + λ S 2b will denote, respectively, the EDR
and the transmission rate of the botnet S 2a ∪ S 2b aggregating
bots from cluster 2. In the following analysis, we set α 1 = 1
and let α 2 vary. We consider the limiting MIRs evaluated using
the theoretical formulas, and accordingly denoted without the
symbol ? and without time-dependence.
In Fig. 5, we display ρ S a ∪ S b and ρ tot as functions of α 2 ,
for balanced transmission rates λ S 1a = λ S 1b = λ S 2a = λ S 2b =
3, and for three values of the overlap degree ω 12 . We recall
that, in view of (27), the value of ω 21 is uniquely determined
from the values α 1 , α 2 and ω 12 . We see that the inequality
Fig. 5. Numerical analysis aimed at testing verification of the inequality
? ρ S a ∪ S b > ? ρ tot . The pertinent MIRs are displayed as functions of α 2 (with
α 1 = 1), and computed for different values of the overlap degrees.
Fig. 6. Numerical analysis aimed at testing verification of the inequality
? ρ S a ∪ S b > ? ρ tot . The pertinent MIRs are displayed as functions of α 2 (with
α 1 = 1), and computed for different values of the transmission rates of the
single subnetworks and clusters.
in (29) is confirmed across the whole range of α 2 and for
all the considered values of overlap. Furthermore, for very
small values of α 2 all the curves tend to collapse, since they
correspond to the degenerate case where cluster 2 has empty
emulation dictionary.
In Fig. 6 we repeat the analysis by using an intermediate
overlap degree ω 12 = 0.5, and by considering different values
for the transmission rates, corresponding to four practical
scenarios. Scenario 1 (dashed-dotted curves) accounts for the
case where the activity of subnet S a is predominant w.r.t. the
activity of S b . Under scenario 2 (dashed curves), the activity
of bots from cluster 2 is more intense than the activity of bots
from cluster 1. Scenarios 3 (dotted curves) and 4 (solid curves)
are mixed combinations of the other two scenarios.
Remarkably, in all our experiments we observed that (29)
was verified. While we cannot claim that BotClusterBuster is
consistent when (19) is violated and/or under the asymmet-
ric scenario, the conducted numerical analysis explains why
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3564 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
BotClusterBuster is in fact able to discriminate bots from
normal users under various practical conditions, as we will
see in detail in the section devoted to simulations.
VI. E XPERIMENTAL R ESULTS
In this section we report the results of an experimental
campaign that we have conducted to validate the theoreti-
cal analysis developed in the previous sections. In order to
provide a quantitative assessment of the botnet identification
performancewe introduce two indicators, namely, the expected
fraction of correctly identified bots and the expected fraction
of normal users declared as bots, namely,
η bot (t) =
E[| ˆ B(t) ∩ B|]
|B|
, η nor (t) =
E[| ˆ B(t) ∩ (N \ B)|]
|N \ B|
.
(31)
where
?
B(t) denotes the botnet estimated at time t. Ideally,
we want an identification algorithm that, for sufficiently long
observation time, estimates a botnet comprising all the true
bots and no normal users, which amounts to:
lim
t→∞
η bot (t) = 1, lim
t→∞
η nor (t) = 0. (32)
Let us now delve into the description of the experimental
setup. First of all, we constructed two different datasets
containing traffic patterns from legitimate network users. In
the forthcoming analysis, we will test BotClusterBuster over
both datasets. The first dataset, which will be referred to as
CampusDataset, was built by asking 100 people, randomly
polled around the Campus of the University of Salerno,
to query an auction portal for about 3 minutes. The second
dataset, which will be referred to as LabDataset, was built
in the Co.Ri.Tel Laboratory of the University of Salerno. We
asked 10 people among students and researchers to query an
e-commerce portal for about 20 minutes. With regard to this
dataset, in order to obtain a larger number of legitimate users,
we divided the traffic patterns into chunks lasting about 2
minutes, and considered each chunk as an independent user,
obtaining a total number of 100 normal users. In both datasets,
each traffic “track” is representative of a normal user. The
application-layer patterns of these tracks have been captured
by a network sniffer.
Once the normal users activity has been produced, we focus
on the multi-cluster DDoS attack. Different from what
obtained for normal users, for the botnet we did not have
access to real-world application-layer attacks. Accordingly,
on the same website where the normal users surfed, we crafted
the bot patterns by randomly picking valid HTTP requests
from the ensemble of requests produced by the monitored
real-world users. 1 Let us now illustrate how the emulation
dictionary is split over the individual clusters. We will consider
3 clusters. First, we join all the normal-user tracks pertaining
to the particular dataset, obtaining 27072 packets for the
CampusDataset and 22178 packets for the LabDataset, and
consider this ensemble of messages as the overall emulation
1 Needless to say, we did not launch a DDoS attack against any website.
We simulated the emission of requests, without effectively sending these
requests to the target site.
dictionary to be disseminated across the botnet. We remark
that using the same messages chosen by the normal users
automatically introduces a correlation between these latter and
the bots, which makes botnet identification even more difficult.
Then we divide the overall dictionary into 7 sets:
E 1 , E 2 , E 3 , E 12 , E 13 , E 23 , E 123 , (33)
where i) all sets are mutually disjoint; ii) the indices appearing
as subscripts denote the cluster(s) using messages in that
particular set. For example, E 1 contains messages that can be
accessed only by cluster 1 and E 123 contains messages that are
available for all clusters. Then, let us focus on cluster 1 for the
sake of definiteness. As initialization, we assume that at time
t = 0 the emulation dictionary E 1 (0) contains 100 messages
chosen, e.g., from E 1 . Then, at time t > 0 the dictionary E 1 (t)
adds to these 100 messages ?α 1 t? messages picked from the
sets relative to cluster 1, partitioned as follows:
?α 1 ω 123 t? from E 123 ,
?α 1 (ω 12 − ω 123 )t? from E 12 ,
?α 1 (ω 13 − ω 123 )t? from E 13 ,
?α 1 (1 − ω 12 − ω 13 + ω 123 )t? from E 1 , (34)
where ω 12 and ω 13 are the overlap degrees introduced in (26),
and ω 123 is the (sub-)fraction of elements that is picked from
the intersection E 123 , common to all the three clusters. 2 The
same procedure is applied to all clusters. Then it is easily
verified that the dictionary construction fulfills the following
conditions, for all i, j ∈ {1,2,3}:
lim
t→∞
|E i (t)|
t
= α i , lim
t→∞
|E i (t) ∩ E j (t)|
|E i (t)|
= ω ij . (35)
In order to make the bots similar to legitimate users, both
the bot transmission rates and the EDR have been chosen on
the same order of the corresponding attributes estimated over
the normal users’ traces. Finally, in the following experiments
we will consider 3 clusters, for different network sizes, cluster
cardinalities, and EDRs. The specific setup of each simulation
is detailed in Table III. We are now ready to examine the
performance of the BotClusterBuster algorithm. We start by
considering the setup reported in the first row of Table III.
In Fig. 7, from left to right, we illustrate the results cor-
responding to decreasing values of the threshold parameter
θ ∈ {0.95,0.9,0.75,0.5}.Let us start by examiningthe bottom
plots, where we display an algorithm snapshot corresponding
the end of the observation window. The decisions produced
by the algorithm are encoded in a graphical matrix, whose
p-th row corresponds to the output of the algorithm when
user p is elected as a pivot. Users are ordered for clarity
of visualization, but this ordering is immaterial, since in our
simulations the bots were randomlyspread over the network. A
white pixel represents the “estimated bot presence”, whereas
a black pixel represents the “estimated bot absence”. Thus,
2 With regard to the picking rule in (34), it is readily seen that not all
configurations of the parameters α i , ω ij and ω 123 are compatible with all
configurations of the sets in (33). We have verified that the configurations
used in our simulations are admissible, which roughly amounts to say that
the cardinalities of the pertinent sets are sufficiently large to make the choices
in (34) admissible for the entire duration of the observation period.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3565
TABLE III
E XPERIMENTS .F OR E ACH E XPERIMENT ,W E R EPORT THE C HOSEN S ETUP . A LL THE E XPERIMENTS W ERE R UN O VER B OTH THE C AMPUS D ATASET AND
THE L AB D ATASET .I N A LL C ASES , W E U SED A C LUSTER E XPURGATION T HRESHOLD β = 0.05, A RISING F ROM THE C HOICES κ = 1 AND ξ = 0.1
Fig. 7. Experiments corresponding to the first configuration in Table III. Top and middle rows. Performance of the botnet identification algorithm, evaluated
over the LabDataset (top) and the CampusDataset (middle). Bottom row. Algorithm snapshot corresponding the end of the observation window: the decisions
produced by the algorithm are encoded in a graphical matrix whose p-th row corresponds to the output of the algorithm when user p is elected as a pivot.
A white pixel in the location (p,q) signifies that the algorithm is estimating (before applying the particular cluster selection rule) that user q is a bot when
user p is elected as pivot. We consider different values of the threshold parameter, in particular, from left to right we have θ = 0.95,0.9,0.75,0.5. The
algorithm snapshots correspond to the CampusDataset.
if pixel (p,q) is white, the algorithm is estimating (before
applying the particular cluster selection rule) that user q is a
bot when user p is elected as pivot.
For θ = 0.95 (bottom row, leftmost plot), condition (19)
is met for the largest degree of overlap, i.e., ω 12 = 0.75.
The presence of the three big white squares of sides 20, 30,
and 50 means that the algorithm is able to identify the 3
clusters properly, in agreement with the theoretical predictions.
We notice also the occasional presence of some white pixels
in the top right block. These pixels correspond to very small
clusters composed of about 2 or 3 normal users. Notably,
the small size of these clusters reveals that the algorithm can
occasionally form a wrong cluster, but that then this cluster
is never paired with other users, i.e., it is very unlikely that
more than a few users can form a wrong botnet. This property
is very important, since clusters with so small cardinalities
cannot have any significance in practice, and there are many
rules one can conceive to discard them. In particular, we will
now see whether the proposed cluster expurgation rule is able
to get rid of this effect. Moreover, we notice that the big
white squares corresponding to the true clusters contain some
black gaps, and are accompanied by some horizontal white
bands. For what concerns gaps, a black pixel in position (p,q)
signifies that the algorithm is not estimating q as member of
the botnet when p is pivot. However, BotClusterBuster is on
purpose designed so as to perform redundant checks, i.e., the
same pairs of nodes are involved in multiple checks. In this
way, a bot is missed only if it is missed by all checks. For
this reason, we see that the occasional black gaps observed in
the white squares are irrelevant if at least one time each bot is
included in a cluster. In the end, the overall set of nodes that
belong at least to one cluster corresponds to the white pixels
covering the main diagonal of the graphical matrix. In relation
to the horizontal white bands, a collection of white pixels in
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3566 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
row p means that the pivot p results paired with many nodes
q, which results into the formation of a relatively large cluster.
Accordingly, we see that occasionally some bots of one cluster
appear paired with bots of another cluster. This effect is clearly
not relevant for DDoS mitigation, as can be concluded from
the fact that η bot (t) ≈ 1 — see the performance curves shown
in the top and middle plots of Fig. 7.
For θ = 0.9 (bottom row, second plot from the left),
condition (19) is still met, however, we are approaching the
case θ = 0.75 which would result into a violation of (19).
Accordingly, we see that the images of the individual clusters
starts to become a bit blurred. When we set θ = 0.75 (bottom
row, third plot from the left), condition (19) is violated, and,
as predicted from our analysis in Sec. V-A, the algorithm does
not lose the capability of identifying the botnet, but loses the
capability of identifying the individual clusters. In particular,
since in our example we have θ = ω 12 = 0.75, but we
have also θ > ω 13 = ω 23 = 0.5, we see that the first two
clusters are merged into a big one, whereas the third cluster
is still correctly identified. Finally, this capability is lost when
θ = 0.5 (bottom row, rightmost plot), which corresponds to
the estimation of a unique big botnet comprising all 100 bots.
Moreover, in the case θ = 0.5 we notice the emergence of
some vertical white bands. A band in column q means that
there exists a node q that results paired with many pivots p.
This corresponds to the formation of many small clusters, one
for each paired pivot. Accordingly, we see that some spurious
small clusters made of normal users arise. As we will see
soon, this effect will play a role in the performance of the
union-rule.
Let us move on to examine the plots in the top and middle
rows of Fig. 7, where we display the algorithm performance
expressed in terms of the indicators η bot (t) and η nor (t), which
have been evaluated over 100 Monte Carlo runs. Top plots
refer to the LabDataset, middle plots to the CampusDataset.
For the sake of clarity, in the following analysis we refer to
the top plots, with similar conclusions holding for the middle
plots. The DDoS evolution is monitored during the observation
window with a time-step of 2 seconds. We show the results
corresponding to the three rules introduced in the previous
sections, namely, the max-rule, the union-rule and the cluster
expurgation rule.
Let us consider first the case θ = 0.95 (top row, leftmost
plot), which meets well condition (19). We start with the
max-rule. From the evolution of η nor (t) (black dashed curve),
we see that the max-rule is effective in rejecting the false
micro-clusters. This happens since the max-rule retains only
the maximum-cardinality cluster, which has however a detri-
mental effect as regards the bot identification. Indeed, we see
that η bot (t) (black solid curve) converges approximately to 0.5,
which means that only the biggest cluster made of 50 bots is
correctly identified.
We continue by illustrating the behavior of the union-rule.
Here we see that the bot identification issue is remediated,
since η bot (t) (red solid curve) converges to 1. This happens
because the union-rule aggregates the detected clusters of any
cardinality. On the other hand, this effect is detrimental as
regards the normal users classification. Indeed, we see that
η nor (t) (red dashed curve) converges approximately to 0.1.
However, this effect must be expected, especially in light of
the analysis of the bottom plots in Fig. 7. The union-rule is in
fact aggregating many clusters of very small cardinality. This
means that, under the union-rule, we are claiming that there
exist a DDoS attack launched by several botnets comprised
of 2 or 3 members, which appears to be a very uncommon
scenario.
Another notable effect observed in the time-evolution of
η nor (t) is the appearance of a peak at some intermediate time.
The explanation of this peak sheds some further light on the
detrimental effects produced by the union-rule. Examining the
individual traffic patterns, we identified one specific normal
user that was performing some anomalous activity. In partic-
ular, they were performing some very intense activity for a
single slot during the entire observation window. As a result,
during this slot of intense activity, this user was coupled to a
very large number of other normal users, giving rise to several
micro-clusters of size 2. The union-rule was then including all
these clusters into the estimated botnet, producing the peak
observed in η nor (t). This effect disappears progressively as
time elapses, since the abnormal behavior of the particular
user is not persistent over time.
Let us finally see whether the cluster expurgationrule is able
to solve both issues experienced under the max-rule and the
union-rule. The performance of BotClusterBuster is accord-
ingly displayed in blue. We see that this algorithm has very
good performance, since η bot (t) (blue solid curve) converges
approximately to 1, and η nor (t) (blue dashed curve) converges
approximately to 0. With regard to the hyperparameterβ of the
cluster expurgation rule, in the experiments we set κ = 1 and
ξ = 0.1, yielding, in view of (24), β = 0.05. We remark that
these are very “agnostic” choices. Indeed, the choice κ = 1
corresponds to say that a DDoS with attack rate barely equal
to a legitimate traffic rate is deemed as dangerous. Likewise,
the choice ξ = 0.1 corresponds to say that a cluster is deemed
as meaningful if it sustains barely 10% of the botnet activity.
From the analysis of the top left plot in Fig. 7, we conclude
that BotClusterBuster delivers good performance under the
conditions used to prove our theoretical results. Let us now see
how a reduction of the threshold parameter θ influences the
performance. To this end, we examine the second, third and
fourth top plots in Fig. 7. For what concerns the max-rule,
we see that η nor (t) (black dashed curve) converges approx-
imately to 0 in all cases. In other words, the performance
in terms of normal users is not affected by variations of
θ. In comparison, for the max-rule the index η bot (t) (black
dashed curve) is sensitive to θ, and in particular increases as
θ decreases. For example, when the algorithm aggregates two
clusters into a big cluster of size 80, then η bot (t) converges
approximately to 0.8 (top row, third plot from the left),
whereas when a unique cluster is produced, then η bot (t)
converges approximately to 1 (top row, rightmost plot).
For what concerns the union-rule, we see that η bot (t)
(red solid curve) converges approximately to 1, irrespective
of the value of θ, which is expected since the union rule
aggregates all detected clusters and, hence, is not sensitive
to the individual clusters. On the other hand, the union-rule
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3567
Fig. 8. Experiments corresponding to the second configuration in Table III.
Top. Performance of the botnet identification algorithm. Bottom. Algo-
rithm snapshot corresponding the end of the observation window: the decisions
produced by the algorithm are encoded in a graphical matrix whose p-th row
corresponds to the output of the algorithm when user p is elected as a pivot.
A white pixel in the location (p,q) signifies that the algorithm is estimating
(before applying the particular cluster selection rule) that user q is a bot when
user p is elected as pivot. Left plots refer to the LabDataset, whereas right
plots to the CampusDataset.
performance degrades severely when we decrease the value of
θ, since lower values of θ favor the emergence of false micro-
clusters. Accordingly, we see that η nor (t) (red dashed curve)
increases, i.e., the performance degrades as θ decreases.
So far we have shown that BotClusterBuster provides proper
cluster identification when the technical conditions used to
prove the theoretical results are met, and continues to provide
proper botnet identification even when condition (19) is vio-
lated. Now we want to check what happens when we deviate
further from the nominal conditions by allowing for clusters’
asymmetries, as described in Sec. V-B. Specifically, we focus
on the configuration reported in the second row of Table III.
We notice that in this asymmetric setting, the overlap degrees
ω 21 , ω 31 and ω 32 can be obtained from the overlap degrees
shown in the table by exploiting the constraints in (27). The
results of these experiments are reported in Fig. 8, with
reference to the case θ = 0.95, and for the two datasets,
namely, LabDataset (left) and CampusDataset (right). As
predicted by the numerical analysis carried out in Sec. V-C,
asymmetries in the EDRs do not lead to significant variations
in the botnet identification performance. In summary, we reach
the remarkable conclusion that both the asymmetries and the
violation of (19) do not impair consistent botnet identification.
A. Sensitivity to Algorithm and Attack Parameters
The simulation setup considered in the previous section was
constructed according to the following logic. In our datasets,
we arrive at a maximum number of normal users equal to
100. Accordingly, we considered a DDoS attack where the
total number of bots is equal to the number of legitimate
users and all bots have rates comparable to legitimate users,
so as not to arouse suspicion. Regarding the hyperparameters
of BotClusterBuster, the experiments in Figs. 7 and 8 already
Fig. 9. Performance of the botnet identification algorithm for the third con-
figuration in Table III, relative to the LabDataset (top) and the CampusDataset
(bottom). In the left plots we used a threshold parameter θ = 0.95, whereas
in the right plots θ = 0.5.
spanned a range of values for the threshold parameter θ and
examined its impact on the botnet identification performance.
It remains to examine the role of the other hyperparameter,
namely, the cluster expurgation threshold β. In the examples
presented so far, we computed β starting from the “physical”
parameters κ and ξ described in Sec. IV-B. In particular,
we set: κ = 1, which corresponds to a balanced network
administrator that starts being alerted when the request rate
coming from the botnet is comparable with the request rate
coming from normal users; and ξ = 0.1, which corresponds
roughly to the assumption that the smallest cluster carries at
least 1/10 of the global botnet activity. Figures 7 and 8 show
that BotClusterBuster performs well under the considered
setup. Now we want to examine the effect of varying this
setup. To this end, we could vary the values of κ and ξ
by keeping the attack parameters fixed, or varying the latter
parameters while keeping fixed the former. For the sake of
clarity, we find it convenient to opt for the second choice, and
accordingly consider the following two paradigmatic cases.
– Network Administrator “anxious” in comparison to the
real attack. Under this setup (third row in Table III), the bots
are distributed over three clusters of sizes 75, 65, and 60. As a
consequence, the cluster expurgation threshold chosen by the
network administrator, which stems from the choices κ = 1
and ξ = 0.1, turns out to be conservative, in the sense that
the minimum expected cluster is significantly smaller than the
smallest cluster effectively present in the data. The left plots
(one for each dataset) in Fig. 9 refer to the case where the
threshold parameter is θ = 0.95, namely, condition (19) is
fulfilled. Accordingly, since the network administrator made
a conservative choice, we see that BotClusterBuster is con-
sistently able to identify the botnet, and particularly the
individual clusters. In comparison, the right plots address the
case θ = 0.5, where all bots are still correctly guessed, while
the individual cluster identifiability is lost. We remark that,
under this setting where individual cluster identifiability is of
no concern, the influence of the cluster expurgation parameters
becomes immaterial.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3568 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Fig. 10. Performance of the botnet identification algorithm for the fourth
configuration in Table III, relative to the LabDataset (top) and the Campus-
Dataset (bottom). In the left plots we used a threshold parameter θ = 0.95,
whereas in the right plots θ = 0.5.
– Network Administrator “relaxed” w.r.t. to the real attack.
Under this setup (last row in Table III), the bots are distributed
over three clusters of sizes 25, 20, and 5. Now, the cluster
expurgation threshold set by the network administrator, stem-
ming from the choices κ = 1 and ξ = 0.1, corresponds to a
“relaxed” choice, in the sense that the network administrator
judges dangerous an attack stronger than the attack actually
taking place. As a result, the minimum expected cluster is
now larger than the smallest cluster effectively present in the
data. The left plots in Fig. 10 confirm this observation, since
we see that η bot (t) saturates to 0.9, which corresponds to the
fact that the smallest cluster of size 5 is missed. Remarkably,
the right plots in Fig. 10 show that we can conveniently trade
off cluster identifiability for correct identification of the entire
botnet (η bot (t) → 1), a capability that is in fact fully recovered
with the intermediate threshold θ = 0.5.
VII. L IMITATIONS AND P ERSPECTIVES
We considered Distributed Denial of Service (DDoS) attacks
launched by a botnet whose members have access to an
emulation dictionary made of admissible requests to mimic
the activity of legitimate network users. The emulation dic-
tionary is distributed across the bots, in such a way that
different clusters of bots pick their messages from different
emulation dictionaries. These dictionaries entail a certain
diversity, i.e., they are not totally overlapped, but also some
commonalities, i.e., their intersection is not empty. For this
novel and challenging scenario, we have first computed the
message innovation rate corresponding to pairs of bot clusters.
We showed that the aggregate innovation rate is a convex
combination, with weights ruled by the overlap degree, of:
i) the innovation rate of a single botnet aggregating the two
clusters and using a single emulation dictionary; and ii) the
sum of the individual innovation rates. This technical result
was useful to devise and examine a botnet identification
algorithm nicknamed BotClusterBuster, which was specifically
equipped with a cluster expurgation rule to manage the
appearance of spurious clusters that should be judiciously
discriminated from the multiple co-existing bot clusters. From
a theoretical standpoint, we showed that BotClusterBuster
provides exact classification of bots and normal users under
reasonable technical conditions. From a practical standpoint,
we assessed the resilience of this algorithm in presence
of deviations from these technical conditions, both through:
i) a numerical analysis carried over a broad range of system
parameters; ii) an experimental campaign conducted over two
real traffic dataset crafted, under different operative conditions,
in our Laboratory and in our University Campus.
The bottom line is that correct botnet identification under
DDoS attacks with multiple emulation dictionaries is possible,
and the proposed technique seems promising, particularly
because it looks robust to several practical issues that are
expected in practice, such as, e.g., deviation from nominal
conditions, setting of the hyperparameters, large variability
across the activities of real-world network users.
The above summary highlights the potential fruitful appli-
cation of the methods proposed in this work in the context
of L7-DDoS attacks. On the other hand, these methods have
certainly limitations, leaving several questions open.
One limitation of our study is that, while we were able to
use real-world traffic traces for the normal users, the malicious
traffic traces were instead synthetically generated according
to a random mechanism, picking messages from the set of
legitimate requests produced by the real-world monitored
users. As it is well known, malicious traces taken from
real-world applications are not publicly available, or are avail-
able under limited permissions that do not allow to extract
sufficient information to test the pertinent algorithms. For these
reasons, we were not able to get permissions to obtain an
application-layer DDoS real-world attack with accessible mes-
sage content. Validating the conducted analysis also on data
taken from real DDoS attacks would constitute an important
progress.
Another relevant aspect pertains to computational complex-
ity. The identification algorithm features a complexity scaling
quadratically with the network size. A useful extension would
be the design of novel algorithms to reduce the computational
burden while still ensuring botnet identification.
Finally, recent and powerful asymmetric DDoS variants
have been considered, where, e.g., few HTTP requests can
produce bulky responses from the target website, inducing an
amplification effect that saturates the target resources with a
relatively small amount of carefully chosen HTTP requests.
Albeit the focus of this work was on symmetric L7-DDoS
attacks, it is worth exploring whether some of the method-
ologies to detect anomalous correlation between bots can be
leveraged also in asymmetric scenarios.
A CKNOWLEDGMENT
The authors are indebted to Alfonso Esposito, who assem-
bled the CampusDataset used in the experiments.
R EFERENCES
[1] M. Cirillo, M. D. Mauro, V. Matta, and M. Tambasco, “Application-layer
DDoS attacks with multiple emulation dictionaries,” in Proc. IEEE Int.
Conf. Acoust., Speech Signal Process. (ICASSP), Toronto, ON, Canada,
Jun. 2021, pp. 2610–2614.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3569
[2] M. Barni and B. Tondi, “The source identification game: An information-
theoretic perspective,” IEEE Trans. Inf. Forensics Security, vol. 8, no. 3,
pp. 450–463, Mar. 2013.
[3] A. Abrardo, M. Barni, K. Kallas, and B. Tondi, “A game-theoretic
framework for optimum decision fusion in the presence of Byzantines,”
IEEE Trans. Inf. Forensics Security, vol. 11, no. 6, pp. 1333–1345,
Jun. 2016.
[4] M. Barni and B. Tondi, “Source distinguishability under distortion-
limited attack: An optimal transport perspective,” IEEE Trans. Inf.
Forensics Security, vol. 11, no. 10, pp. 2145–2159, Oct. 2016.
[5] M. Mardani, G. Mateos, and G. B. Giannakis, “Dynamic anomalogra-
phy: Tracking network anomalies via sparsity and low rank,” IEEE J.
Sel. Topics Signal Process., vol. 7, no. 1, pp. 50–66, Feb. 2013.
[6] P. Venkitasubramaniam, T. He, and L. Tong, “Anonymous network-
ing amidst eavesdroppers,” IEEE Trans. Inf. Theory, vol. 54, no. 6,
pp. 2770–2784, Jun. 2008.
[7] J. Kim and L. Tong, “Unsupervised and nonparametric detection of
information flows,” Signal Process., vol. 92, no. 11, pp. 2577–2593,
Nov. 2012.
[8] S. Marano, V. Matta, T. He, and L. Tong, “The embedding capacity
of information flows under renewal traffic,” IEEE Trans. Inf. Theory,
vol. 59, no. 3, pp. 1724–1739, Mar. 2013.
[9] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, “DDoS in the IoT:
Mirai and other botnets,” Computer, vol. 50, no. 7, pp. 80–84, 2017.
[10] M. J. Farooq and Q. Zhu, “Modeling, analysis, and mitigation of
dynamic botnet formation in wireless IoT networks,” IEEE Trans. Inf.
Forensics Security, vol. 14, no. 9, pp. 2412–2426, Sep. 2019.
[11] M. Hammoudeh et al., “Network traffic analysis for threat detection
in the Internet of Things,” IEEE Internet Things Mag., vol. 3, no. 4,
pp. 40–45, Dec. 2020.
[12] R. Winward. IoT Attack Handbook. Accessed: May 25, 2021. [Online].
Available: https://www.radware.com/iot-attack-ebook/
[13] A. Marzano et al., “The evolution of Bashlite and Mirai IoT botnets,”
in Proc. ISCC, Natal, Brazil, Jun. 2018, pp. 813–818.
[14] N. Hoque, D. K. Bhattacharyya, and J. K. Kalita, “Botnet in DDoS
attacks: Trends and challenges,” IEEE Commun. Surveys Tuts., vol. 17,
no. 4, pp. 2242–2270, 4th Quart., 2015.
[15] Z. Liu, H. Jin, Y.-C. Hu, and M. Bailey, “Practical proactive DDoS-attack
mitigation via endpoint-driven in-network traffic control,” IEEE/ACM
Trans. Netw., vol. 26, no. 4, pp. 1948–1961, Aug. 2018.
[16] L. Feinstein, D. Schnackenberg, R. Balupari, and D. Kindred, “Statistical
approaches to DDoS attack detection and response,” in Proc. Inf.
Survivability Conf. Expo. (DARPA), Washington, DC, USA, Apr. 2003,
pp. 303–314.
[17] L. Li, J. Zhou, and N. Xiao, “DDoS attack detection algorithms based
on entropy computing,” in Proc. ICICS, Zhengzhou, China, Dec. 2007,
pp. 452–466.
[18] J. Yuan and K. Mills, “Monitoring the macroscopic effect of DDoS
flooding attacks,” IEEE Trans. Dependable Secure Comput., vol. 2, no. 4,
pp. 324–335, Oct. 2005.
[19] Z. Liu, Y. Cao, M. Zhu, and W. Ge, “Umbrella: Enabling ISPs to offer
readily deployable and privacy-preserving DDoS prevention services,”
IEEE Trans. Inf. Forensics Security, vol. 14, no. 4, pp. 1098–1107,
Apr. 2019.
[20] Y. Xiang, K. Li, and W. Zhou, “Low-rate DDoS attacks detection and
traceback by using new information metrics,” IEEE Trans. Inf. Forensics
Security, vol. 6, no. 2, pp. 426–437, Jun. 2011.
[21] J. Luo, X. Yang, J. Wang, J. Xu, J. Sun, and K. Long, “On a math-
ematical model for low-rate shrew DDoS,” IEEE Trans. Inf. Forensics
Security, vol. 9, no. 7, pp. 1069–1083, Jul. 2014.
[22] M. E. Ahmed, S. Ullah, and H. Kim, “Statistical application fingerprint-
ing for DDoS attack mitigation,” IEEE Trans. Inf. Forensics Security,
vol. 14, no. 6, pp. 1471–1484, Jun. 2019.
[23] B. Rashidi, C. Fung, and E. Bertino, “A collaborative DDoS
defence framework using network function virtualization,” IEEE
Trans. Inf. Forensics Security, vol. 12, no. 10, pp. 2483–2497,
Oct. 2017.
[24] R. Biswas, S. Kim, and J. Wu, “Sampling rate distribution for flow mon-
itoring and DDoS detection in datacenter,” IEEE Trans. Inf. Forensics
Security, vol. 16, pp. 2524–2534, 2021.
[25] A. Praseed and P. S. Thilagam, “DDoS attacks at the application layer:
Challenges and research perspectives for safeguarding Web applica-
tions,” IEEE Commun. Surveys Tuts., vol. 21, no. 1, pp. 661–685,
1st Quart., 2019.
[26] A. Wang, W. Chang, S. Chen, and A. Mohaisen, “Delving into Internet
DDoS attacks by botnets: Characterization and analysis,” IEEE/ACM
Trans. Netw., vol. 26, no. 6, pp. 2843–2855, Dec. 2018.
[27] Layer 7 DDoS–Blocking HTTP Flood Attacks. Accessed: May 25, 2021.
[Online]. Available: https://blog.sucuri.net/2014/02/layer-7-ddos-
blocking-http-flood-attacks.html
[28] Taxonomy of DDoS Attacks. Accessed: May 25, 2021. [Online]. Avail-
able: https://www.riorey.com/types-of-ddos-attacks/#attack-15
[29] S. Ranjan, R. Swaminathan, M. Uysal, A. Nucci, and E. Knightly,
“DDoS-shield: DDoS-resilient scheduling to counter application layer
attacks,” IEEE/ACM Trans. Netw., vol. 17, no. 1, pp. 26–39, Feb. 2009.
[30] A. Praseed and P. S. Thilagam, “Modelling behavioural dynamics
for asymmetric application layer DDoS detection,” IEEE Trans. Inf.
Forensics Security, vol. 16, pp. 617–626, 2021.
[31] A. Praseed and P. S. Thilagam, “Multiplexed asymmetric attacks: Next-
generation DDoS on HTTP/2 servers,” IEEE Trans. Inf. Forensics
Security, vol. 15, pp. 1790–1800, 2020.
[32] Verizon Media Platform. Application Layer DDoS Mitigation in Action.
Accessed: May 25, 2021. [Online]. Available: https://vzmediaplatform.
medium.com/application-layer-ddos-mitigation-in-action-ee73e2ee4075
[33] International Botnet and IoT Security Guide 2020. Accessed:
May 25, 2021. [Online]. Available: https://securingdigitaleconomy.org/
wp-content/uploads/2019/11/CSDE_Botnet-Report_2020_FINAL.pdf
[34] T. Mahjabin, Y. Xiao, T. Li, and C. L. P. Chen, “Load distributed
and benign-bot mitigation methods for IoT DNS flood attacks,” IEEE
Internet Things J., vol. 7, no. 2, pp. 986–1000, Feb. 2020.
[35] Z. A. El Houda, L. Khoukhi, and A. S. Hafid, “Bringing intelligence
to software defined networks: Mitigating DDoS attacks,” IEEE Trans.
Netw. Service Manage., vol. 17, no. 4, pp. 2523–2535, Dec. 2020.
[36] C. Wang, T. T. N. Miu, X. Luo, and J. Wang, “SkyShield: A sketch-
based defense system against application layer DDoS attacks,” IEEE
Trans. Inf. Forensics Security, vol. 13, no. 3, pp. 559–573, Mar. 2018.
[37] Y. Xie and S.-Z. Yu, “Monitoring the application-layer DDoS attacks for
popular websites,” IEEE/ACM Trans. Netw., vol. 17, no. 1, pp. 15–25,
Feb. 2009.
[38] V. Matta, M. Di Mauro, and M. Longo, “Botnet identification in
randomized DDoS attacks,” in Proc. 24th Eur. Signal Process. Conf.
(EUSIPCO), Aug. 2016, pp. 2260–2264.
[39] V. Matta, M. Di Mauro, and M. Longo, “DDoS attacks with randomized
traffic innovation: Botnet identification challenges and strategies,” IEEE
Trans. Inf. Forensics Security, vol. 12, no. 8, pp. 1844–1859, Aug. 2017.
[40] V. Matta, M. Di Mauro, and M. Longo, “Botnet identification in
multi3554 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Botnet Identification in DDoS Attacks With
Multiple Emulation Dictionaries
Michele Cirillo , Graduate Student Member, IEEE, Mario Di Mauro , Member, IEEE,
Vincenzo Matta , Member, IEEE, and Marco Tambasco
Abstract—In a Distributed Denial of Service (DDoS) attack,
a network (botnet) of dispersed agents (bots) sends requests to
a website to saturate its resources. Since the requests are sent
by automata, the typical way to detect them is to look for
some repetition pattern or commonalities between requests of
the same user or from different users. For this reason, recent
DDoS variants exploit communication layers that offer broader
possibility in terms of admissible request patterns, such as, e.g.,
the application layer. In this case, the malicious agents can pick
legitimate messages from an emulation dictionary, and each indi-
vidual agent sends a relatively low number of admissible requests,
so as to make its activity non suspicious. This problem has been
recently addressed under the assumption that all the members
of the botnet use the same emulation dictionary. This situation
is an idealization of what occurs in practice, since different
clusters of agents are typically sharing only part of a global
emulation dictionary. The diversity among the emulation dictio-
naries across different clusters introduces significant complexity
in the botnet identification challenge. This work tackles this issue
and provides the following main contributions. We obtain an
analytical characterization of the message innovation rate of the
DDoS attack with multiple emulation dictionaries. Exploiting this
result, we design a botnet identification algorithm equipped with
a cluster expurgation rule, which, under appropriate technical
conditions, is shown to provide exact classification of bots and
normal users as the observation window size increases. Then,
an experimental campaign over real network traces is conducted
to assess the validity of the theoretical analysis, as well as to
examine the effect of a number of non-ideal effects that are
unavoidably observed in practical scenarios.
Index Terms—Distributed denial of service, DDoS, cyber-
security, botnet, traffic emulation.
I. I NTRODUCTION
N
ETWORKS are consistently exposed to a variety of
dangerous cyber-threats. Providing reliable processing
and inference strategies to contrast these threats is a critical
part of the network security chain [2]–[8]. This work focuses
Manuscript received November 25, 2020; revised February 22, 2021;
accepted May 3, 2021. Date of publication May 21, 2021; date of current
version June 21, 2021. This article was presented in part at the Proceedings
of ICASSP [1]. The associate editor coordinating the review of this manuscript
and approving it for publication was Dr. Mika Ylianttila. (Corresponding
author: Vincenzo Matta.)
Michele Cirillo, Mario Di Mauro, and Vincenzo Matta are with the Depart-
ment of Information and Electrical Engineering and Applied Mathematics
(DIEM), University of Salerno, 84084 Fisciano, Italy, and also with the
National Inter-University Consortium for Telecommunications (CNIT), Italy
(e-mail: micirillo@unisa.it; mdimauro@unisa.it; vmatta@unisa.it).
Marco Tambasco is with Ericsson Telecomunicazioni S.p.A., 84016 Pagani,
Italy (e-mail: marco.tambasco@ericsson.com).
This article has supplementary downloadable material available at https://
doi.org/10.1109/TIFS.2021.3082290, provided by the authors.
Digital Object Identifier 10.1109/TIFS.2021.3082290
on the design and analysis of inferential strategies for
the mitigation of Distributed Denial of Service (DDoS)
attacks.
DDoS attacks are powerful cyber-threats that can pro-
voke significant damages to data networks. These attacks are
launched by a network (the botnet) of malicious agents (the
bots) controlled by a remote entity (the botmaster). The bots
try to bypass the network Intrusion Detection System (IDS) by
implementing a “drop-by-drop” strategy, where i) each indi-
vidual bot sends a relatively low number of legitimate requests
to a target site; and ii) the global rate of requests produced
by the entire botnet is so large to saturate the computational
resources of the target. In order to mitigate the impact of these
attacks, the network administrator should be able to identify
and then ban the bots. Unfortunately, the distributed nature of
DDoS attacks, as opposed to traditional non-distributed denial
of service, makes the botnet highly strewn across the overall
network that mixes legitimate and malicious users. As a result,
detection of each single bot is a demanding task.
A. Motivating Example
A recent and famous example of real-world DDoS attack
is Mirai, which has already caused noteworthy damages,
particularly exploiting the vulnerabilities of poorly secured
IoT devices [9]–[11]. The Mirai botnet is able to use different
layers of the protocol stack to launch different types of attacks,
including SYN-flood, ACK-flood, TCP STOMP attacks, DNS
attacks, UDP attacks, and HTTP attacks [12]. According to
a recent report of a recognized cyber-security provider, “the
HTTP attack included in Mirai is a highly flexible attack
with several customizations that could prove difficult to defend
against without the right tools” [12]. The main difficulties in
facing this type of attack arise from the fact that the botnet can
craft a number of legitimate HTTP requests that do not appear
suspicious to the network administrator. The main element that
the network administrator can leverage to face the attack is
the limited amount of HTTP requests across different bots,
which induces a suspicious similarity among the bots’ traffic
patterns. Therefore, the power of this attack grows with the
increasing availability of crafted messages, and for this reason
the HTTP protocol is particularly convenient to the attacker.
In our work, this aspect is made formal by introducing an
emulation dictionary, i.e., a set of legitimate messages that
the bots can send to the target site.
1556-6021 © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3555
An even more dangerous evolution of Mirai regards the
implementation of coordinated attacks, where a common
target is attacked by different groups of bots, with each group
being coordinated by a different Command and Control (C&C)
center [13]. There are two main elements of novelty arising
in this scenario: i) the HTTP requests crafted by the spatially
dispersed C&C centers will exhibit a certain degree of diver-
sity, which makes the DDoS identification task more difficult,
because diversity across bots reduces similarity between bots’
patterns; and ii) the HTTP requests of different C&C centers
cannot be totally different, because each center learns and
crafts legitimate requests from the same web content that
is effectively present on the target site. These fundamental
elements of novelty find correspondence in the main novelty
presented in our work, that is the introduction of multiple
clusters of bots, with each cluster using its own emulation
dictionary (diversity), and with different emulation dictionaries
sharing part of their requests (partial overlap).
B. Related Work
In recent years, several useful works addressed the problem
of devising countermeasures toward DDoS identification and
mitigation — we invite the Reader to consult [14] and [15] for
an overview on the subject. We now provide a brief summary
of related works.
1) Classical DDoS: We start by listing some recent articles
relevant to DDoS attacks that do not take place specifically
at the application layer. Accordingly, these articles are not
strictly related to our work, nonetheless we feel it useful to
report them as relevant references in the general context of
DDoS attacks. A popular approach to tackle DDoS attacks
and bot identification is based on statistical methods aimed at
revealing anomalous patterns, e.g., repetition patterns, unusual
traffic rates. The DDoS identification strategy devised in [16]
relies on the detection of anomalies observed in the entropy
and in the frequency-sorted distribution of selected packet
attributes. In a similar vein, a technique based on entropy
detection is proposed in [17], where the degree of random-
ness associated to suitable packet attributes is elected as the
critical marker of a DDoS. A hierarchical method aimed
at capturing shifts within spatio-temporal traffic patterns is
designed in [18]. Such shifts are then exploited to reveal a
DDoS flooding attack. The framework Umbrella is proposed
in [19], focusing on amplification DDoS attacks and offer-
ing to the victims the possibility to customize the level of
defense. In [20], the generalized entropy and the information
distance metrics are used to reveal low-rate DDoS attacks,
where dissimilarity between legitimate and malicious traffic
is evaluated. The case of low-rate shrew DDoS attacks (TCP
flows constrained to sustain a small fraction of their ideal rate
at low attack costs) is tackled in [21], where a model amenable
to control the TCP congestion window at the target website
is exploited. In [22], the Authors propose a fingerprinting
approach relying on the analysis of packet-level features in
a traffic flow (e.g., length, number of transmissions). The
obtained fingerprints are used to generate “normal” profiles,
and then a clustering-based detection algorithm decides about
the legitimacy of an unknown fingerprint possibly associated to
a DDoS source. In the context of virtualized network domains,
a defense mechanism named CoFence is introduced in [23]
to handle SYN flood DDoS attacks through resource sharing.
The resource sharing mechanism is modeled as a Stackelberg
game, where all domains aim to maximize their own utility.
Finally, the Authors in [24] propose a virtualized monitoring
system to analyze SYN flood attacks. Due to the huge number
of SYN requests, the monitoring system subsamples each
flow probabilistically, leading to a critical interplay between
sampling rate and DDoS detection rate.
2) Application-Layer DDoS: Since DDoS attacks are typi-
cally based on the repetition of predefined actions or patterns,
their power can be greatly amplified when they are imple-
mented at the application layer of the TCP/IP protocol stack
(L7-DDoS) [25]–[28].
In particular, L7-DDoS attacks can be broadly categorized
in two classes [29]: i) Request Flooding Attack, where the
attack flows exhibit a request rate higher than legitimate traffic;
ii) Asymmetric Workload Attack, where the attacker sends
few requests that require a computationally expensive response
from the server. Our work focuses on class i). Nevertheless,
it is useful to illustrate briefly the main features of class ii).
Asymmetric workload attacks are typically designed to
put under strain complex servers such as database systems,
where few specific SQL-based queries can force the data-
base to perform many nested and computationally expensive
operations. The work in [30] is focused on detecting such
asymmetric L7-DDoS attacks by exploiting the Probabilistic
Timed Automata (PTA) framework, where server resources are
represented by states and requests by transitions. A measure
of the workload is associated to each state to quantify the
amount of computation required by the server to satisfy a
specific request. The same Authors propose a generalization of
their original method in [30], called Multiplexed Asymmetric
Attacks [31], where the idea is to exploit the Multiplexing and
Server Push functionalities of the HTTP/2 protocol to carry
more requests simultaneously. One strength of asymmetric
workload attacks is that they typically rely on few malicious
agents to perform the requests and, hence, a botnet needs
comparably less resources w.r.t. request flooding attacks. At
the same time, the presence itself of few requests can be a
weakness of asymmetric attacks. In fact, an IDS can zoom
on in agents that send computationally expensive requests and
monitor them to detect repetition patterns and other kind of
suspicious behavior.
In contrast, the request flooding attacks in class i) become
particularly difficult to detect when the bots are able to craft
a large number of different requests, so as to emulate the
legitimate activity of a normal network user. Unfortunately,
there exist several real-world examples showing the relevance
and power of L7-DDoS attacks based on request flooding.
One is the case of Logitravel, a worldwide travel agency that
experienced an attack with peaks reaching approximately 9
million requests per minute, corresponding to about 150000
requests per second, and a maximum load 50 times larger
than the normal load [32]. Another example is a recent attack
performed using the sophisticated malware Mirai illustrated
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3556 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
in Sec. I-A. The popularity of request flooding attacks is
even growing since nowadays they can be easily implemented
through the Malware-as-a-Service (MaaS) paradigm, a service
recently appeared into the Dark Web, which allows to rent
powerful botnets for a low fee [33].
The above observations explain the noteworthy interest of
the scientific community on L7-DDoS flooding attacks. As
mentioned in Sec. I-A, different protocols of the application
layer can become carriers for such attacks. One example is
the DNS flooding attack launched through the Domain Name
System protocol. In particular, recent variants of DNS flooding
attacks exploit the vulnerabilities of specific environments,
such as the Internet of Things (IoT) or the Software Defined
Network (SDN) environment. With reference to the IoT con-
text, a bot mitigation strategy is proposed in [34], which
relies on the hierarchical connections among DNS servers.
In the context of SDN environments, in [35] a strategy named
WisdomSDN is conceived to detect illegitimate DNS requests
and responses. Actually, since standard DNS queries are built
through a very limited set of messages, one typical way to
counter such attacks is to instruct an IDS to perform a content
control of each query, so as to detect repetitive behavior and
ban the associated users.
In comparison, HTTP flooding attacks are more challenging
to defend against, due to the botnet possibility of building an
extremely high number of messages, e.g., GET/POST requests.
In [36], a sketch-based approach to detect HTTP flooding
attacks is proposed. A sketch is a data structure based on hash
tables, used to aggregate high dimensional data streams. The
idea in [36] is based on the fact that through the sketches
it is possible to detect significant changes, interpreted as
occurrences of attacks, in massive data streams. The problem
of detecting HTTP flooding attacks is faced also in [37],
where the Authors propose an Abnormal Traffic Detection
Module (ATDM) able to: i) organizingthe HTTP request flows
as time series; and ii) predicting the traffic intensity based on
previous observations. Then, an abnormal behavior is declared
when the distance between predictions and actual intensities
exceeds a suitable threshold.
Recently, the concept of L7-DDoS attacks characterized by
the possibility of emulating normal users by crafting a rich
variety of legitimate traffic patterns was put forth in [38]–[40].
The model adopted in [38]–[40] introduces an emulation
dictionary that is learned continually and, hence, enriched
continually by the botmaster, through monitoring and collec-
tion of legitimate surfing activity performed on the target site.
The bots can access the emulation dictionary of admissible
messages in order to emulate the behavior of a normal network
user. By “admissible”, we mean here that the bot requests
should be referred to content that is effectively present on the
target website. Usually, to launch the attack, some malicious
code is installed on the compromised machines. Then, the code
installed on a given bot starts sending requests taken from a
certain set of legitimate messages. To this end, the botmaster
controlling a given cluster of bots must put in the emulation
dictionary a set of messages corresponding to content that is
effectively available on the target site. This operation needs
continuous monitoring and learning from the botmaster, for
at least two reasons. First, richer sets of requests give to
the botnet more power of emulating normal users. Second,
tracking the evolution of a target website is especially relevant
in relation to content that changes dynamically over time,
e.g., due to intrinsic characteristics of the website, advertising,
or protection mechanisms. For example, on an e-commerce
portal, new products can be promoted over time, and the
botmaster is interested in enriching the emulation dictionary
with the corresponding new pages to maximize the degree of
innovation and, hence, of emulation.
Notably, the attacks studied in [38]–[40] are particularly
challenging, since they assume that if one looks at the indi-
vidual request pattern of a bot, there is no way to distinguish it
from a legitimate pattern, i.e., bot patterns are individually not
anomalous. Accordingly, in [38]–[40] a strategy is proposed
that is able to identify the botnet by exploiting dependence
across bot patterns.
3) Coordinated DDoS: The botnet identification strategies
proposed in [38]–[40] assume either that the emulation dic-
tionary is one and the same for all bots [38], [39] or that
different groups of bots can use completely disjoint dictionar-
ies [40]. These assumptions appear somehow restrictive, since
in practice it is expected that none of these two extreme scenar-
ios is verified, for different reasons, including: decentralized
control of the botnet, decentralized learning of the emulation
dictionary,imperfect communication.In comparison,it is more
realistic to assume that, inside the botnet, there exist clusters
of bots that pick messages from the same emulation dictionary,
but that at the same time a certain degree of diversity exists
among the dictionaries of different clusters. Such augmented
diversity implies in turn an augmented variability in the traffic
patterns produced by the botnet, making it more difficult to
distinguish them from legitimate users.
The presence of multiple emulation dictionaries spread
across the network reflects some sophisticated and challenging
DDoS scenarios, where a huge botnet is partitioned into
several groups or clusters, each of which under the control
of a different C&C center. Such a flexible organization is
aimed at concurrently maximizing the damage against a target
and minimizing the possibility of being revealed. Moreover,
a decentralized C&C infrastructure, a.k.a. Peer-to-Peer botnet,
has been proven to offer a strong robustness as compared
to centralized solutions where hindering a central server is
sufficient to mitigate or stop the threat [41].
Recent works on coordinated DDoS attacks focus on the
case where communication among bots controlled by the same
C&C center induces a community structure. In [42], [43]
the PeerHunter strategy is devised to perform a behavioral
analysis that maps bots and legitimate applications, or different
types of bots, into different communities. In [44], the Authors
characterize the communication among network nodes in
terms of an undirected graph, and graph metrics such as the
node degree and the conductance are used to identify bot
communities. Similar concepts are exploited in [45], where an
algorithm named BotCLAM is able to pinpoint distinct botnet
communities within a communication graph.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3557
TABLE I
N OTATION
C. Main Contributions
In order to defeat an attacker, one must necessarily assume
to have some advantage over it. Accordingly, the DDoS
identification methods exploited in the references listed in the
previous section rely on one or more among the following
assumptions: i) existence of patterns that each bot repeats
several times; ii) other anomalous behavior of the individual
bots, e.g., malformed or suspicious HTTP requests; iii) a
communication structure among group of bots, i.e., a network
graph, giving rise to distinct communities inside the botnet.
In comparison, in this work we consider the worst-case
scenario addressed in [39], where none of these assumptions
is verified, since: i) each individual bot has a fairly rich
emulation dictionary so as to avoid suspicious repetitions;
ii) the patterns formed by the individual bots are assumed
to appear perfectly legitimate to a network administrator;
iii) no detectable communication structure exists among the
bots. Under this demanding setting, the techniques listed in
Sec. I-B cannot perform properly, for example, evaluating
the entropy of a user’s request pattern does not reveal any
meaningful information as regards its nature (bot or normal).
Likewise, estimating a community graph is hopeless in the
absence of data related to the existence of links between
pairs of bots. As a result, under the setting considered in this
work, a critical information useful to discriminate a botnet
from normal users is the similarity between the activities
of distinct bots, arising because the emulation dictionary is
constrained to grow over time up to a limited rate. Unfor-
tunately, the techniques available to exploit such information
consider only the cases where all bots craft their legitimate
requests from the same emulation dictionary [38], [39], or the
straightforward extension where different groups of bots use
completely disjoint dictionaries [40]. As explained before,
and motivated by the example in Sec. I-A, recent evolutions
of DDoS attacks leverage the possibility of distributing the
attack across separate clusters of bots coordinated by separate
C&C centers. This relevant evolution introduces the additional
challenge of infusing a botnet identification algorithm with the
capability of handling the diversity across distinct emulation
dictionaries. In summary, the main contribution of this work
is to provide a theoretical analysis, supported by experiments
carried out on datasets containing the activity of real-world
users, to characterize a botnet identification strategy for the
demanding setting of DDoS attacks with multiple emulation
dictionaries.
II. DD O S W ITH M ULTIPLE E MULATION D ICTIONARIES
Let N = {1,2,..., N} denote the monitored network made
of N users, legitimate and/or bots. We start by introducing
some useful quantities related to the network activity. For a
given subnet S ⊆ N, we denote by N S (t) the overall number
of transmissions taking place in S up to a given time t. The
transmission activity of S will be then summarized by the
empirical transmission rate:
?
λ S (t) ?
N S (t)
t
, (1)
whose asymptotic (t → ∞) value, when it exists, is denoted
by λ S . We remark that this indicator is useful to quantify
the amount of transmissions, but it does not convey any
information about the content of the transmitted messages.
In an application-layer DDoS attack, the message content
becomes critical to enable faithful discrimination between bots
and legitimate users. Thus, we introduce a second indicator
pertaining to the variability of the message content, namely,
the Message Innovation Rate (MIR). Letting D S (t) be the set
of all the distinct messages sent up to t by users belonging to
subnet S, the empirical MIR is defined as:
? ρ S (t) ?
|D S (t)|
t
. (2)
When it exists, the limiting MIR is denoted by ρ S . We
remark that the above two descriptors, ? λ S (t) and ? ρ S (t), are
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3558 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
relative to generic users, i.e., they apply to both normal users
or bots.
The third and last descriptor we are going to introduce per-
tains only to the bot activity. Let B ⊆ N denote the ensemble
of all bots disseminated across the network. We assume that
the botmaster has collected a set of messages available for the
purpose of emulating legitimate traffic patterns. The botmaster
distributes fairly the dictionary across the botnet, in such
a way that different clusters of bots receive approximately
equal-sized portions of the dictionary. Formally, thebotnet is
partitioned into C clusters and at time t the bots belonging
to the i-th cluster can access an emulation dictionary E i (t),
whose cardinality grows over time at rate:
α ? lim
t→∞
|E i (t)|
t
, i = 1,2,...,C, (3)
which is accordingly referred to as Emulation Dictionary Rate
(EDR). In order to send apparently legitimate requests, a bot
belonging to the i-th cluster picks admissible messages from
E i (t). In order to guarantee a non-suspicious innovation rate,
the botmaster must steadily learn new admissible messages,
which means that the cardinality of the emulation dictionary
must increase over time.
One fundamental feature of this work is that we allow
for non-negligible interaction between distinct clusters. More
specifically, the emulation dictionaries of two clusters i and j
have an intersection given by:
E ij (t) ? E i (t) ∩ E j (t), (4)
whose overlap degree is quantified as:
lim
t→∞
|E ij (t)|
|E i (t)|
= lim
t→∞
|E ij (t)|
|E j (t)|
= ω ij = ω ji ∈ (0,1), (5)
yielding, in view of (3), the EDR of the intersection:
lim
t→∞
|E ij (t)|
t
= α ω ij . (6)
One example of the scenario with multiple dictionaries is
illustrated in Fig. 1, with reference to three clusters.
Our model allows intersection among more than two dictio-
naries — see the top of Fig. 1. Nevertheless, in the following
we will show an algorithm able to identify any arbitrary
number of clusters resorting only to successive pairwise
checks. For this reason, only the pairwise overlap degrees
ω ij , shown in the bottom of Fig. 1, will play a role in the
analysis of the botnet identification algorithm. In order to
avoid misunderstanding, we remark that the meaning of the
forthcoming analysis is not that our strategy applies only
to pairs of clusters, but that a pairwise characterization is
sufficient to identify any arbitrary number of clusters.
III. C LUSTER I NTERACTION
Preliminarily, it is useful to introduce the following function,
for α,λ > 0:
R(α,λ) ?
αλ
α + λ .
(7)
In [39] it is shown that this function corresponds to the
MIR of a botnet that uses one and the same emulation
Fig. 1. Top. Illustration of the DDoS attack with multiple emulation
dictionaries. Bottom. Pairwise overlaps relative to the setting displayed in
the top.
dictionary, with EDR α and transmission rate λ, under either
a synchronous or Poisson scheduling. For later use, we report
also the following inequality, holding for any choice of positive
α,λ 1 ,λ 2 [39]:
R(α,λ 1 + λ 2 ) ≤ R(α,λ 1 ) + R(α,λ 2 ), (8)
which reflects the fact that the innovation rate of a botnet
made of two components transmitting at rates λ 1 and λ 2 , and
using the same emulation dictionary with EDR α, is upper
bounded by the sum of the innovation rates of the individual
components.
The following theorem establishes the coupling effect
between clusters that arises from the nonzero overlap between
their emulation dictionaries.
Theorem 1 (Pairwise MIR): Let B i and B j be subnets made
of bots belonging to cluster i and j, respectively. Assume that
the transmission policies of all bots are either deterministic
and synchronous (i.e., all bots transmit at regular intervals)
or governed by independent Poisson processes. In both cases,
the transmission rates are allowed to vary across bots. Then,
the limiting MIR of the joint subnet B i ∪ B j is:
? ρ B i ∪ B j (t)
m.s.
−−→ ρ B i ∪ B j = ω ij R(α,λ B i + λ B j )
+(1 − ω ij )[R(α,λ B i ) + R(α,λ B j )], (9)
where the symbol
m.s.
−−→ denotes mean-square convergence as
t → ∞.
Proof: See the Supplemental Material [46].
Equation (9) admits a clear interpretation. The MIR of the
botnet B i ∪ B j , which aggregates bots from clusters i and
j, is a convex combination, with weights ω ij and 1 − ω ij ,
of two types of MIRs. A fraction ω ij of the aggregate MIR is
given by the MIR corresponding to a botnet with transmission
rate λ B i +λ B j , whose members pick messages from the same
emulation dictionary. In comparison, a fraction 1−ω ij of the
aggregate MIR is given by the sum of the MIRs corresponding
to B i and B j . This fraction represents messages not picked
from the intersection between the two emulation dictionaries.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3559
It is also useful to compare (9) with the MIRs corresponding
to the cases of total overlap and absence of overlap, respec-
tively. We have from (8) and (9):
R(α,λ B i + λ B j ) ≤ ρ B i ∪ B j ≤ R(α,λ B i ) + R(α,λ B j ). (10)
In other words, the aggregate botnet B i ∪ B j is: i) more
innovative than a botnet where both clusters pick messages
from the same emulation dictionary (left inequality in (10),
total overlap); and ii) less innovative than a botnet where
the clusters pick messages from disjoint dictionaries (right
inequality in (10), no overlap at all).
IV. B OTNET I DENTIFICATION A LGORITHM
A botnet identification algorithm nicknamed BotBuster was
proposed in [39]. This algorithm is able to detect a botnet
possibly hidden in the network under the assumption that
there is a single emulation dictionary common to all bots
(i.e., no multi-cluster allowed), and with detection error that
vanishes as the observation time grows. We now manage to
illustrate how efficient botnet identification can be achieved
under the multi-cluster setting addressed in this work.
To this aim, we build an algorithm nicknamed BotClus-
terBuster, which is composed of two stages. The first stage
pertains to the formation of candidate bot clusters. The routine
implemented at this stage is inherited from BotBuster, which,
as said, was designed for the single-cluster case. Proving
that this routine can be useful in the multi-cluster setting as
well, requires significant effort and a novel analysis that relies
primarily on the results contained in Theorem 1. The second
stage pertains to cluster expurgation, a procedure necessary
to discard possibly false clusters from the set of candidates
produced in the first stage.
A. Cluster Formation
The core of BotClusterBuster is a pairwise comparison
between a pivot element (a single node or an estimated botnet)
and a test node. The final goal is to decide whether or not
the pivot and the test node form a botnet. Let us start by
considering a pivot node p, and a test node τ.
First, the algorithm computes the empirical MIRs corre-
sponding to node p, to node τ, and to their union, namely,
? ρ {p} (t), ? ρ {τ} (t), and ? ρ {p,τ} (t) — see (2). Now, the EDR is
not known beforehand, and when it is estimated from the
data one gets distinct values for the two nodes p and τ,
either because one or both nodes correspond to normal users,
or because of estimation errors. Therefore, it is necessary to
compute a common reference EDR. This is not an easy task,
since, e.g., intuitive solutions such as the average between
the EDRs of the individual nodes might lead to inconsistent
results — see [39]. In order to overcome this issue, in [39] a
Replacement and Reassignment (R&R) procedure is proposed.
This procedure relies on the intuition that, if some messages
from the node with higher estimated EDR are fictitiously
reassigned to the other node, the resulting EDRs tend to move
close to each other, until a common EDR? α(t) is reached. Once
this reference EDR is obtained, BotClusterBuster computes
the MIR that would correspond to a botnet with one and
TABLE II
B EHAVIOR OF THE MIR FOR THE C ASES D ESCRIBED IN THE M AIN T EXT
the same emulation dictionary (total overlap) having reference
EDR ? α(t), namely,
? ρ tot (t) ? R
? ? α(t), ?
λ {p,τ} (t) ? . (11)
We further introduce the sum MIR:
? ρ sum (t) ? ? ρ {p} (t) + ? ρ {τ} (t). (12)
Let us now delve into the analysis of the possible cases
that the algorithm encounters when testing nodes p and τ.
Depending on the nature of these nodes, there are three
possibilities — see the summary in Table II.
Case I: If p OR τ are normal, we have that:
? ρ {p,τ} (t) ≈ ? ρ sum (t), (13)
which intuitively stems from the fact that low correlation is
observed between normal users and between normal users and
bots. Moreover, it can be shown that [39]:
? ρ tot (t) ≤ ? ρ sum (t). (14)
Case II: If p AND τ are bots from the same cluster, for
sufficiently large t we have ? α(t) ≈ α and ? λ {p,τ} (t) ≈ λ p +λ τ ,
yielding:
? ρ {p,τ} (t) ≈ ? ρ tot (t) ≈ R(α,λ p + λ τ ). (15)
Case III: If p AND τ are bots from distinct clusters i and
j, from Theorem 1 we have:
? ρ {p,τ} (t)
≈ ω ij R(α,λ p + λ τ ) + (1 − ω ij )[R(α,λ p ) + R(α,λ τ )]
≈ ω ij ? ρ tot (t) + (1 − ω ij )? ρ sum (t), (16)
where in the second approximate equality we exploited the
relationship ? ρ tot (t) ≈ R(α,λ p + λ τ ), which can be proved
as in case II. Indeed, by examining the R&R procedure it is
readily seen that convergence of ? α(t) to α is not affected by
the fact that p and τ use distinct emulation dictionaries.
Assume now that we set a threshold equal to, for θ ∈ (0,1):
γ(t) = θ ? ρ tot (t) + (1 − θ)? ρ sum (t), (17)
and that the algorithm adopts the following rule:
? ρ {p,τ} (t) ≤ γ(t) ⇒ form an estimated botnet {p,τ}. (18)
Let us examine how such classification rule works under the
aforementioned three cases — see Fig. 2. When p or τ are
normal users (case I), from (13), (17) and (18) we conclude
that the algorithm rejects the hypothesis that {p,τ} is a botnet,
since the empirical MIR ? ρ {p,τ} (t) will be sufficiently close to
the upper boundary ? ρ sum (t). Likewise, when p and τ are bots
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3560 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Fig. 2. Time evolution of the relevant MIRs, for the three cases described in the main text.
sharing the same emulation dictionary (case II), from (15), (17)
and (18) we conclude that the algorithm accepts the hypothesis
that {p,τ} is a botnet, since the empirical MIR ? ρ {p,τ} (t) will
be sufficiently close to the lower boundary ? ρ tot (t). Finally, let
us examine the situation where p and τ are bots from distinct
clusters (case III). Assume that:
θ > ω ij . (19)
In this case, we see from (16), (17) and (18) that the
algorithm rejects the hypothesis that {p,τ} is a botnet, since
? ρ {p,τ} (t) will stay above the threshold. In summary, we see
that under condition (19) the algorithm ends up estimating a
botnet only when p and τ belong to the same cluster.
Iterating the above procedure yields the BotClusterBuster
algorithm, whose pseudo-code is reported at the top of this
page. The algorithm starts with node 1 as a pivot. If nodes 1
and 2 are classified as a botnet,
?
B(1;t) = {1,2}, otherwise
?
B(1;t) = {1}. At the end of the loop, the algorithm returns a
candidate botnet cluster
?
B(1;t) (in case the candidate cluster
has cardinality equal to 1, it is discarded). The loop is iterated
across the whole set of pivots, yielding a sequence of candidate
clusters, namely,
?
B(1;t), ? B(2;t),..., ? B(N;t).
We remark that the analysis of cases I–III is basically
unchanged if we replace the pivot node p with a subnet of bots
belonging to the same cluster. Accordingly, since for large t
the pairwise checks are all correct, they can produce either
empty sets or subnets of bots belonging to the same cluster.
In particular: i) if the initial pivot node is a normal user,
BotClusterBuster produces an empty cluster; ii) if the initial
pivot node is a bot from a certain cluster, BotClusterBuster
produces a candidate cluster matching the cluster the pivot
belongs to. Thus, provided that (19) is verified, as t → ∞ the
algorithm ends up estimating all the botnets corresponding to
the different clusters, reaching the twofold goal of discriminat-
ing bots from normal users and identifying the local structure
of the individual clusters.
In the absence of errors, the results produced by our algo-
rithm should not be affected by the initial pivot, in the follow-
ing sense. When the pivot is a normal user, BotClusterBuster
should produce an empty cluster. When the pivot is a bot, Bot-
ClusterBuster should end up with the cluster pertaining to that
bot. However, we notice that: i) we cannot know beforehand
how many clusters exist and, hence, we cannot select before-
hand one pivot for each cluster; and ii) in real-world data
some pivots can exhibit anomalous behavior, for example, over
Algorithm 1
?
B(t) = BotClusterBuster (traffic patterns
until time t, θ, β)
N = {1,2,..., N}
for p ∈ N do
?
B(p;t) = {p}
for τ ∈ N \ {p} do
γ(t) = θ? ρ tot (t) + (1 − θ)? ρ sum (t)
if ? ρ ?
B (p;t)∪{τ} (t) ≤ γ(t) then
?
B(p;t) = ? B(p;t)
? {τ}
end
if | ? B(p;t)| = 1 then
?
B(p;t) = ∅
% begin cluster expurgation
if
?
λ ?
B (p;t) (t) ≤ β ?
λ N (t) then
?
B(p;t) = ∅
% end cluster expurgation
end
?
B(t) =
N
?
p=1
?
B(p;t)
a particular realization, one legitimate user can be particularly
lazy in producing new messages and, hence, using it as pivot
can bias significantly the algorithm output. For these reasons,
to avoid biasing the results, in BotClusterBuster all pivots
have the same dignity, namely, the algorithm produces a set of
candidate botnets for each pivot node in {1,2,..., N}. Then,
the ensemble of candidate clusters is scanned and expurgated
using the strategy illustrated in the next section.
In accordance with what was found in [39], the nested loopy
structure of BotClusterBuster yields a computational complex-
ity scaling quadratically with the network size, which can be
conveniently distributed over multiple machines by means of
parallel implementations. In comparison to the problem of
finding a subset of nodes fulfilling an assigned condition,
which would lead in general to a combinatorial complexity,
a quadratic complexity arises because BotClusterBuster can
work in terms of pairwise checks. The question of whether
one can further reduce the complexity and still preserve botnet
identification consistency is open.
B. Cluster Expurgation
According to the analysis reported in the previous section,
the first stage of BotClusterBuster ends up delivering one
(possibly empty) candidate cluster per each initial pivot node.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3561
The most natural way to build the final estimated botnet is to
retain all the non-empty botnet clusters, namely, to consider
their union (union-rule). From a theoretical standpoint such
rule would provide perfect botnet identification. However,
in practice there are several non-ideal effects that can induce
coupling between normal users and/or between normal users
and bots. First of all, our analysis guarantees convergence
of certain relevant quantities for sufficiently long time, and
in practice we must face issues related to finite observation
windows. Second, the condition that normal users are mutually
independent and independent from bots (yielding an aggregate
MIR approximately equal to ? ρ sum (t), hence resulting into an
easy threshold up-crossing)cannot be perfectly met in practice.
Occasionally, we can have normal users that appear correlated
to other normal users or to some bots. As a matter of fact,
the algorithm usually delivers the true clusters plus some
false micro-clusters containing legitimate network users, due
to spurious correlations arising during the pairwise checks.
In the traditional single-cluster setting, this issue is easily
remediated by retaining only the estimated botnet with largest
cardinality (max-rule). This rule would obviously fail in the
multi-cluster scenario, since it will surely discard all but one
cluster.
In order to face this issue, the BotClusterBuster algorithm
implements a cluster expurgation strategy, aimed at: i) retain-
ing the true clusters, while ii) discarding the false ones. We
now propose a cluster expurgation strategy aimed at reaching
these goals. To this end, it is useful to highlight two important
“physical” aspects related to the bot clusters. First of all,
the power of a (symmetric) DDoS attack is determined by its
global transmission rate, λ B , relative to the global transmission
rate, i.e., λ B should be typically at least on the same order
of λ N . Second, the rate of an individual candidate cluster
must occupy a certain fraction of the overall botnet rate and,
hence, of the overall transmission rate. These two aspects can
be combined by establishing that the algorithm retains the
candidate cluster
?
B(p;t) if, and only if:
?
λ ?
B (p;t) (t) > β ?
λ N (t), (20)
where β ∈ (0,1) is the cluster expurgation hyperparameter
that determines the fraction of the total transmission rate below
which a cluster is reputed to be spurious. Finally, the estimate
of the entire botnet is produced by applying the union operator
to the survived clusters.
In order to select an appropriate value for β, we now relate
it to two physical parameters that are strictly tied with the
aforementioned two physical aspects. With regard to aspect
i), we say that we are under a meaningful DDoS attack if:
λ B = κ λ N \ B = κ (λ N − λ B ) ⇒ λ B =
κ
1 + κ
λ N , (21)
namely, if the global botnet activity is κ times the activity of
the normal users, with κ being typically at least equal to 1.
With regard to aspect ii), in order to deserve countermeasures,
a botnet cluster must sustain a reasonable part of the global
attack rate, namely,
λ B i ≥ ξλ B , (22)
for some ξ ∈ (0,1). Joining (21) with (22), the algorithm
retains the candidate cluster
?
B(p;t) if, and only if:
?
λ ?
B (p;t) (t) >
ξκ
1 + κ
?
λ N (t), (23)
which, in view of (20), creates the following link between the
cluster expurgation threshold β and the physical parameters κ
and ξ:
β = ξ
κ
1 + κ
. (24)
Needless to say, the adopted choice for cluster expurgation
is not unique, and other criteria are possible. For example,
perhaps the simplest one is to identify a minimum cluster
size and retain only clusters that exceed that size. However,
compared against our choice, the latter rule seems a bit less
related to physical considerations, and more based on an
absolute criterion, rather than relative to the network activity
observed on the data.
It is useful to comment on the role of the parameters
κ and ξ. Actually, the value of κ determines a safeguard
level at which we judge a botnet dangerous in terms of
resource saturation. Likewise, the value of ξ determines to
what extent we can tolerate to miss some small bot cluster.
Remarkably, setting these parameters introduces a flexible
degree of customization that is more related to the type of
service and users’ expectation for a particular application. For
example, the typical choice of a network administrator facing a
DDoS attack are: i) avoiding that the destination site crashes;
ii) guaranteeing proper service to the legitimate users. Under
these conditions, it is preferable not to be indulgent in cluster
acceptance, so as to reduce the likelihood of banning normal
users, perhaps at the price of losing some bots. Finally, it is
important to remark that, to guarantee proper functioning of
BotClusterBuster, the network administrator does not need
a detailed knowledge of the attack characteristics. In other
words, it is not necessary to estimate precise values of κ and
ξ. Rather, it is sufficient to make a conservative choice so as
to set a cluster expurgation threshold β < ξκ/(1 + κ). This
particular aspect will be illustrated in detail in Sec. VI-A.
V. P RACTICAL I SSUES
In real-world settings, we cannot expect that the technical
conditions used to prove our mathematical claims are perfectly
met. For this reason, in this section we examine some relevant
scenarios that are not covered by the previous analysis, and
verify whether BotClusterBuster can deliver satisfying perfor-
mance even under these perturbed conditions.
A. Violation of Condition (19)
The choice of the parameter θ in (19) can be determined
by different factors. Preliminarily, we notice that the case
ω ij ≈ 1 (total overlap) is of scarce interest here, since it
basically corresponds to the single cluster case already dealt
with in [39]. Thus, let us assume that ω ij takes on some
intermediate value. On one hand, we could conservatively
set the threshold parameter θ close to 1 in order to be sure
that (19) holds true. On the other hand, if θ collapses to 1,
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3562 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Fig. 3. Botnet identifiability vs. cluster identifiability.
the threshold γ(t) collapses to the lower boundary ? ρ tot (t),
thus reducing the likelihood that the estimated MIR ? ρ {p,τ} (t)
stays below the threshold. Accordingly, there is a certain
flexibility in the choice of θ that should be taken into account
in practice. For this reason, it makes sense to examine whether
the algorithm is robust to violation of (19).
In presence of this violation, it is readily seen that, among
cases I–III described before, only case III changes. In fact,
provided that θ is not collapsing to 0 or 1, in cases I
and II the estimated MIR ? ρ {p,τ} (t) stays above or below
the threshold, respectively. In contrast, when case III is in
force, nodes p and τ belong to distinct clusters with partially
overlapped emulation dictionaries, which implies that, since
(19) is violated, the threshold γ(t) becomes larger than the
MIR associated to the botnet {p,τ} — see (16) and (17).
Accordingly, the algorithm would classify the pair {p,τ} as a
botnet even if p and τ belong to distinct clusters. In principle,
this is not a problem, since what we need is to distinguish
bots from normal users, and not to separate the bot clusters.
This property is illustrated in Fig. 3, where we see the two
possible behaviors of the algorithm, depending on whether θ
is greater or smaller than the overlap degree ω ij . In summary,
if θ < ω ij , the algorithm is able to identify membership to the
overall botnet, while if θ > ω ij the algorithm is able to identify
the additional attribute of membership to the individual cluster.
Unfortunately, the analysis in this section is not sufficient
to establish rigorously the consistency of BotClusterBuster
under violation of (19). This is because, due to the impos-
sibility of discriminating the individual clusters, when the
algorithm progresses the intermediate pivot botnets can be
mixed, i.e., comprising bots of different clusters. The technical
analysis of this case appears to be nontrivial. Nevertheless,
we will show that the dichotomy illustrated in Fig. 3 is cor-
roborated by the numerical analysis conducted in Sec. V-C as
well as by the results observed in our experimental campaign
illustrated in Sec. VI. This dichotomy becomes especially
relevant once we note that the degree of overlap between
pairs of dictionaries is expected to be seldom available in
practical applications. Accordingly, we have at least two useful
conclusions arising from Fig. 3. On one hand, we conclude
that achieving individual cluster identification should not be so
hard since condition (19) does not require detailed knowledge
of the degree of overlap ω ij , a rough prediction is sufficient,
so as to let θ > ω ij . Therefore, a pragmatic choice for the
network administrator is to set a relatively high value of θ
(i.e., 0.9, 0.95), which means that condition (19) would be
violated only if two dictionaries are extremely overlapped.
Under these conditions, BotClusterBuster will be able to dis-
tinguish properly all clusters, but for the clusters featuring very
overlapped emulation dictionaries, which would be eventually
merged since they are in fact akin to a single cluster with the
same emulation dictionary. On the other hand, we remark that,
as we will clearly see in the experimental analysis, only the
identifiability of individual clusters is affected by the choice of
θ. Accordingly, the final goal of the network administrator of
banning all bots belonging to the botnet, is actually preserved
even when condition (19) is violated. In summary,we conclude
that the choice of the threshold parameter θ is not critical for
proper functioning of BotClusterBuster.
B. Clusters’ Asymmetries
Another assumption adopted so far pertains to the equal
distribution of the emulation dictionaries across the network.
Assume instead that different clusters are assigned unbalanced
emulation dictionaries, yielding different EDRs, namely, for
i = 1,2,...,C:
α i = lim
t→∞
|E i (t)|
t
. (25)
Likewise, we now allow for variable overlap degrees.
Formally, the common intersection E ij (t) of the dictionaries
pertaining to clusters i and j has a degree of overlap with
E i (t) and E j (t) given by, respectively:
ω ij = lim
t→∞
|E ij (t)|
|E i (t)|
, ω ji = lim
t→∞
|E ij (t)|
|E j (t)|
. (26)
We notice that simultaneous verification of (25) and (26)
entails the following relationship:
α ij ? lim
t→∞
|E ij (t)|
t
= α i ω ij = α j ω ji . (27)
Actually, the proof of Theorem 1 does not require any
symmetry assumption. In particular, the proof reported in the
Supplemental Material [46] is carried out under the aforemen-
tioned asymmetric scenario, and the resulting MIR referred to
clusters i and j is:
ρ B i ∪ B j = R(α ij ,λ B i ω ij + λ B j ω ji )
+(1 − ω ij )R(α i ,λ B i ) + (1 − ω ji )R(α j ,λ B j ).
(28)
Despite the fact that the limiting MIR corresponding to
partially overlapped dictionaries can be precisely evaluated
using (28), in the asymmetric scenario it is hard to exploit
this relationship to prove consistency of BotClusterBuster.
In fact, the asymmetry introduced by the unknown parame-
ters α i ,α j ,ω ij ,ω ji , precludes the simple extension of the
arguments used in Sec. IV-A to examine cases I–III. For
example, when α i = α j we cannot claim that the reference
EDR ? α(t) obtained from the R&R procedure converges to
some known value. As a result, we are no longer in the
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3563
Fig. 4. Graphical illustration of the scenario described in Sec. V-C, with
two subnetworks, S a = S 1a ∪S 2a and S b = S 1b ∪S 2b , each one containing
bots belonging to clusters 1 and 2.
position of establishing the limiting behavior of ? ρ tot (t), and,
hence, of the threshold γ(t). Nevertheless, we have collected
numerous numerical evidences where, for various choices of
the parameters characterizing the aforementioned asymmetric
scenario, the following inequality is observed:
? ρ S a ∪ S b (t) > ? ρ tot (t) = R(? α(t),λ S a + λ S b ), (29)
for two subnets S 1 and S 2 , each one containing bots belonging
to distinct clusters i and j. Since i) Eq. (29) implies that the
empirical MIR corresponding to S a ∪S b is larger than the MIR
associated to the reference EDR ? α(t); and ii) the empirical
MIR ? ρ S a ∪ S b (t) is obviously upper bounded by the sum of the
individual MIRs, we conclude that under these conditions the
evolution of BotClusterBuster would be basically unchanged.
C. Numerical Analysis
As remarked in Secs. V-A and V-B, a rigorous treatment
of the non-ideal scenarios described in these sections is
definitely nontrivial. For this reason, we now focus on a
numerical analysis aimed at capturing the expected behavior
of BotClusterBuster under these non-ideal scenarios.
We have examined the MIR arising from pairs of subnets of
mixed type, i.e., each one containing bots from two distinct
clusters, and for several sets of parameters. The considered
scenario is illustrated in Fig. 4. We have two subnets:
S a = S 1a ∪ S 2a , S b = S 1b ∪ S 2b , (30)
where each subnet is made of bots from both clusters 1 and 2.
The subscripts 1 and 2 are used accordingly to denote subnets
belonging to the pertinent clusters. Now, let α 1 and λ 1 =
λ S 1a + λ S 1b be, respectively, the EDR and the transmission
rate of the botnet S 1a ∪S 1b coming from cluster 1. Likewise,
α 2 and λ 2 = λ S 2a + λ S 2b will denote, respectively, the EDR
and the transmission rate of the botnet S 2a ∪ S 2b aggregating
bots from cluster 2. In the following analysis, we set α 1 = 1
and let α 2 vary. We consider the limiting MIRs evaluated using
the theoretical formulas, and accordingly denoted without the
symbol ? and without time-dependence.
In Fig. 5, we display ρ S a ∪ S b and ρ tot as functions of α 2 ,
for balanced transmission rates λ S 1a = λ S 1b = λ S 2a = λ S 2b =
3, and for three values of the overlap degree ω 12 . We recall
that, in view of (27), the value of ω 21 is uniquely determined
from the values α 1 , α 2 and ω 12 . We see that the inequality
Fig. 5. Numerical analysis aimed at testing verification of the inequality
? ρ S a ∪ S b > ? ρ tot . The pertinent MIRs are displayed as functions of α 2 (with
α 1 = 1), and computed for different values of the overlap degrees.
Fig. 6. Numerical analysis aimed at testing verification of the inequality
? ρ S a ∪ S b > ? ρ tot . The pertinent MIRs are displayed as functions of α 2 (with
α 1 = 1), and computed for different values of the transmission rates of the
single subnetworks and clusters.
in (29) is confirmed across the whole range of α 2 and for
all the considered values of overlap. Furthermore, for very
small values of α 2 all the curves tend to collapse, since they
correspond to the degenerate case where cluster 2 has empty
emulation dictionary.
In Fig. 6 we repeat the analysis by using an intermediate
overlap degree ω 12 = 0.5, and by considering different values
for the transmission rates, corresponding to four practical
scenarios. Scenario 1 (dashed-dotted curves) accounts for the
case where the activity of subnet S a is predominant w.r.t. the
activity of S b . Under scenario 2 (dashed curves), the activity
of bots from cluster 2 is more intense than the activity of bots
from cluster 1. Scenarios 3 (dotted curves) and 4 (solid curves)
are mixed combinations of the other two scenarios.
Remarkably, in all our experiments we observed that (29)
was verified. While we cannot claim that BotClusterBuster is
consistent when (19) is violated and/or under the asymmet-
ric scenario, the conducted numerical analysis explains why
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3564 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
BotClusterBuster is in fact able to discriminate bots from
normal users under various practical conditions, as we will
see in detail in the section devoted to simulations.
VI. E XPERIMENTAL R ESULTS
In this section we report the results of an experimental
campaign that we have conducted to validate the theoreti-
cal analysis developed in the previous sections. In order to
provide a quantitative assessment of the botnet identification
performancewe introduce two indicators, namely, the expected
fraction of correctly identified bots and the expected fraction
of normal users declared as bots, namely,
η bot (t) =
E[| ˆ B(t) ∩ B|]
|B|
, η nor (t) =
E[| ˆ B(t) ∩ (N \ B)|]
|N \ B|
.
(31)
where
?
B(t) denotes the botnet estimated at time t. Ideally,
we want an identification algorithm that, for sufficiently long
observation time, estimates a botnet comprising all the true
bots and no normal users, which amounts to:
lim
t→∞
η bot (t) = 1, lim
t→∞
η nor (t) = 0. (32)
Let us now delve into the description of the experimental
setup. First of all, we constructed two different datasets
containing traffic patterns from legitimate network users. In
the forthcoming analysis, we will test BotClusterBuster over
both datasets. The first dataset, which will be referred to as
CampusDataset, was built by asking 100 people, randomly
polled around the Campus of the University of Salerno,
to query an auction portal for about 3 minutes. The second
dataset, which will be referred to as LabDataset, was built
in the Co.Ri.Tel Laboratory of the University of Salerno. We
asked 10 people among students and researchers to query an
e-commerce portal for about 20 minutes. With regard to this
dataset, in order to obtain a larger number of legitimate users,
we divided the traffic patterns into chunks lasting about 2
minutes, and considered each chunk as an independent user,
obtaining a total number of 100 normal users. In both datasets,
each traffic “track” is representative of a normal user. The
application-layer patterns of these tracks have been captured
by a network sniffer.
Once the normal users activity has been produced, we focus
on the multi-cluster DDoS attack. Different from what
obtained for normal users, for the botnet we did not have
access to real-world application-layer attacks. Accordingly,
on the same website where the normal users surfed, we crafted
the bot patterns by randomly picking valid HTTP requests
from the ensemble of requests produced by the monitored
real-world users. 1 Let us now illustrate how the emulation
dictionary is split over the individual clusters. We will consider
3 clusters. First, we join all the normal-user tracks pertaining
to the particular dataset, obtaining 27072 packets for the
CampusDataset and 22178 packets for the LabDataset, and
consider this ensemble of messages as the overall emulation
1 Needless to say, we did not launch a DDoS attack against any website.
We simulated the emission of requests, without effectively sending these
requests to the target site.
dictionary to be disseminated across the botnet. We remark
that using the same messages chosen by the normal users
automatically introduces a correlation between these latter and
the bots, which makes botnet identification even more difficult.
Then we divide the overall dictionary into 7 sets:
E 1 , E 2 , E 3 , E 12 , E 13 , E 23 , E 123 , (33)
where i) all sets are mutually disjoint; ii) the indices appearing
as subscripts denote the cluster(s) using messages in that
particular set. For example, E 1 contains messages that can be
accessed only by cluster 1 and E 123 contains messages that are
available for all clusters. Then, let us focus on cluster 1 for the
sake of definiteness. As initialization, we assume that at time
t = 0 the emulation dictionary E 1 (0) contains 100 messages
chosen, e.g., from E 1 . Then, at time t > 0 the dictionary E 1 (t)
adds to these 100 messages ?α 1 t? messages picked from the
sets relative to cluster 1, partitioned as follows:
?α 1 ω 123 t? from E 123 ,
?α 1 (ω 12 − ω 123 )t? from E 12 ,
?α 1 (ω 13 − ω 123 )t? from E 13 ,
?α 1 (1 − ω 12 − ω 13 + ω 123 )t? from E 1 , (34)
where ω 12 and ω 13 are the overlap degrees introduced in (26),
and ω 123 is the (sub-)fraction of elements that is picked from
the intersection E 123 , common to all the three clusters. 2 The
same procedure is applied to all clusters. Then it is easily
verified that the dictionary construction fulfills the following
conditions, for all i, j ∈ {1,2,3}:
lim
t→∞
|E i (t)|
t
= α i , lim
t→∞
|E i (t) ∩ E j (t)|
|E i (t)|
= ω ij . (35)
In order to make the bots similar to legitimate users, both
the bot transmission rates and the EDR have been chosen on
the same order of the corresponding attributes estimated over
the normal users’ traces. Finally, in the following experiments
we will consider 3 clusters, for different network sizes, cluster
cardinalities, and EDRs. The specific setup of each simulation
is detailed in Table III. We are now ready to examine the
performance of the BotClusterBuster algorithm. We start by
considering the setup reported in the first row of Table III.
In Fig. 7, from left to right, we illustrate the results cor-
responding to decreasing values of the threshold parameter
θ ∈ {0.95,0.9,0.75,0.5}.Let us start by examiningthe bottom
plots, where we display an algorithm snapshot corresponding
the end of the observation window. The decisions produced
by the algorithm are encoded in a graphical matrix, whose
p-th row corresponds to the output of the algorithm when
user p is elected as a pivot. Users are ordered for clarity
of visualization, but this ordering is immaterial, since in our
simulations the bots were randomlyspread over the network. A
white pixel represents the “estimated bot presence”, whereas
a black pixel represents the “estimated bot absence”. Thus,
2 With regard to the picking rule in (34), it is readily seen that not all
configurations of the parameters α i , ω ij and ω 123 are compatible with all
configurations of the sets in (33). We have verified that the configurations
used in our simulations are admissible, which roughly amounts to say that
the cardinalities of the pertinent sets are sufficiently large to make the choices
in (34) admissible for the entire duration of the observation period.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3565
TABLE III
E XPERIMENTS .F OR E ACH E XPERIMENT ,W E R EPORT THE C HOSEN S ETUP . A LL THE E XPERIMENTS W ERE R UN O VER B OTH THE C AMPUS D ATASET AND
THE L AB D ATASET .I N A LL C ASES , W E U SED A C LUSTER E XPURGATION T HRESHOLD β = 0.05, A RISING F ROM THE C HOICES κ = 1 AND ξ = 0.1
Fig. 7. Experiments corresponding to the first configuration in Table III. Top and middle rows. Performance of the botnet identification algorithm, evaluated
over the LabDataset (top) and the CampusDataset (middle). Bottom row. Algorithm snapshot corresponding the end of the observation window: the decisions
produced by the algorithm are encoded in a graphical matrix whose p-th row corresponds to the output of the algorithm when user p is elected as a pivot.
A white pixel in the location (p,q) signifies that the algorithm is estimating (before applying the particular cluster selection rule) that user q is a bot when
user p is elected as pivot. We consider different values of the threshold parameter, in particular, from left to right we have θ = 0.95,0.9,0.75,0.5. The
algorithm snapshots correspond to the CampusDataset.
if pixel (p,q) is white, the algorithm is estimating (before
applying the particular cluster selection rule) that user q is a
bot when user p is elected as pivot.
For θ = 0.95 (bottom row, leftmost plot), condition (19)
is met for the largest degree of overlap, i.e., ω 12 = 0.75.
The presence of the three big white squares of sides 20, 30,
and 50 means that the algorithm is able to identify the 3
clusters properly, in agreement with the theoretical predictions.
We notice also the occasional presence of some white pixels
in the top right block. These pixels correspond to very small
clusters composed of about 2 or 3 normal users. Notably,
the small size of these clusters reveals that the algorithm can
occasionally form a wrong cluster, but that then this cluster
is never paired with other users, i.e., it is very unlikely that
more than a few users can form a wrong botnet. This property
is very important, since clusters with so small cardinalities
cannot have any significance in practice, and there are many
rules one can conceive to discard them. In particular, we will
now see whether the proposed cluster expurgation rule is able
to get rid of this effect. Moreover, we notice that the big
white squares corresponding to the true clusters contain some
black gaps, and are accompanied by some horizontal white
bands. For what concerns gaps, a black pixel in position (p,q)
signifies that the algorithm is not estimating q as member of
the botnet when p is pivot. However, BotClusterBuster is on
purpose designed so as to perform redundant checks, i.e., the
same pairs of nodes are involved in multiple checks. In this
way, a bot is missed only if it is missed by all checks. For
this reason, we see that the occasional black gaps observed in
the white squares are irrelevant if at least one time each bot is
included in a cluster. In the end, the overall set of nodes that
belong at least to one cluster corresponds to the white pixels
covering the main diagonal of the graphical matrix. In relation
to the horizontal white bands, a collection of white pixels in
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3566 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
row p means that the pivot p results paired with many nodes
q, which results into the formation of a relatively large cluster.
Accordingly, we see that occasionally some bots of one cluster
appear paired with bots of another cluster. This effect is clearly
not relevant for DDoS mitigation, as can be concluded from
the fact that η bot (t) ≈ 1 — see the performance curves shown
in the top and middle plots of Fig. 7.
For θ = 0.9 (bottom row, second plot from the left),
condition (19) is still met, however, we are approaching the
case θ = 0.75 which would result into a violation of (19).
Accordingly, we see that the images of the individual clusters
starts to become a bit blurred. When we set θ = 0.75 (bottom
row, third plot from the left), condition (19) is violated, and,
as predicted from our analysis in Sec. V-A, the algorithm does
not lose the capability of identifying the botnet, but loses the
capability of identifying the individual clusters. In particular,
since in our example we have θ = ω 12 = 0.75, but we
have also θ > ω 13 = ω 23 = 0.5, we see that the first two
clusters are merged into a big one, whereas the third cluster
is still correctly identified. Finally, this capability is lost when
θ = 0.5 (bottom row, rightmost plot), which corresponds to
the estimation of a unique big botnet comprising all 100 bots.
Moreover, in the case θ = 0.5 we notice the emergence of
some vertical white bands. A band in column q means that
there exists a node q that results paired with many pivots p.
This corresponds to the formation of many small clusters, one
for each paired pivot. Accordingly, we see that some spurious
small clusters made of normal users arise. As we will see
soon, this effect will play a role in the performance of the
union-rule.
Let us move on to examine the plots in the top and middle
rows of Fig. 7, where we display the algorithm performance
expressed in terms of the indicators η bot (t) and η nor (t), which
have been evaluated over 100 Monte Carlo runs. Top plots
refer to the LabDataset, middle plots to the CampusDataset.
For the sake of clarity, in the following analysis we refer to
the top plots, with similar conclusions holding for the middle
plots. The DDoS evolution is monitored during the observation
window with a time-step of 2 seconds. We show the results
corresponding to the three rules introduced in the previous
sections, namely, the max-rule, the union-rule and the cluster
expurgation rule.
Let us consider first the case θ = 0.95 (top row, leftmost
plot), which meets well condition (19). We start with the
max-rule. From the evolution of η nor (t) (black dashed curve),
we see that the max-rule is effective in rejecting the false
micro-clusters. This happens since the max-rule retains only
the maximum-cardinality cluster, which has however a detri-
mental effect as regards the bot identification. Indeed, we see
that η bot (t) (black solid curve) converges approximately to 0.5,
which means that only the biggest cluster made of 50 bots is
correctly identified.
We continue by illustrating the behavior of the union-rule.
Here we see that the bot identification issue is remediated,
since η bot (t) (red solid curve) converges to 1. This happens
because the union-rule aggregates the detected clusters of any
cardinality. On the other hand, this effect is detrimental as
regards the normal users classification. Indeed, we see that
η nor (t) (red dashed curve) converges approximately to 0.1.
However, this effect must be expected, especially in light of
the analysis of the bottom plots in Fig. 7. The union-rule is in
fact aggregating many clusters of very small cardinality. This
means that, under the union-rule, we are claiming that there
exist a DDoS attack launched by several botnets comprised
of 2 or 3 members, which appears to be a very uncommon
scenario.
Another notable effect observed in the time-evolution of
η nor (t) is the appearance of a peak at some intermediate time.
The explanation of this peak sheds some further light on the
detrimental effects produced by the union-rule. Examining the
individual traffic patterns, we identified one specific normal
user that was performing some anomalous activity. In partic-
ular, they were performing some very intense activity for a
single slot during the entire observation window. As a result,
during this slot of intense activity, this user was coupled to a
very large number of other normal users, giving rise to several
micro-clusters of size 2. The union-rule was then including all
these clusters into the estimated botnet, producing the peak
observed in η nor (t). This effect disappears progressively as
time elapses, since the abnormal behavior of the particular
user is not persistent over time.
Let us finally see whether the cluster expurgationrule is able
to solve both issues experienced under the max-rule and the
union-rule. The performance of BotClusterBuster is accord-
ingly displayed in blue. We see that this algorithm has very
good performance, since η bot (t) (blue solid curve) converges
approximately to 1, and η nor (t) (blue dashed curve) converges
approximately to 0. With regard to the hyperparameterβ of the
cluster expurgation rule, in the experiments we set κ = 1 and
ξ = 0.1, yielding, in view of (24), β = 0.05. We remark that
these are very “agnostic” choices. Indeed, the choice κ = 1
corresponds to say that a DDoS with attack rate barely equal
to a legitimate traffic rate is deemed as dangerous. Likewise,
the choice ξ = 0.1 corresponds to say that a cluster is deemed
as meaningful if it sustains barely 10% of the botnet activity.
From the analysis of the top left plot in Fig. 7, we conclude
that BotClusterBuster delivers good performance under the
conditions used to prove our theoretical results. Let us now see
how a reduction of the threshold parameter θ influences the
performance. To this end, we examine the second, third and
fourth top plots in Fig. 7. For what concerns the max-rule,
we see that η nor (t) (black dashed curve) converges approx-
imately to 0 in all cases. In other words, the performance
in terms of normal users is not affected by variations of
θ. In comparison, for the max-rule the index η bot (t) (black
dashed curve) is sensitive to θ, and in particular increases as
θ decreases. For example, when the algorithm aggregates two
clusters into a big cluster of size 80, then η bot (t) converges
approximately to 0.8 (top row, third plot from the left),
whereas when a unique cluster is produced, then η bot (t)
converges approximately to 1 (top row, rightmost plot).
For what concerns the union-rule, we see that η bot (t)
(red solid curve) converges approximately to 1, irrespective
of the value of θ, which is expected since the union rule
aggregates all detected clusters and, hence, is not sensitive
to the individual clusters. On the other hand, the union-rule
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3567
Fig. 8. Experiments corresponding to the second configuration in Table III.
Top. Performance of the botnet identification algorithm. Bottom. Algo-
rithm snapshot corresponding the end of the observation window: the decisions
produced by the algorithm are encoded in a graphical matrix whose p-th row
corresponds to the output of the algorithm when user p is elected as a pivot.
A white pixel in the location (p,q) signifies that the algorithm is estimating
(before applying the particular cluster selection rule) that user q is a bot when
user p is elected as pivot. Left plots refer to the LabDataset, whereas right
plots to the CampusDataset.
performance degrades severely when we decrease the value of
θ, since lower values of θ favor the emergence of false micro-
clusters. Accordingly, we see that η nor (t) (red dashed curve)
increases, i.e., the performance degrades as θ decreases.
So far we have shown that BotClusterBuster provides proper
cluster identification when the technical conditions used to
prove the theoretical results are met, and continues to provide
proper botnet identification even when condition (19) is vio-
lated. Now we want to check what happens when we deviate
further from the nominal conditions by allowing for clusters’
asymmetries, as described in Sec. V-B. Specifically, we focus
on the configuration reported in the second row of Table III.
We notice that in this asymmetric setting, the overlap degrees
ω 21 , ω 31 and ω 32 can be obtained from the overlap degrees
shown in the table by exploiting the constraints in (27). The
results of these experiments are reported in Fig. 8, with
reference to the case θ = 0.95, and for the two datasets,
namely, LabDataset (left) and CampusDataset (right). As
predicted by the numerical analysis carried out in Sec. V-C,
asymmetries in the EDRs do not lead to significant variations
in the botnet identification performance. In summary, we reach
the remarkable conclusion that both the asymmetries and the
violation of (19) do not impair consistent botnet identification.
A. Sensitivity to Algorithm and Attack Parameters
The simulation setup considered in the previous section was
constructed according to the following logic. In our datasets,
we arrive at a maximum number of normal users equal to
100. Accordingly, we considered a DDoS attack where the
total number of bots is equal to the number of legitimate
users and all bots have rates comparable to legitimate users,
so as not to arouse suspicion. Regarding the hyperparameters
of BotClusterBuster, the experiments in Figs. 7 and 8 already
Fig. 9. Performance of the botnet identification algorithm for the third con-
figuration in Table III, relative to the LabDataset (top) and the CampusDataset
(bottom). In the left plots we used a threshold parameter θ = 0.95, whereas
in the right plots θ = 0.5.
spanned a range of values for the threshold parameter θ and
examined its impact on the botnet identification performance.
It remains to examine the role of the other hyperparameter,
namely, the cluster expurgation threshold β. In the examples
presented so far, we computed β starting from the “physical”
parameters κ and ξ described in Sec. IV-B. In particular,
we set: κ = 1, which corresponds to a balanced network
administrator that starts being alerted when the request rate
coming from the botnet is comparable with the request rate
coming from normal users; and ξ = 0.1, which corresponds
roughly to the assumption that the smallest cluster carries at
least 1/10 of the global botnet activity. Figures 7 and 8 show
that BotClusterBuster performs well under the considered
setup. Now we want to examine the effect of varying this
setup. To this end, we could vary the values of κ and ξ
by keeping the attack parameters fixed, or varying the latter
parameters while keeping fixed the former. For the sake of
clarity, we find it convenient to opt for the second choice, and
accordingly consider the following two paradigmatic cases.
– Network Administrator “anxious” in comparison to the
real attack. Under this setup (third row in Table III), the bots
are distributed over three clusters of sizes 75, 65, and 60. As a
consequence, the cluster expurgation threshold chosen by the
network administrator, which stems from the choices κ = 1
and ξ = 0.1, turns out to be conservative, in the sense that
the minimum expected cluster is significantly smaller than the
smallest cluster effectively present in the data. The left plots
(one for each dataset) in Fig. 9 refer to the case where the
threshold parameter is θ = 0.95, namely, condition (19) is
fulfilled. Accordingly, since the network administrator made
a conservative choice, we see that BotClusterBuster is con-
sistently able to identify the botnet, and particularly the
individual clusters. In comparison, the right plots address the
case θ = 0.5, where all bots are still correctly guessed, while
the individual cluster identifiability is lost. We remark that,
under this setting where individual cluster identifiability is of
no concern, the influence of the cluster expurgation parameters
becomes immaterial.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
3568 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 16, 2021
Fig. 10. Performance of the botnet identification algorithm for the fourth
configuration in Table III, relative to the LabDataset (top) and the Campus-
Dataset (bottom). In the left plots we used a threshold parameter θ = 0.95,
whereas in the right plots θ = 0.5.
– Network Administrator “relaxed” w.r.t. to the real attack.
Under this setup (last row in Table III), the bots are distributed
over three clusters of sizes 25, 20, and 5. Now, the cluster
expurgation threshold set by the network administrator, stem-
ming from the choices κ = 1 and ξ = 0.1, corresponds to a
“relaxed” choice, in the sense that the network administrator
judges dangerous an attack stronger than the attack actually
taking place. As a result, the minimum expected cluster is
now larger than the smallest cluster effectively present in the
data. The left plots in Fig. 10 confirm this observation, since
we see that η bot (t) saturates to 0.9, which corresponds to the
fact that the smallest cluster of size 5 is missed. Remarkably,
the right plots in Fig. 10 show that we can conveniently trade
off cluster identifiability for correct identification of the entire
botnet (η bot (t) → 1), a capability that is in fact fully recovered
with the intermediate threshold θ = 0.5.
VII. L IMITATIONS AND P ERSPECTIVES
We considered Distributed Denial of Service (DDoS) attacks
launched by a botnet whose members have access to an
emulation dictionary made of admissible requests to mimic
the activity of legitimate network users. The emulation dic-
tionary is distributed across the bots, in such a way that
different clusters of bots pick their messages from different
emulation dictionaries. These dictionaries entail a certain
diversity, i.e., they are not totally overlapped, but also some
commonalities, i.e., their intersection is not empty. For this
novel and challenging scenario, we have first computed the
message innovation rate corresponding to pairs of bot clusters.
We showed that the aggregate innovation rate is a convex
combination, with weights ruled by the overlap degree, of:
i) the innovation rate of a single botnet aggregating the two
clusters and using a single emulation dictionary; and ii) the
sum of the individual innovation rates. This technical result
was useful to devise and examine a botnet identification
algorithm nicknamed BotClusterBuster, which was specifically
equipped with a cluster expurgation rule to manage the
appearance of spurious clusters that should be judiciously
discriminated from the multiple co-existing bot clusters. From
a theoretical standpoint, we showed that BotClusterBuster
provides exact classification of bots and normal users under
reasonable technical conditions. From a practical standpoint,
we assessed the resilience of this algorithm in presence
of deviations from these technical conditions, both through:
i) a numerical analysis carried over a broad range of system
parameters; ii) an experimental campaign conducted over two
real traffic dataset crafted, under different operative conditions,
in our Laboratory and in our University Campus.
The bottom line is that correct botnet identification under
DDoS attacks with multiple emulation dictionaries is possible,
and the proposed technique seems promising, particularly
because it looks robust to several practical issues that are
expected in practice, such as, e.g., deviation from nominal
conditions, setting of the hyperparameters, large variability
across the activities of real-world network users.
The above summary highlights the potential fruitful appli-
cation of the methods proposed in this work in the context
of L7-DDoS attacks. On the other hand, these methods have
certainly limitations, leaving several questions open.
One limitation of our study is that, while we were able to
use real-world traffic traces for the normal users, the malicious
traffic traces were instead synthetically generated according
to a random mechanism, picking messages from the set of
legitimate requests produced by the real-world monitored
users. As it is well known, malicious traces taken from
real-world applications are not publicly available, or are avail-
able under limited permissions that do not allow to extract
sufficient information to test the pertinent algorithms. For these
reasons, we were not able to get permissions to obtain an
application-layer DDoS real-world attack with accessible mes-
sage content. Validating the conducted analysis also on data
taken from real DDoS attacks would constitute an important
progress.
Another relevant aspect pertains to computational complex-
ity. The identification algorithm features a complexity scaling
quadratically with the network size. A useful extension would
be the design of novel algorithms to reduce the computational
burden while still ensuring botnet identification.
Finally, recent and powerful asymmetric DDoS variants
have been considered, where, e.g., few HTTP requests can
produce bulky responses from the target website, inducing an
amplification effect that saturates the target resources with a
relatively small amount of carefully chosen HTTP requests.
Albeit the focus of this work was on symmetric L7-DDoS
attacks, it is worth exploring whether some of the method-
ologies to detect anomalous correlation between bots can be
leveraged also in asymmetric scenarios.
A CKNOWLEDGMENT
The authors are indebted to Alfonso Esposito, who assem-
bled the CampusDataset used in the experiments.
R EFERENCES
[1] M. Cirillo, M. D. Mauro, V. Matta, and M. Tambasco, “Application-layer
DDoS attacks with multiple emulation dictionaries,” in Proc. IEEE Int.
Conf. Acoust., Speech Signal Process. (ICASSP), Toronto, ON, Canada,
Jun. 2021, pp. 2610–2614.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
CIRILLO et al.: BOTNET IDENTIFICATION IN DDoS ATTACKS WITH MULTIPLE EMULATION DICTIONARIES 3569
[2] M. Barni and B. Tondi, “The source identification game: An information-
theoretic perspective,” IEEE Trans. Inf. Forensics Security, vol. 8, no. 3,
pp. 450–463, Mar. 2013.
[3] A. Abrardo, M. Barni, K. Kallas, and B. Tondi, “A game-theoretic
framework for optimum decision fusion in the presence of Byzantines,”
IEEE Trans. Inf. Forensics Security, vol. 11, no. 6, pp. 1333–1345,
Jun. 2016.
[4] M. Barni and B. Tondi, “Source distinguishability under distortion-
limited attack: An optimal transport perspective,” IEEE Trans. Inf.
Forensics Security, vol. 11, no. 10, pp. 2145–2159, Oct. 2016.
[5] M. Mardani, G. Mateos, and G. B. Giannakis, “Dynamic anomalogra-
phy: Tracking network anomalies via sparsity and low rank,” IEEE J.
Sel. Topics Signal Process., vol. 7, no. 1, pp. 50–66, Feb. 2013.
[6] P. Venkitasubramaniam, T. He, and L. Tong, “Anonymous network-
ing amidst eavesdroppers,” IEEE Trans. Inf. Theory, vol. 54, no. 6,
pp. 2770–2784, Jun. 2008.
[7] J. Kim and L. Tong, “Unsupervised and nonparametric detection of
information flows,” Signal Process., vol. 92, no. 11, pp. 2577–2593,
Nov. 2012.
[8] S. Marano, V. Matta, T. He, and L. Tong, “The embedding capacity
of information flows under renewal traffic,” IEEE Trans. Inf. Theory,
vol. 59, no. 3, pp. 1724–1739, Mar. 2013.
[9] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, “DDoS in the IoT:
Mirai and other botnets,” Computer, vol. 50, no. 7, pp. 80–84, 2017.
[10] M. J. Farooq and Q. Zhu, “Modeling, analysis, and mitigation of
dynamic botnet formation in wireless IoT networks,” IEEE Trans. Inf.
Forensics Security, vol. 14, no. 9, pp. 2412–2426, Sep. 2019.
[11] M. Hammoudeh et al., “Network traffic analysis for threat detection
in the Internet of Things,” IEEE Internet Things Mag., vol. 3, no. 4,
pp. 40–45, Dec. 2020.
[12] R. Winward. IoT Attack Handbook. Accessed: May 25, 2021. [Online].
Available: https://www.radware.com/iot-attack-ebook/
[13] A. Marzano et al., “The evolution of Bashlite and Mirai IoT botnets,”
in Proc. ISCC, Natal, Brazil, Jun. 2018, pp. 813–818.
[14] N. Hoque, D. K. Bhattacharyya, and J. K. Kalita, “Botnet in DDoS
attacks: Trends and challenges,” IEEE Commun. Surveys Tuts., vol. 17,
no. 4, pp. 2242–2270, 4th Quart., 2015.
[15] Z. Liu, H. Jin, Y.-C. Hu, and M. Bailey, “Practical proactive DDoS-attack
mitigation via endpoint-driven in-network traffic control,” IEEE/ACM
Trans. Netw., vol. 26, no. 4, pp. 1948–1961, Aug. 2018.
[16] L. Feinstein, D. Schnackenberg, R. Balupari, and D. Kindred, “Statistical
approaches to DDoS attack detection and response,” in Proc. Inf.
Survivability Conf. Expo. (DARPA), Washington, DC, USA, Apr. 2003,
pp. 303–314.
[17] L. Li, J. Zhou, and N. Xiao, “DDoS attack detection algorithms based
on entropy computing,” in Proc. ICICS, Zhengzhou, China, Dec. 2007,
pp. 452–466.
[18] J. Yuan and K. Mills, “Monitoring the macroscopic effect of DDoS
flooding attacks,” IEEE Trans. Dependable Secure Comput., vol. 2, no. 4,
pp. 324–335, Oct. 2005.
[19] Z. Liu, Y. Cao, M. Zhu, and W. Ge, “Umbrella: Enabling ISPs to offer
readily deployable and privacy-preserving DDoS prevention services,”
IEEE Trans. Inf. Forensics Security, vol. 14, no. 4, pp. 1098–1107,
Apr. 2019.
[20] Y. Xiang, K. Li, and W. Zhou, “Low-rate DDoS attacks detection and
traceback by using new information metrics,” IEEE Trans. Inf. Forensics
Security, vol. 6, no. 2, pp. 426–437, Jun. 2011.
[21] J. Luo, X. Yang, J. Wang, J. Xu, J. Sun, and K. Long, “On a math-
ematical model for low-rate shrew DDoS,” IEEE Trans. Inf. Forensics
Security, vol. 9, no. 7, pp. 1069–1083, Jul. 2014.
[22] M. E. Ahmed, S. Ullah, and H. Kim, “Statistical application fingerprint-
ing for DDoS attack mitigation,” IEEE Trans. Inf. Forensics Security,
vol. 14, no. 6, pp. 1471–1484, Jun. 2019.
[23] B. Rashidi, C. Fung, and E. Bertino, “A collaborative DDoS
defence framework using network function virtualization,” IEEE
Trans. Inf. Forensics Security, vol. 12, no. 10, pp. 2483–2497,
Oct. 2017.
[24] R. Biswas, S. Kim, and J. Wu, “Sampling rate distribution for flow mon-
itoring and DDoS detection in datacenter,” IEEE Trans. Inf. Forensics
Security, vol. 16, pp. 2524–2534, 2021.
[25] A. Praseed and P. S. Thilagam, “DDoS attacks at the application layer:
Challenges and research perspectives for safeguarding Web applica-
tions,” IEEE Commun. Surveys Tuts., vol. 21, no. 1, pp. 661–685,
1st Quart., 2019.
[26] A. Wang, W. Chang, S. Chen, and A. Mohaisen, “Delving into Internet
DDoS attacks by botnets: Characterization and analysis,” IEEE/ACM
Trans. Netw., vol. 26, no. 6, pp. 2843–2855, Dec. 2018.
[27] Layer 7 DDoS–Blocking HTTP Flood Attacks. Accessed: May 25, 2021.
[Online]. Available: https://blog.sucuri.net/2014/02/layer-7-ddos-
blocking-http-flood-attacks.html
[28] Taxonomy of DDoS Attacks. Accessed: May 25, 2021. [Online]. Avail-
able: https://www.riorey.com/types-of-ddos-attacks/#attack-15
[29] S. Ranjan, R. Swaminathan, M. Uysal, A. Nucci, and E. Knightly,
“DDoS-shield: DDoS-resilient scheduling to counter application layer
attacks,” IEEE/ACM Trans. Netw., vol. 17, no. 1, pp. 26–39, Feb. 2009.
[30] A. Praseed and P. S. Thilagam, “Modelling behavioural dynamics
for asymmetric application layer DDoS detection,” IEEE Trans. Inf.
Forensics Security, vol. 16, pp. 617–626, 2021.
[31] A. Praseed and P. S. Thilagam, “Multiplexed asymmetric attacks: Next-
generation DDoS on HTTP/2 servers,” IEEE Trans. Inf. Forensics
Security, vol. 15, pp. 1790–1800, 2020.
[32] Verizon Media Platform. Application Layer DDoS Mitigation in Action.
Accessed: May 25, 2021. [Online]. Available: https://vzmediaplatform.
medium.com/application-layer-ddos-mitigation-in-action-ee73e2ee4075
[33] International Botnet and IoT Security Guide 2020. Accessed:
May 25, 2021. [Online]. Available: https://securingdigitaleconomy.org/
wp-content/uploads/2019/11/CSDE_Botnet-Report_2020_FINAL.pdf
[34] T. Mahjabin, Y. Xiao, T. Li, and C. L. P. Chen, “Load distributed
and benign-bot mitigation methods for IoT DNS flood attacks,” IEEE
Internet Things J., vol. 7, no. 2, pp. 986–1000, Feb. 2020.
[35] Z. A. El Houda, L. Khoukhi, and A. S. Hafid, “Bringing intelligence
to software defined networks: Mitigating DDoS attacks,” IEEE Trans.
Netw. Service Manage., vol. 17, no. 4, pp. 2523–2535, Dec. 2020.
[36] C. Wang, T. T. N. Miu, X. Luo, and J. Wang, “SkyShield: A sketch-
based defense system against application layer DDoS attacks,” IEEE
Trans. Inf. Forensics Security, vol. 13, no. 3, pp. 559–573, Mar. 2018.
[37] Y. Xie and S.-Z. Yu, “Monitoring the application-layer DDoS attacks for
popular websites,” IEEE/ACM Trans. Netw., vol. 17, no. 1, pp. 15–25,
Feb. 2009.
[38] V. Matta, M. Di Mauro, and M. Longo, “Botnet identification in
randomized DDoS attacks,” in Proc. 24th Eur. Signal Process. Conf.
(EUSIPCO), Aug. 2016, pp. 2260–2264.
[39] V. Matta, M. Di Mauro, and M. Longo, “DDoS attacks with randomized
traffic innovation: Botnet identification challenges and strategies,” IEEE
Trans. Inf. Forensics Security, vol. 12, no. 8, pp. 1844–1859, Aug. 2017.
[40] V. Matta, M. Di Mauro, and M. Longo, “Botnet identification in
multi-clustered DDoS attacks,” in Proc. EUSIPCO, Kos, Greece,
Aug./Sep.Received February 20, 2021, accepted March 7, 2021, date of publication March 18, 2021, date of current version March 29, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3066957
IMDoC: Identification of Malicious Domain
Campaigns via DNS and Communicating Files
DAVID LAZAR
1 , KOBI COHEN 2 , (Senior Member, IEEE), ALON FREUND 3 ,
AVISHAY BARTIK
3 , AND AVIV RON 3
1 Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel
2 School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel
3 IBM Cyber Security Center of Excellence, Beer Sheva 8489325, Israel
Corresponding author: Kobi Cohen (yakovsec@bgu.ac.il)
This work was supported in part by the IBM Cyber Security Center of Excellence at Gav-Yam Negev, and in part by the Israeli National
Cyber Bureau via the Cyber Security Research Center at Ben-Gurion University of the Negev.
ABSTRACT Cyber attacks have become more sophisticated and frequent over the years. Detecting the
components operated during a cyber attack and relating them to a specific threat actor is one of the main
challenges facing cyber security systems. Reliable detection of malicious components and identification
of the threat actor is imperative to mitigate security issues by Security Operations Center (SOC) analysts.
The Domain Name System (DNS) plays a significant role in most cyber attacks observed nowadays in
that domains act as a Command and Control (C&C) in coordinated bot network attacks or impersonate
legitimate websites in phishing attacks. Thus, DNS analysis has become a popular tool for malicious domain
identification.InthiscollaborativeresearchassociatingBen-GurionUniversityandIBM,wedevelopanovel
algorithm to detect malicious domains and relate them to a specific malware campaign in a large-scale real-
data DNS traffic environment, dubbed Identification of Malicious Domain Campaigns (IMDoC) algorithm.
Its novelty resides in developing a framework that combines the existence of communicating files for
the observed domains and their DNS request patterns in a real production environment. The analysis
was conducted on real data from Quad9 (9.9.9.9) DNS recursive resolvers combined with malicious
communicating files extracted from VirusTotal, and confirms the strong performance of the algorithm on
a real large-scale data production environment.
INDEX TERMS Cyber security, domain name system (DNS), clustering methods, detection algorithms.
I. INTRODUCTION
The Domain Name System (DNS) is a fundamental com-
ponent of the functionality of the internet. DNS provides a
mapping between domain names and IP addresses, which is
a core service for applications on the internet. Since DNS
is ubiquitous across the internet, DNS services have been
abused in different ways to execute a range of attacks [1].
An attacker can exploit a set of domains to carry out complex
attacks, while targeting users and organizations through mal-
ware related campaigns such as phishing [2]–[4], pharming
[5], [6], and Distributed Denial of Service (DDoS) attacks
using a multitude of botnets [7], [8]. One notorious example
is the Dyn DDoS cyberattack by the Mirai botnet in 2016 [9].
The associate editor coordinating the review of this manuscript and
approving it for publication was Gautam Srivastava .
To respond to this malicious use of the DNS, domain
blacklists containing known malware domains [10] and IP
reputation information [11] have been developed by net-
work operators to detect DNS queries originating from
malware-infected machines and block their communications
withtheattackers.TocreatetheseblacklistsandIPreputation
information, malicious domains and IP addresses must be
identified to separate them from benign ones. This effort
is crucial since security vendors should not block benign
domains from their clients.
Once a malicious domain has been identified, it is imper-
ative to determine which threat actor or malware campaign
the domain is related to. This can shed light on the type of
malicious activity of the domain and its purpose. This kind
of information can allow Security Operations Center (SOC)
analyststobetterunderstandcybersecuritythreatsandhandle
them efficiently and reliably. The relationship of a given
45242
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
domain to a specific malicious activity can help security
researchers build effective models to mitigate security issues.
Moreover, it can help analysts and researchers to gain better
insights of an observed threat group and help in classifying
executables to a specific malware in addition to YARA rules
and other methods.
OneofthemostpopularwaysofanalyzingDNStrafficisto
use passive DNS (pDNS) data (see [12]–[15] and references
therein). The analysis is performed offline on a copy of live
DNS traffic to study past DNS traffic patterns to evaluate the
maliciousness of non-categorized domains. Offline calcula-
tions overcome the need to process a huge amount of data
in real-time. Recent studies have analyzed pDNS to isolate
malicious domains and IP addresses, and identify infected
machines [12]–[15]. However, developing robust methods to
relatemaliciousdomainstoamalwarecampaignhasnotbeen
addressed and is the main focus of this paper.
Relating a massive amount of unknown domains to a
malware campaign based solely on DNS traffic is a very
challengingtask.However,whencombiningDNStrafficwith
threat intelligence data, a robust method for this task can be
constructed. In this paper, our method utilizes the communi-
cating files of suspicious domains together with passive DNS
traffic to relate unknown domains to a malware campaign.
The communicating files were extracted using VirusTotal’s
file analysis database. The passive DNS traffic was derived
from a real production environment, namely, Quad9 DNS
servers.
A. MAIN RESULTS
This paper addresses the problem of expanding a seed
of known malicious domains related to the same mal-
ware campaign to categorize unknown domains as mali-
cious and related to this malware campaign. Related stud-
ies of malicious domain detection have relied mostly on
DNS patterns and characteristics or domain name analysis
to find evidence of a Domain Generation Algorithm (DGA)
[12]–[14], [16]–[19]. However, these methods are only
used to distinguish between benign and malicious domains.
In[20],theauthorsconsideredtheproblemofidentifyingnew
malicious domains related to an observed campaign, as con-
sidered in this paper. Their method was based on clustering
known malicious domains from the same campaign together
with uncategorized domains to find new malicious domains
related to the observed campaign. It achieved good perfor-
mance in detecting phishing attacks in which the domain
name has a specific structure (where the attacker tries to
mimic a domain name of a well-known website). However,
its performance degrades when facing general attacks when
the domain name is structure agnostic, such as general C&C
domains. In this paper we overcome this issue by developing
a novel robust method for detecting general attacks. It should
be noted that the system described here is not intended to
find zero-day attacks since these are beyond the scope of
this paper. These types of attacks are typically addressed
by anomaly detection algorithms trained on benign samples.
Below, we summarize our main contributions.
1) A NOVEL METHOD TO RELATE MALICIOUS DOMAINS TO
MALWARE CAMPAIGNS BASED ON COMMUNICATING FILES
We develop a novel method to determine the malware cam-
paign of a malicious domain based on its communicating
files. The novelty resides in the use of the communicating
files of each domain to categorize it to its malware campaign.
Our approach takes a set of malicious domains and clusters
them as a function of their malware family distributions
based on communicating files, without relying on their DNS
features at all. This allows the system to relate malicious
domains to malware campaigns with high reliability when
communicating files are available. This contrasts sharply
with most malicious domain identification methods that rely
heavily on DNS features.
2) A NOVEL METHOD TO DETECT UNCATEGORIZED
DOMAINS FROM A SPECIFIC MALWARE CAMPAIGN
BASED ON DNS DATA
We develop a novel method to identify uncategorized mali-
cious domains and relate them to an observed malware cam-
paign. This is done by using the time-based correlation of the
number of aggregated DNS requests per day between a set of
malicious domains from the same malware campaign and a
suspicious domain. Note that in [20], the method clustered a
set of domains based on DNS features for a fixed time frame
(a fixed week for all domains in the set in their experiments)
regardless of the IP change events of domains involved in the
clustering process. Unlike [20], we innovate by analyzing a
dynamic time-frame selection (a week in our experiments)
which starts from the last observed IP change event of each
pair of the known malicious domain and the new suspicious
domain involved in the time-based correlation. This method
allows for detection of new suspicious domains with high
reliability through its dynamic time correlation analysis.
3) ALGORITHM DEVELOPMENT
We develop an algorithm to identify new malicious domains
in the context of a malware campaign, dubbed Identification
of Malicious Domain Campaigns (IMDoC). The algorithm
processes communicating files data as well as DNS data
to identify malicious domains by utilizing the two methods
described above. IMDoC algorithm works as follows. The
algorithm is divided into 3 main stages: Train, Expand, and
Predict.AnillustrationofthealgorithmcanbefoundinFig.2
in Section IV. In the Train stage, the algorithm performs a
training phase, where known malicious domains are given.
In the training process, a feature vector is constructed using
the domains’ communicating files. Then, clustering algo-
rithmsareappliedtothedomainsbasedonthefeaturevectors.
Next, in the Expand stage, the algorithm expands each of
the clusters by their resolved IPs, and as a result obtains
new samples which are loosely connected to the observed
maliciousdomains.Finally,inthePredictstage,thealgorithm
VOLUME 9, 2021 45243
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
uses one of the two methods described above, depending on
whether communicating files are available or not, to decide
whether the new expanded domains (i.e., the candidates) are
a part of the observed malicious campaign or not.
4) EXTENSIVE PERFORMANCE EVALUATION USING REAL
DATA IN A REAL PRODUCTION ENVIRONMENT
Enterprises tend to be reluctant to share their data and
real-world security performance because of the legal risks of
violating privacy, or to avoid sharing information that could
benefittheircompetitors.Therefore,analyzingandvalidating
cyber security algorithms in real-world systems using up-to-
date real data is one of the main hurdles in academic cyber
security research. This collaboration between Ben-Gurion
University and IBM constitutes an important step forward.
We deployed the algorithm in a real working production
environment, and analyzed and validated its performance
using up-to-date data. Specifically, the performance evalua-
tion consisted of data from Quad9 (9.9.9.9), a free service
IBM launched with Packet Clearing House (PCH) and the
Global Cyber Alliance (GCA). Quad9 handles a massive
amount of DNS requests and responses daily at the recursive
resolver layer, and provides several datasets that originate
from these requests and responses. These datasets are filtered
fromalluser-datatoavoidviolationsofprivacy.Forexample,
one of the datasets we used in this paper is a stream of newly
observed DNS responses, dubbed the Unique DNS Record
(UDR), containing only the queried domain, the query type
and the response record. This stream of around 1 million
UDRrecordsperdaywascondensedfromtheQuad9systems
operatingin76countriesand128locations.Theexperimental
results based on this real-world environment were satisfying
and highly compatible across all tests, and significantly out-
performed existing methods.
B. RELATED WORK
Developing detection methods for cyber security can be
divided broadly into two main approaches: signature-based
detection [21]–[23] and anomaly-based detection [7], [15],
[24]–[27]. To identify malicious domains, detection methods
typically use DNS data, as considered in this paper. Next,
we discuss several aspects of DNS-based detection methods
that were investigated in related studies, including DNS data
collection, data enrichment, ground truth, and algorithmic
methods [16].
1) DNS DATA COLLECTION
The DNS infrastructure is distributed; hence, different loca-
tions can be considered to collect the DNS data. The most
common choice between those is the DNS resolver involve-
ment, since it is the only location that has access to the
clients’ DNS queries. One approach consists of collect-
ing the communication data between an end host (e.g. PC,
smartphone, server) and its DNS resolver (referred to as
the Host-Resolver) [13], [17]. The other collects the com-
munication data between two DNS servers (referred to
as DNS-DNS), one of which may be the DNS resolver
[12], [14]. The first location (Host-Resolver) can pro-
vide detailed information about clients’ DNS queries and
responses (e.g. IP addresses) which can create a better
behavioral pattern for the hosts, because their activity can be
tracked sequentially. In [13], the authors used a table of query
sourceIPaddressesforeachdomainnametocreateaDomain
Name Travel Graph (DNTG) which represents a sequence
of queries in a small time window. In [28], the authors
analyzed a dataset containing more than 26 billion DNS
request-response records collected from more than 600 glob-
ally distributed recursive DNS resolvers to gain insights into
the evolving nature of DNS traffic, and identify malicious
domains. Another advantage of Host-Resolver collection is
that any institute can deploy sensors on its network to col-
lect this kind of DNS data. However, this also can be a
disadvantage since the behavior of hosts can only be seen
within a single organization. The exception is a public DNS
server for recursive queries (e.g. Google Public DNS [29],
Quad9 DNS [30], Cisco OpenDNS [31], Cloudflare 1.1.1.1
DNS [32]). The data collected from these servers is more
diverse because they represent different types of clients and
there is a greater likelihood of catching suspicious behav-
iors related to different attacks. However, because of privacy
issues, public DNS vendors may omit most client details
saved in their datasets.
TheDNS-DNSdatacollectionsensorscollectqueriesfrom
different organizations. In cases where the data are collected
from TLD servers, they have the greatest visibility and can
yield unique insights to expose new malicious trends. How-
ever, the queries’ responses are not available at this level
since these only serve iterative queries. Collecting queries
from an Authoritative server solves this issue. However, due
to caching at the recursive resolver level, not all queries
will be visible to that server. The DNS-ADVP platform [7]
analyzes passive DNS records from an Authoritative DNS
server to identify DDoS (Distributed Denial of Service)
attacks against Top-Level domains. The Kopis system [12]
passively monitors DNS traffic at the upper levels of the
DNS hierarchy (Authoritative servers and TLDs) to detect
malware domains using the global visibility obtained by
monitoring network traffic at the upper DNS hierarchy with-
out relying on monitoring traffic from local recursive DNS
servers. Another distinction between the different DNS data
collection approaches can be made in terms of the method
used to collect the DNS data. One is to initiate queries to
a predetermined large collection of domains to obtain the
domain resolution responses [18]. The other is to collect the
requests and their responses initiated by clients passively [7],
[12]–[14], [20]. The first approach is known as active DNS
data collection, and the latter is called passive DNS data
collection. There are various problems associated with the
active DNS data collection approach. The first is that the
queries initiated by the collector itself do not reflect an actual
user usage pattern. Moreover, if a predetermined limited set
of hosts is queried, the data collected may be biased. On the
45244 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
other hand, active DNS data provides an easy way to collect
data without concerns over privacy issues. Passive DNS data
collection is the approach taken in the majority of studies
conducted in the field of DNS analysis as it better represents
the characteristics of real users and can be more helpful in
identifying trends and patterns in clients’ activity based on
their DNS requests and their corresponding responses.
In the system model considered in this paper, we col-
lected passive DNS data from Quad9, a public DNS recursive
resolver servers. Therefore, the data were collected at the
Host-Resolver level. Bear in mind that the application of
IMDoC is not limited to our evaluation environment and
datasets.ItcanbeappliedtodifferentDNSenvironmentswith
various data collection points (e.g ISP-level).
2) DATA ENRICHMENT
Except for pure DNS data (i.e. request and response), other
sources of information can be used to enrich the data used
in the DNS analysis. In [19], the authors used geo-location
data to determine hosting countries and cities as part of their
IP address analysis. This was used to determine whether an
IP address belonged to a country that is notorious for hosting
malicious domains and to depict the fact that malicious graph
components are often characterized by greater distances
betweencities/countriesinwhichtheirIPsarehosted.In[20],
the authors used the Autonomous System Number (ASN)
from the Border Gateway Protocol (BGP) information as one
of their clustering features. In [18], the authors used WHOIS
data to verify that an IP was public rather than dedicated in
case the Fully Qualified Domain Name (FQDN) belonged to
a hosting service Second Level Domain (SLD). In the system
model considered in this paper, the files communicated with
the observed domains are extracted to enrich the DNS data.
These files can be derived from threat intelligence sites or
from any security vendor report that relates malicious files to
domain names. In our evaluation environment, IMDoC used
VirusTotal as a data source for the communicating files.
3) GROUND TRUTH
Another consideration in a DNS analysis is determining
a high-quality ground truth, whether as a starting seed to
expand from using unsupervised learning methods, or for
training and validation sets using supervised learning meth-
ods. To do so, blacklists and threat intelligence sites can
provide a domains list related to malicious activity. Some
of these blacklists are category-related, such as: spam black-
lists (DNSBL [33]), or phishing blacklists (PhishTank [34],
OpenPhish [35]), whereas other blacklists provide a general
indication of maliciousness (IBM X-Force’s Threat Intel-
ligence database [36], VirusTotal [37], McAfee SiteAdiv-
sor [38], malwaredomainlist.com [39], malc0de.com [40],
DNS-BH [41]). In [13], the authors used a method in which
if one of the cluster members appeared on the blacklist,
the cluster containing the blacklisted domain was marked
as malicious. However, methods based on domain blacklists
are limited to known behaviors, since only known malicious
domains are included. Moreover, one of the problems of
learning from blacklists is that it is a conservative list which
includes only domains that have been confirmed as mali-
cious. However, there are many domains in malicious cam-
paigns that are actually used by malware without directly
contributing to its malicious activity (e.g., C&C commu-
nication, payload download, spam-relaying). Furthermore,
some malicious domains are not on the blacklist because a
specific variant of the malware was not researched or reverse
engineered. Another approach to achieve ground truth on
malicious behavior is to simulate attacks. In [7], the authors
created synthetic DDoS attacks over different time frames to
test their DDoS attack classifier.
In this paper we use popular threat intelligence sites
and domain name blacklists as our ground truth for mali-
cious domains, and specifically OSINT Feeds - Bambenek
Consulting [42], Netlab OpenData Project [43], and Alien-
Vault - Open Threat Exchange [44]. Furthermore, we used
DGArchive [45] to validate our predicted domains. This
ground truth fits our objective of expanding a seed of
known malicious domains that relates to a certain malware
campaign.
4) ALGORITHMIC METHODS
Different algorithmic methods via DNS analysis have been
suggested to identify malicious domains. In [13], the authors
constructed a graph from a batch of ordered queries in a cer-
tain timeslot and clustered the domains based on sequential
correlation. In [14], a single domain at a time was inspected
by constructing a domain graph which represented the cor-
relation among different domains. A path-based mechanism
was used to derive a malicious score for each domain. A dif-
ferent approach proposed in [46] calculated the reputation
score based on domain name lexical features.
Amorecommonapproachistousemachinelearningalgo-
rithms to classify domains as malicious. In [12], the authors
used supervised learning which takes a set of statistical fea-
ture vectors as input, which summarizes the query/response
behavior of each domain. In [47], the J48 decision tree
algorithm was used with a feature vector consisting of both
DNS related features and other network traffic features to
detect domains used for malware C&C servers. In [18],
an iterative semi-supervised random forest classifier was
constructed to separate dedicated and public IP addresses.
In [48], the authors proposed a deep neural networks to clas-
sify domain names as benign or malicious, as part of DGAs.
These methods, however, have not considered the problem
of identifying new malicious domains related to an observed
campaign, as considered in this paper. In [20], the authors
used unsupervised clustering to expand a seed of mali-
cious domains in order to identify new malicious domains.
However, as explained in Subsection I-A, the method is
not robust to general attacks, which is the main focus of
this paper.
VOLUME 9, 2021 45245
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
II. PRELIMINARIES
We start by presenting background knowledge on the
Quad9 DNS Architecture in Subsection II-A, which is the
environmentforthisstudy.WethendescribeVirusTotal(Sub-
section II-B) that was used to extract data about the files
associated with the observed malicious domains, and the
AVClass tool (Subsection II-B1) that was used to parse the
file labeling of VirusTotal’s AV engines.
A. THE Quad9 DNS ARCHITECTURE
The architecture in this paper is based on a real-world envi-
ronment in the form of Quad9, a free service that IBM
launched in collaboration with Packet Clearing House (PCH)
and the Global Cyber Alliance (GCA) to deliver greater
online privacy and security protection to consumers and busi-
nesses[30].Quad9providesastreamofnewlyobservedDNS
responses,oraUniqueDNSRecord(UDR)thatonlycontains
the response domain, query type, and response record. This
stream of roughly 1 million UDR records per day is con-
densedfromtheQuad9systemsoperatingin76countriesand
128 locations. Quad9 also offers aggregations of the request
counts for some domains. These data are called DSURF. Due
to the massive volume Quad9 DNS recursive resolvers deal
with, the aggregation is sampled for only a small percent-
age of the requests that flow through the Quad9 recursive
resolvers.
An illustration of Quad9 DNS architecture is presented
in Fig. 1. Each client sets the Quad9 DNS recursive
resolver address (9.9.9.9) to consume DNS services from
this provider. The Quad9 DNS recursive resolver queries
authoritative DNS servers upon DNS requests by its clients.
Generally, when a DNS client needs to find the IP address
FIGURE 1. An illustration of the Quad9 architecture.
of a host or service known by its FQDN, it queries its DNS
recursive resolver for the IP Address. The recursive resolver
first looks for the IP address in its cache. If it does not exist,
it starts a hierarchical recursive resolution process, which
begins with the root servers and ends at an authoritative name
server. Since the DNS system is hierarchical, the root node
contains the addresses of all Top Level Domain (TLD) name
servers, and the TLD name servers contain the addresses
of Second Level Domain (SLD) name servers. Therefore,
the recursive resolver first requests the root node, followed
by the next tree level, whose addresses are responded to
by current tree level, until an authoritative answer is found
whichyieldstheresponsetotherequestedquery.IftheFQDN
is invalid or non-existent in the tree, the recursive resolver
reports this information to the client.
In our architecture, cached DNS requests do not appear
in the UDR database since it only contains newly observed
DNS responses. Whenever a DNS request does not appear
in the recursive resolver cache and the resolver queries the
rest of the chain of servers within the DNS hierarchical
recursive resolution process, the request is recorded in the
UDR database. As for the DSURF database, the cached DNS
requests for a specific FQDN appear in the aggregation of the
requests. However, as stated above, only a small percentage
of these requests are aggregated.
InordertopreservetheprivacyofQuad9DNSclients,only
some of the details are saved for each request, including the
DNS request code, the queried FQDN, the response code,
Time To Live (TTL), and the resolved IP addresses. The
clients’ identification and characteristics do not appear in the
databases.
B. VirusTotal
VirusTotal [37] is a website that aggregates many
antivirus (AV) products and online scan engines to check
for malware and malicious activity. Upon submitting a file
or domain, basic results are shared with the submitter, and
also between the examining partners, who use the results to
improve their own systems. Users can also scan suspicious
domains, URLs, and search through the VirusTotal dataset.
Currently, VirusTotal inspects samples with over 70 antivirus
scanners and URL/domain blacklisting services.
Regarding files, VirusTotal not only indicates whether
a given AV solution has detected a submitted file as
malicious, but also displays each engine’s detection label
(e.g. Trojan.gen). Regarding domains and URLs, VirusTotal
can obtain data about the IPs the domains has resolved to,
Historical WHOIS Lookup, Historical SSL Certificates, and
the latest files that communicated with this domain when
opened or executed (Communicating Files). VirusTotal also
has URL scanners integrated within it. Most can discriminate
betweentypes ofmalicious sites(e.g.malware sites,phishing
sites, suspicious sites) for some of the submitted sites.
VirusTotal offers numerous ways to submit files and
domains for inspection by the products integrated in
it, including the primary public web interface, desktop
45246 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
uploaders, browser extensions, and a programmatic API.
In this study we used the HTTP-based public API to monitor
for suspicious files and domains in VirusTotal.
1) AVClass
To parse the results of the VirusTotal Anti-Virus (AV)
engines, we used the AVClass tool [49], [50], a malware
labeling tool. AVClass takes the AV labels as input for a large
number of malware samples (e.g., VirusTotal JSON reports)
and outputs the most likely family name for each sample that
it can extract from the AV labels.
III. PROBLEM STATEMENT
WeconsiderasetD , {d 1 ,d 2 ,...,d N D }containingN D mali-
cious domains, a set F , {F 1 ,F 2 ,...,F N F } containing N F
malwarefamiliesandasetB , {B 1 ,B 2 ,...,B N B }containing
N B malware campaigns where N B ≤ N F and N B ≤ N D . Each
domain (say d j ∈ D) relates to a single malware campaign
(say B i ∈ B). Typically, in real-world scenarios, a large
number of domains are involved in each campaign attack.
Each campaign B i follows distribution f i over the malware
family set F. Thus, we say that domain d j relates to malware
campaign B i if the set of malwares that communicates with
domain d j follows distribution f i .
A malware family contains variants or different instances
of a specific malware. For example, Locky is a ransomware
malware released in 2016. Since then several variants found
in the wild contain minor changes in the way the malware
operates. Some of these variants are still operating. All these
variants are categorized as a part of the Locky malware fam-
ily. A malware campaign is assembled from various malware
families. The distribution of these malware families distin-
guishes each campaign from another.
Next, we denote the domain seed S i as the set of domains
related to malware campaign B i . As in [20], we are interested
in expanding the domain seeds to find new domains which
are related to malware campaigns. This is done by expand-
ing each domain in the seed to other candidate domains.
This involves extracting all the domains resolved to this IP,
as described below. Let
ˆ
D d j be a set of candidate domains
for domain d j ∈ S i , and let
ˆ
D S i ,
n
ˆ
D d j ,d j ∈ S i
o
be the set
of all candidate domains for domains in S i . From the set of
candidate domains, we are interested in judiciously selecting
a subset Y S i ⊆
ˆ
D S i of domains to expand the seed S i with
sufficient reliability. The expanded set of domains is defined
by:
E i , S i ∪ Y S i , (1)
and we define the expansion ratio of seed S i by:
η i ,
|E i |
|S i |
. (2)
Next, we define the well-known detection measures that
are used in most of the cyber-security literature. Let TP i ,
FN i , FP i and TN i denote the number of True Positive (i.e.,
when a malware campaign domain is classified as related to
this specific malware campaign), False Negative (i.e., when a
malware campaign domain is classified as unrelated to this
specific malware ), False Positive (i.e., when an unrelated
domain to the observed malware campaign is classified as
related) and True Negative (i.e., when an unrelated domain
to the observed malware campaign is classified as unrelated)
binary classification results for S i , respectively. Let
P i =
TP i
TP i + FP i
(3)
denote the Precision score, and let
R i =
TP i
TP i + FN i
(4)
denote the Recall score for S i .
Since we are interested in categorizing a large number
of malicious domains to malware campaigns, these marked
domains will eventually be blocked, or assigned to SOC
analysts to investigate and act on each case. As a result, our
systemshouldachieveahighPrecisionscore,sodomainsthat
are benign or unrelated to the observed malicious campaign
are not blocked unintentionally or a cyber-security investiga-
tion conducted in vain. At the same time, we are interested
in achieving a Recall score which is not too small (typically,
greater than 0.3), to categorize a sufficiently large number
of malicious domains to a malware campaign. This allows
SOCanalyststobettercharacterizeandbuildefficientmodels
for the malware campaign for cyber security research and
operations.
The objective is thus to develop an algorithm that maxi-
mizes the average expansion ratio over the seeds, under the
target reliability constraints of P i ≥ ρ 1 and R i ≥ ρ 2 for
all S i . In the experiments, we set typical values of the target
Precision score to ρ 1 ≈ 0.8 − 0.9 and the target Recall score
to ρ 2 ≈ 0.3.
IV. THE IDENTIFICATION OF MALICIOUS DOMAIN
CAMPAIGNS (IMDoC) ALGORITHM
In this section we present IMDoC algorithm to meet
the objective described above. The algorithm is illustrated
in Fig. 2, and the pseudocode is given in Algorithm 1.
IMDoC is divided into 3 main stages: Train, Expand, and
Predict. In the Train stage, IMDoC first acquires the ground
truth. Then, it constructs the feature vector accordingly using
associated files. Finally, it clusters the domains based on
the constructed feature vectors. Next, in the Expand stage,
IMDoC expands each cluster by its resolved IPs, and obtains
new samples which are loosely connected to the observed
malicious domains. Finally, in the Predict stage, IMDoC
uses two different methods to decide whether the expanded
domains are part of the observed malicious campaign or not.
Each of these stages plays an important role in the algorithm
as explained in detail next.
A. THE TRAIN STAGE
In the training stage, IMDoC operates on a set of given mali-
ciousdomainsandextractsthefeaturevectorforeachdomain
VOLUME 9, 2021 45247
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 2. The architecture of IMDoC algorithm.
Algorithm 1 IMDoC Algorithm
1: D ← N D malicious domains.
2: for d j ∈ D do
3: C j ← CommunicatingFiles(d j )
4: for c i ∈ C j do
5: l ← AVClass(c i )
6: V d j (l) + +
7: end for
8: end for
9: S ← Clustering(V)
10: for S i ∈ S do
11: T ← S i
12: while T 6= ∅ do
13: for d j ∈ T do
14: IP d j ← ResolvedIPs(d j )
15:
ˆ
D d j ← ResolvedDomains(IP d j )
16: Y d j ← Predict( ˆ D d j )
17: for y ∈ Y d j do
18: if label(y) == i then
19: T.append(y)
20: end if
21: end for
22: T.remove(d j )
23: end for
24: end while
25: end for
based solely on its communicating files. Then, IMDoC clus-
tersthedomainsbasedontheconstructedfeaturevectors.The
goal of this stage is to build a ground truth for each malicious
campaign, consisting of the domains that are related to it,
based on their communicating files. Thus, only malicious
domains are considered in this stage.
1) OBTAINING THE DATA
IMDoC starts by getting a set of domains D containing
N D malicious domains. These domains are suspected of
malicious activity, identified by either a heuristic automated
method or manually, by a security analyst. This domain seed
can contain domains that are related to different malware
campaigns.
2) CONSTRUCTING THE FEATURE VECTOR
Let C j ,
n
c 1 ,c 2 ,...,c N C j
o
be the set of communicating
files for domain d j ∈ D, with cardinality N C j . Next, IMDoC
extracts the set C j for each domain d j ∈ D using VirusTotal
API.Whenadomainis searchedinVirusTotal,agreatdealof
information can relate it to a malicious activity. IMDoC uses
the communicating files to relate each domain to a specific
malware campaign.
For each file, the SHA-256 file hash is provided. When
a file hash is searched in VirusTotal, the results of all
72 Antivirus products collaborating with VirusTotal are
shown. Each AV product has a different way to tag the result
of the malicious entity, and there are different tags for the
same file. These tags can point to the same malware fam-
ily or variants with different descriptions, and can provide
information about different types of malware families for the
same file, as each AV product operates differently. For each
domain d j ∈ D, IMDoC uses the AVClass tool to obtain the
resulting malware family F k ∈ F from these tags for each
communicating file c i ∈ C j . Then, it generates a feature
vector V d j of size N F for each domain d j , where each entry
contains the frequency of the malware families. The overall
processoffeaturevectorconstructionisillustratedinfigure3.
It is worth noting that the date of the communicating files
is used during file extraction. In our environment, VirusTo-
tal provides the date when the malicious file was scanned
(i.e. executed) and communicated with the observed domain.
In the experiments, we extracted the communicating files
for each domain for a period corresponding to the previous
2 years to remain up to date on malicious activities in case
this domain was used in other malicious activities in the
past. This was done because malicious campaign domains
can operate for periods ranging from several days to years,
especially when not identified. When operating in different
network environments where another data source is available
45248 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 3. An illustration of the construction of the feature vector.
for the communicating files (e.g. an AV vendor), it is possible
to redirect any communication from the malicious files to a
controlled server (e.g. using DNS configuration in a sandbox
environment), and to save the exact communication time.
Thesedatacanbeusedlatertofilteronlyup-to-datemalicious
file communications.
3) CLUSTERING
IMDoC uses these feature vectors to cluster malicious
domains, so that domains with similar histograms of com-
municating file malware families reside in the same cluster.
In this study, we used two clustering algorithms on the fea-
ture vectors: K-Means and DBSCAN. We chose these two
popularclusteringalgorithmsbecausetheybothrepresentdif-
ferent approaches when it comes to clustering. Specifically,
DBSCAN uses density-based clustering, while K-Means is
based on a distance metric from a centroid. Generally, one
approach can be superior to the other in different scenarios.
Note that in our experiments, we used DBSCAN with
an epsilon of 0.5 (which is the maximum distance between
two samples for one to be considered in the neighborhood
of the other) and a minimum threshold of 40 samples in a
neighborhood for a sample to be considered a core point.
The distance metric was the standard Euclidean distance.
In K-Means, we noted 9 clusters, which represented the num-
ber of malware campaigns in our experiments. Furthermore,
we have set the number of times the K-Means algorithm
runs with different centroid seeds to 50. Both algorithmic
implementations were taken from the scikit-learn Python
framework [51].
As a result of this stage, IMDoC obtains a set of clusters,
S ,
? S
1 ,S 2 ,...,S N B
? ,whereeachclusterS
i (i.e.,thedomain
seed) contains malicious domains from the same malware
campaignwhichisassociatedwithsimilarbehaviorofthetag
histogram of their communicating files.
B. THE EXPAND STAGE
Next, IMDoC performs the Expand stage, as illustrated
in Fig. 4. Specifically, for each domain d j ∈ S, IMDoC
utilizes the real network data to extract the set IP d j that
contains all the IPs resolved to this domain, for the time
period in question. Next, for each IP in IP d j IMDoC extracts
all the domains resolved to this IP. Finally, for each seed
S i , for each domain d j ∈ S i , a set
ˆ
D d j that contains all the
domainsresolvedtotheseIPsisobtained.Then,theset ˆ D S i =
n
ˆ
D d j ,d j ∈ S i
o
represents the set of all candidate domains for
domains in S i (i.e., each domain in
ˆ
D S i is a candidate to be
an expanded domain of seed S i ). This set of new domains is
derived from the real network data and contains domains that
may be related to one of the malicious campaigns.
Quad9 is a DNS recursive resolver and therefore its main
role is to answer the client queries with the appropriate
answers from the necessary authoritative name server. When
FIGURE 4. An illustration of the IP-based exanpsion stage.
VOLUME 9, 2021 45249
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
such an answer is received, specifically for the case of an ‘A’
or ‘AAAA’ DNS record, the Quad9 servers operate a passive
DNS inspection which stores the requested domain and also
the corresponding IP address answered by the authoritative
name server to the requested domain. As a result, Quad9, and
specifically the UDR dataset, stores pairs of domain name
to IP address, derived from the authoritative answers of ‘A’
and ‘AAAA’ DNS records for all the clients’yy requests.
It is important to emphasize that the records stored in this
dataset are only from authoritative DNS servers’ answers
and therefore can be trusted in security analysis. In order to
find the domain names mapped to a given IP address, which
will be used in the expansion phase, our system goes over
the aforementioned pairs of domain name to IP address and
stores all the domain names that were resolved to the given IP
address (i.e., the domain name that resides in a pair with the
given IP address). This way we can obtain the domain names
that were resolved to the given IP address and then expand
our method to these domain names. Since we rely only on the
clients’ requests, it is possible that there are domain names
that are mapped to a specific IP address but were not queried
by the Quad9 clients and therefore would not appear in the
dataset. However, since Quad9 deals with heavy traffic, our
method still achieves sufficient and trusted data to continue
the expansion process. In our system, we do not use reverse
DNS records of IP addresses (i.e., PTR records). As a source
ofdata,ourwayofmappingIPaddressestoobservedresolved
domain names is more reliable and trusted than reverse DNS
queries since those are configured by the owner of the IP
address and may return any response, which may be false or
not up to date responses [52]. In our implementation, we rely
onlyonactualobservedresolutionsofIPaddressestodomain
namesandhencethereverseofthismappingismoreaccurate
than the reverse DNS protocol.
Another interesting approach to expanding each seed of
malicious domains is by querying the dataset or threat intelli-
gence service (i.e. VirusTotal) for the contacted domains for
each of the communicating files. This query can derive new
domains in the expansion process that may be malicious and
need to be checked. We did not use the communicating files
for the expansion stage in our experiments to avoid bias in
the next stage toward domains that reside solely in VirusTotal
and did not reside in our real-data environment (i.e. Quad 9),
since these domains may already be known to be malicious
and our goal is to expand our seed of known domains to
new undiscovered malicious domains. This allowed us to
better measure our proposed system on a real data network
environment.
C. THE PREDICT STAGE
Finally, in the Predict stage, IMDoC classifies each expanded
domain and relates it to one of the clusters. As a result
of the Predict stage, IMDoC obtains a label for each pre-
dicted domain, and uses these prediction labels to determine
whichmaliciouscampaign(i.e.cluster)thisdomainrelatesto.
When new domains are predicted to be part of the malicious
campaign, IMDoC creates a set of these domains, T, and
expands them as done for the seed domains. This process
cancontinuewhenevertherearemoredomainstoexpandand
predict, i.e. when T is not empty. When a domain is predicted
to be related to one of the malicious campaigns (i.e. cluster),
it is added to this malicious campaign domain set so that
the implemented prediction methods in IMDoC will consider
it in the upcoming decisions on new domains. The Predict
stage is divided into two different approaches, depending on
whether the domain has associated communicating files or
not, as detailed next.
1) COMMUNICATING FILES-BASED PREDICTION
Whenassociatedfilesexistforthecandidatedomain,IMDoC
constructs the feature vector of a domain as same as done
in the Train stage. This is based on the frequency of the
communicating malicious files’ malware families with the
observed domain. After constructing this feature vector, two
approaches can be taken to predict the class of expanded
domains. The first is to use the cluster centers, and assess
the distance from them in the feature space. The closest
cluster center (that exceeds a predefined threshold) becomes
the cluster the sample will reside in. This prediction method
coincides with the K-Means algorithm. The second is to
train a One Class Classifier for each cluster, and create an
ensemble method to choose which of the clusters fits the
best, or classifies this point as a noise point. This method
may be used with the clusters obtained from the DBSCAN
algorithm. Generally, one approach can be superior to the
other in different scenarios.
2) PREDICTION WITHOUT COMMUNICATING FILES
In the case, where associated files do not exist for the can-
didate domain, IMDoC uses a prediction method based on
DNS data, as presented in Algorithm 2 and explained next.
For each seed S i , for each candidate for the expanded domain
ˆ
d r ∈
ˆ
D S i , IMDoC identifies the last IP change (UDR record)
Algorithm 2 Prediction Using the Correlation From Time of
IP Change Event Used in IMDoC Algorithm
1: Y S i ← ∅
2: for ˆ d r ∈
ˆ
D S i do
3: t c ← TimeSeriesLastIPChange( ˆ d r )
4: for d j ∈ S i do
5: t s ← TimeSeriesLastIPChange(d j )
6: C c,s ← SpearmanCorrelation(t c ,t s )
7: if C c,s ≥ Thresh s then
8: Count( ˆ d r ) + +
9: end if
10: end for
11: if Count( ˆ d r ) ≥ Thresh c then
12: Y S i .append( ˆ d r )
13: end if
14: end for
45250 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
day that was observed, and constructs a time-frame, t c , of one
week starting from that day. This time-frame includes the
number of requests observed in the DSURF data for each
day in this time-frame. Next, IMDoC iterates each of the seed
domains d j ∈ S i , and creates the same time-frame t s from the
last IP change of the current observed seed domain. When
these two time-frames of one week are available, IMDoC
calculates a Spearman’s rank correlation coefficient between
the candidate domain and the current seed domain, C c,s .
The Spearman’s rank correlation coefficient is a nonpara-
metric measure of rank correlation that measures monotonic
relationships (whether linear or not) between two variables.
It has a value in the range [−1,+1], where a correlation
value of +1 is achieved when the two observed variables
have a similar rank and a correlation value of −1 indicates
that the observations have a dissimilar rank between the two
variables. Let a i , b i , i = 1,...,n, be a pair of variables with
n observations. The Spearman’s rank correlation coefficient
is defined by:
r S = 1 −
6
P n
i=1 d 2 i
n(n 2 − 1)
, (5)
where d i = rg(a i ) − rg(b i ), and rg(·) is the observation
rank [53]. The reason we chose this type of correlation over
the standard Pearson coefficient correlation is because the
Pearson coefficient correlation measures linear correlations
betweenvariablesandassumesthevariablesarenormallydis-
tributed. However, our observed variables may have different
characteristics from those noted, and can still be considered
correlated.
If the Spearman’s rank correlation coefficient value is
above a predetermined threshold (called the correlation
threshold and denoted as Thresh s ), IMDoC increments a
counter of the candidate domain, Count( ˆ d r ). When IMDoC
has calculated the correlation between the candidate domain
and all the seed domains, it observes the counter value for the
candidate domain. If this counter is above a predetermined
threshold (called the occurrence threshold and denoted by
Thresh c ), IMDoC considers this domain to be related to the
malware campaign, as represented by the seed domains, and
appends this domain to the set of predicted domains, Y S i .
The intuition for this method is based on analyzing com-
mon behaviors of malware campaigns. Domains from the
same malware campaign are more likely to be registered to
a new IP in the same time period. The IP change event repre-
sents the beginning of the specified domain in the observed
malware campaign operations. Therefore, the traffic since
this IP change event should fit the same rate pattern. Fig. 5
illustrates this behavior, and presents a histogram of the
queries observed for 5 domains from the Bayrob malware
campaign during the week after an IP change event occurred.
Practically, the method is split into 2 phases of training and
classification. In the first phase, we calculate the time-frames
since the last IP change of all seed domains and store them
in a seed time-frame database. The classification phase cor-
relates each given suspicious domain with all the domains in
FIGURE 5. An example of query patterns since the IP change of 5
domains from the Bayrob campaign.
FIGURE 6. An illustration of the training phase of the DNS-based method.
the seed. The training phase is presented in Fig. 6 and the
classification phase is presented in Fig. 7.
V. EVALUATION AND EXPERIMENTAL RESULTS
Weimplementedextensiveexperimentsinarealworkingpro-
duction environment to evaluate the performance of IMDoC
algorithm. The experiments conducted in a Quad9 DNS envi-
ronment consisted of DNS data derived from Quad9 Recur-
sive resolvers in the form of UDR and DSURF datasets,
as discussed in Subsection II-A. In the first experiment,
the initial data were a list of known malicious domains and
their related malware campaigns (i.e. their labels). The pur-
poseofthisexperimentwastoevaluatetheclusteringmethod,
where the feature vector for each domain was the histograms
of the domain communicating files’ malware families. In this
experiment,themaliciousdomainsweredividedintoclusters,
where each cluster represented a different malware campaign
and the results were verified against the given labels of the
domains in the different clusters.
In the next two experiments, our purpose was to evalu-
ate the expansion and prediction methods used in IMDoC
algorithm. In both experiments, one of the clusters was cho-
sen as a representative example. The aim of these experi-
ments was to identify new domains which did not appear
in the given malicious domain list, but were connected to
the malware campaign represented by the chosen cluster.
Both experiments use resolved IPs to expand the chosen
cluster of domains into new domains related to this cluster
VOLUME 9, 2021 45251
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 7. An illustration of the classification phase of DNS-based method.
(i.e. these two domains resolved to the same IP address
at some point in time). The main difference between these
phases was the method in IMDoC algorithm they were
designedtoevaluate.Thefirstfocusedonusingthecommuni-
cating files of each suspected domain together with machine
learning methods to decide whether this domain matched the
cluster characteristics, whereas the second focused on using
patterns of DNS requests of each suspected domain together
with statistical methods to determine whether this domain
matched the observed cluster. The methods also operated on
data with different characteristics. For the first, the domains
had observed communicating files, whereas in the second
the domains had suitable DNS data (i.e. UDR and DSURF
available data).
A. EVALUATION BY COMMUNICATING FILES-BASED
CLUSTERING
In this experiment, we manually selected 1846 domains from
9 different malware campaigns: Bayrob, Symmi, Fobber,
Virlock, Dircrypt, Locky, Tinba, Explosive, and Cryptowall,
as shown in Table 1.
TABLE 1. Number of malicious domains in each campaign.
The data were collected using threat intelligence sites pro-
viding malicious domains feeds, such as: OSINT Feeds -
Bambenek Consulting [42], Netlab OpenData Project [43],
AlienVault - Open Threat Exchange [44]. We collected
enoughsamplesforeachmalwarecampaign(morethan50)to
establish a robust notion of the domains operating within the
context of each malware campaign. Some of the domains did
not have DNS information in the UDR dataset or in Virus-
Total, but all the selected domains did have malicious files
FIGURE 8. The distribution of malware families for the Bayrob cluster.
communicating with them, which were extracted from Virus-
Total. As explained when presenting Algorithm 1, the com-
municating files for each of the inspected domains were
extracted using VirusTotal API and the AVClass tool was run
on each file to get the file’s associated malware family from
the VirusTotal AV engines. When all the files had an associ-
ated family, IMDoC algorithm constructed a malware family
distributionforeachdomainbasedontheassociatedmalware
families for each domain’s communicating malicious files.
After going over all the given malicious domains, IMDoC
algorithm clustered them based on the malware family dis-
tribution of each domain (the feature vectors, as explained
above). As a result, each cluster included malicious domains
with a similar malware family distribution. For example,
Fig. 8 shows the average malware family distribution for the
cluster related to the Bayrob malware campaign, where each
color represents a different malware family.
Importantly, in this experiment only malicious domains
have been considered since our system is expected to receive
a feed of malicious domains, where these domains are uncat-
egorized by malicious campaigns. IMDoC clusters these
45252 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 9. A comparison of real labels and clustering results.
domains based on their communicating files, which results
in several seeds for different malicious campaigns. In this
step, benign domains are irrelevant because each cluster con-
tains only malicious domains that are a part of a certain
malicious campaign. Therefore, in this experiment we only
used malicious domains to evaluate the clustering method
that will differentiate between domains that relate to different
malicious campaigns. This is considered our ground truth for
this model.
We evaluated two clustering algorithms in this experiment:
K-Means and DBSCAN, as discussed in Subsection IV-A3.
Bothimplementationswereusedfromthescikit-learnPython
framework [51]. The input provided to these algorithms was
the feature vectors mentioned above.
To measure the performance of the algorithms against
the real labels, we used several metrics: (i) Homogeneity:
each cluster only contained members of a certain class. The
value could be between 0 and 1, where 1 stands for perfect
homogeneous labeling; (ii) Completeness: all members of a
certain class were assigned to the same cluster. The value
couldbebetween0and1,where1standsforperfectcomplete
labeling; (iii) V-measure: the harmonic mean between the
homogeneity score and the completeness score ranging from
0 to 1, where 1 stands for perfect clustering in terms of
both homogeneity and completeness; (iv) Silhouette Coef-
ficient: a measure of how similar an object is to its own
cluster (cohesion) as compared to other clusters (separation).
The best value is +1 and the worst value is −1. This mea-
sures how well a clustering method performs. A score of +1
means that the clusters are well apart from each other and
can be easily distinguished. The Silhouette Coefficient can
be written as:
x−y
max(x,y) , where x is the average inter-cluster
distance (i.e. the average distance between all clusters), and y
is the intra-cluster distance (i.e. the average distance between
each point within a cluster). Achieving high values for the
metrics presented above indicates strong performance for an
algorithm. For DBSCAN we set an epsilon of 0.5 (which is
the maximum distance between two samples for one to be
considered in the neighborhood of the other), and a minimum
threshold of 40 samples in a neighborhood for which the
sampleisconsideredacorepoint.Thedistancemetricwasthe
standard Euclidean distance. For K-Means, we noted 9 clus-
ters, the same as the number of selected malware campaigns.
We set the number of times the K-Means algorithm ran with
different centroid seeds to 50. These parameters yielded the
best results for the above metrics.
The results of the evaluation metrics present strong per-
formance for the suggested methods, as shown in Table 2.
Figure 9 depicts the results of the clustering algorithms and
TABLE 2. Results for the suggested clustering algorithms.
VOLUME 9, 2021 45253
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 10. The confusion matrices of the clustering algorithms.
the comparison of the real labels to the clustering labels
provided by both methods. We used T-distributed Stochas-
tic Neighbor Embedding (T-SNE) for visualization by non-
linear dimensionality reduction, which enables embedding
high-dimensional data for visualization in a low-dimensional
space of two dimensions.
Furthermore, we evaluated the performance of the cluster-
ing algorithms as a multi-class classification problem, where
each class relates to a different malware campaign. The con-
fusion matrices presented in Fig. 10(b) show that for the
K-Meansclusteringalgorithm,allthesampleswereclassified
correctly except 5 from the Explosive malware campaign and
5fromtheCryptowallmalwarecampaignthatwereclassified
as belonging to the Dircrypt malware campaign. Fig. 10(a)
indicates that for the DBSCAN clustering algorithm, all sam-
ples were classified correctly except 16 from the Cryptowall
malware campaign that were classified as noise; i.e., not
compatible with any existing cluster.
B. COMMUNICATING FILES-BASED PREDICTION
METHODS
Inthesecondexperiment,weevaluatedthepredictionmethod
based on the domain’s communicating files. In this exper-
iment, IMDoC algorithm was used to expand one of the
clusters to find more malicious domains related to the same
malware campaign. We chose the cluster that contained the
Bayrob malware domains. Bayrob is a family of Trojans
that target the Windows platform. They can download and
launch additional modules from a C&C server. They can
also function as a proxy server. The malware is used to
send spam messages and steal user data. The family was
detected in 01/26/2017 and is still operating today [54]. Note
that the Bayrob malware uses DGA to generate the mali-
cious domains, which has been reverse engineered and fully
understood [55]. This means an exact answer can be given
when a domain is observed to be generated by this DGA.
In this experiment we used DGArchive [45], a site that
provides a convenient API to check whether a domain is
part of one of the DGAs of the malwares that reside in the
DGArchive database.
To expand this cluster, we first chose the period of time to
operate. Then, IMDoC algorithm iterated over the domains
contained in this cluster, extracted the IPs whose domains
were resolved in this period of time (there could be more
than one IP) and performed a reverse search over these IPs
to find the domains resolved to them in the defined period
of time. In this experiment, IMDoC algorithm used the pas-
sive DNS data in VirusTotal to acquire the data needed to
determine which domain name resolved to which IP address.
In this experiment, for the expansion we chose the time
period between 01/01/2018 and 01/06/2020. The 107 seed
domains related to the Bayrob malware were expanded using
the resolved IPs as stated above. This expansion process
yielded 94,942 expanded domains. Since the Bayrob DGA
only generates domains with a ‘‘net’’ TLD, we filtered the
result by the ‘‘net’’ TLD, and were left with 8,594 expanded
domains. Of these expanded domains, 1,335 were verified by
the DGArchive to be part of the Bayrob DGA. It is worth
noting that the 94,942 expanded domains did not result from
only 1 expansion process, but from several iterations of this
process over domains that were predicted to be related to this
malicious campaign. It used the prediction method described
below.
The expansion process yielded numerous domains which
were either benign or malicious but not related to the specific
malware campaign. Therefore, to find the domains which
were related to the observed malware campaign, for each
of the new domains derived from the expansion process,
45254 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 3. IMDoC prediction results for clustering by communicating files.
IMDoC algorithm extracted the communicating files of these
domains. Unlike the first experiment, it predicted which
domain was related to the observed cluster based on the
malicious file distribution to determine whether it matched
the malicious file distribution of the chosen cluster (Bayrob
malware campaign).
For the K-Means clustering method, this is fairly easy,
since we can see which of the classified cluster centers’ is
the closest in terms of Euclidean distance. If it is the cluster
related to the Bayrob malware campaign, IMDoC algorithm
tags this domain as related to this cluster and the expansion
process continues as described above on the next iteration of
the algorithm.
The procedure is more complex for the DBSCAN cluster-
ingmethod,becausethereisnobuilt-inpredictionmethodfor
thisdensity-basedclustering.Wecreatedaoneclassclassifier
(i.e.OneClassSVM)onthemaliciousfiledistributionsofthe
domains residing in the chosen cluster. When a new domain
derived from the expansion is tested, IMDoC algorithm aims
topredicttheclassofthisdomainwiththeoneclassclassifier,
and determines whether this domain relates to the malware
campaign based on the outcome. One can also expand this
functionality by running a one class classifier for each of the
clusters created by the DBSCAN algorithm and implement-
ing a voting method to determine the clusters to which the
new expanded domain should be assigned.
The results of both prediction methods are described
in Table 3. Using the K-Means prediction IMDoC algorithm
successfully expanded the seed of 107 malicious domains in
the Bayrob malware campaign cluster to 1,288 new domains
predicted to be part of the Bayrob malware campaign. Out of
these domains, 1,286 were verified to have been generated
from the Bayrob malware DGA by the DGArchive. This is a
significant expansion ratio of η ≈ 13. In terms of binary clas-
sification, this experiment resulted in 1,286 TP samples, 2 FP
samples, 7,257 TN samples and 49 FN samples. In addition
to the Precision and Recall scores defined in Subsection III,
we present the Accuracy score as follows:
A =
TP + TN
TP + FP + TN + FN
. (6)
IMDoC with K-Means prediction achieved an Accuracy
score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Open
University of Israel, in 2010. He is currently a
Security Researcher with the IBM’s Cyber Secu-
rity Center of Excellence, Beer-Sheva, specializ-
inginnetworkandsystemsecurity.Priortojoining
IBM, he served as a Security Software Engineer
for PMO.
AVIV RON received the B.Sc. degree in com-
puter science from Ben-Gurion University, Israel,
in 2007. He worked for five years as a Soft-
ware Engineer with Intel, four years as a Security
Researcher and Architect with Intel, and five years
as a Senior Security Researcher with IBM. He also
served for four years as an External Lecturer on
cyber security with Ben Gurion University. He has
17 patents. He is currently focused on detecting
cyber threats by applying artificial intelligence.
45258 VOLUME 9, 2021
Received February 20, 2021, accepted March 7, 2021, date of publication March 18, 2021, date of current version March 29, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3066957
IMDoC: Identification of Malicious Domain
Campaigns via DNS and Communicating Files
DAVID LAZAR
1 , KOBI COHEN 2 , (Senior Member, IEEE), ALON FREUND 3 ,
AVISHAY BARTIK
3 , AND AVIV RON 3
1 Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel
2 School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel
3 IBM Cyber Security Center of Excellence, Beer Sheva 8489325, Israel
Corresponding author: Kobi Cohen (yakovsec@bgu.ac.il)
This work was supported in part by the IBM Cyber Security Center of Excellence at Gav-Yam Negev, and in part by the Israeli National
Cyber Bureau via the Cyber Security Research Center at Ben-Gurion University of the Negev.
ABSTRACT Cyber attacks have become more sophisticated and frequent over the years. Detecting the
components operated during a cyber attack and relating them to a specific threat actor is one of the main
challenges facing cyber security systems. Reliable detection of malicious components and identification
of the threat actor is imperative to mitigate security issues by Security Operations Center (SOC) analysts.
The Domain Name System (DNS) plays a significant role in most cyber attacks observed nowadays in
that domains act as a Command and Control (C&C) in coordinated bot network attacks or impersonate
legitimate websites in phishing attacks. Thus, DNS analysis has become a popular tool for malicious domain
identification.InthiscollaborativeresearchassociatingBen-GurionUniversityandIBM,wedevelopanovel
algorithm to detect malicious domains and relate them to a specific malware campaign in a large-scale real-
data DNS traffic environment, dubbed Identification of Malicious Domain Campaigns (IMDoC) algorithm.
Its novelty resides in developing a framework that combines the existence of communicating files for
the observed domains and their DNS request patterns in a real production environment. The analysis
was conducted on real data from Quad9 (9.9.9.9) DNS recursive resolvers combined with malicious
communicating files extracted from VirusTotal, and confirms the strong performance of the algorithm on
a real large-scale data production environment.
INDEX TERMS Cyber security, domain name system (DNS), clustering methods, detection algorithms.
I. INTRODUCTION
The Domain Name System (DNS) is a fundamental com-
ponent of the functionality of the internet. DNS provides a
mapping between domain names and IP addresses, which is
a core service for applications on the internet. Since DNS
is ubiquitous across the internet, DNS services have been
abused in different ways to execute a range of attacks [1].
An attacker can exploit a set of domains to carry out complex
attacks, while targeting users and organizations through mal-
ware related campaigns such as phishing [2]–[4], pharming
[5], [6], and Distributed Denial of Service (DDoS) attacks
using a multitude of botnets [7], [8]. One notorious example
is the Dyn DDoS cyberattack by the Mirai botnet in 2016 [9].
The associate editor coordinating the review of this manuscript and
approving it for publication was Gautam Srivastava .
To respond to this malicious use of the DNS, domain
blacklists containing known malware domains [10] and IP
reputation information [11] have been developed by net-
work operators to detect DNS queries originating from
malware-infected machines and block their communications
withtheattackers.TocreatetheseblacklistsandIPreputation
information, malicious domains and IP addresses must be
identified to separate them from benign ones. This effort
is crucial since security vendors should not block benign
domains from their clients.
Once a malicious domain has been identified, it is imper-
ative to determine which threat actor or malware campaign
the domain is related to. This can shed light on the type of
malicious activity of the domain and its purpose. This kind
of information can allow Security Operations Center (SOC)
analyststobetterunderstandcybersecuritythreatsandhandle
them efficiently and reliably. The relationship of a given
45242
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
domain to a specific malicious activity can help security
researchers build effective models to mitigate security issues.
Moreover, it can help analysts and researchers to gain better
insights of an observed threat group and help in classifying
executables to a specific malware in addition to YARA rules
and other methods.
OneofthemostpopularwaysofanalyzingDNStrafficisto
use passive DNS (pDNS) data (see [12]–[15] and references
therein). The analysis is performed offline on a copy of live
DNS traffic to study past DNS traffic patterns to evaluate the
maliciousness of non-categorized domains. Offline calcula-
tions overcome the need to process a huge amount of data
in real-time. Recent studies have analyzed pDNS to isolate
malicious domains and IP addresses, and identify infected
machines [12]–[15]. However, developing robust methods to
relatemaliciousdomainstoamalwarecampaignhasnotbeen
addressed and is the main focus of this paper.
Relating a massive amount of unknown domains to a
malware campaign based solely on DNS traffic is a very
challengingtask.However,whencombiningDNStrafficwith
threat intelligence data, a robust method for this task can be
constructed. In this paper, our method utilizes the communi-
cating files of suspicious domains together with passive DNS
traffic to relate unknown domains to a malware campaign.
The communicating files were extracted using VirusTotal’s
file analysis database. The passive DNS traffic was derived
from a real production environment, namely, Quad9 DNS
servers.
A. MAIN RESULTS
This paper addresses the problem of expanding a seed
of known malicious domains related to the same mal-
ware campaign to categorize unknown domains as mali-
cious and related to this malware campaign. Related stud-
ies of malicious domain detection have relied mostly on
DNS patterns and characteristics or domain name analysis
to find evidence of a Domain Generation Algorithm (DGA)
[12]–[14], [16]–[19]. However, these methods are only
used to distinguish between benign and malicious domains.
In[20],theauthorsconsideredtheproblemofidentifyingnew
malicious domains related to an observed campaign, as con-
sidered in this paper. Their method was based on clustering
known malicious domains from the same campaign together
with uncategorized domains to find new malicious domains
related to the observed campaign. It achieved good perfor-
mance in detecting phishing attacks in which the domain
name has a specific structure (where the attacker tries to
mimic a domain name of a well-known website). However,
its performance degrades when facing general attacks when
the domain name is structure agnostic, such as general C&C
domains. In this paper we overcome this issue by developing
a novel robust method for detecting general attacks. It should
be noted that the system described here is not intended to
find zero-day attacks since these are beyond the scope of
this paper. These types of attacks are typically addressed
by anomaly detection algorithms trained on benign samples.
Below, we summarize our main contributions.
1) A NOVEL METHOD TO RELATE MALICIOUS DOMAINS TO
MALWARE CAMPAIGNS BASED ON COMMUNICATING FILES
We develop a novel method to determine the malware cam-
paign of a malicious domain based on its communicating
files. The novelty resides in the use of the communicating
files of each domain to categorize it to its malware campaign.
Our approach takes a set of malicious domains and clusters
them as a function of their malware family distributions
based on communicating files, without relying on their DNS
features at all. This allows the system to relate malicious
domains to malware campaigns with high reliability when
communicating files are available. This contrasts sharply
with most malicious domain identification methods that rely
heavily on DNS features.
2) A NOVEL METHOD TO DETECT UNCATEGORIZED
DOMAINS FROM A SPECIFIC MALWARE CAMPAIGN
BASED ON DNS DATA
We develop a novel method to identify uncategorized mali-
cious domains and relate them to an observed malware cam-
paign. This is done by using the time-based correlation of the
number of aggregated DNS requests per day between a set of
malicious domains from the same malware campaign and a
suspicious domain. Note that in [20], the method clustered a
set of domains based on DNS features for a fixed time frame
(a fixed week for all domains in the set in their experiments)
regardless of the IP change events of domains involved in the
clustering process. Unlike [20], we innovate by analyzing a
dynamic time-frame selection (a week in our experiments)
which starts from the last observed IP change event of each
pair of the known malicious domain and the new suspicious
domain involved in the time-based correlation. This method
allows for detection of new suspicious domains with high
reliability through its dynamic time correlation analysis.
3) ALGORITHM DEVELOPMENT
We develop an algorithm to identify new malicious domains
in the context of a malware campaign, dubbed Identification
of Malicious Domain Campaigns (IMDoC). The algorithm
processes communicating files data as well as DNS data
to identify malicious domains by utilizing the two methods
described above. IMDoC algorithm works as follows. The
algorithm is divided into 3 main stages: Train, Expand, and
Predict.AnillustrationofthealgorithmcanbefoundinFig.2
in Section IV. In the Train stage, the algorithm performs a
training phase, where known malicious domains are given.
In the training process, a feature vector is constructed using
the domains’ communicating files. Then, clustering algo-
rithmsareappliedtothedomainsbasedonthefeaturevectors.
Next, in the Expand stage, the algorithm expands each of
the clusters by their resolved IPs, and as a result obtains
new samples which are loosely connected to the observed
maliciousdomains.Finally,inthePredictstage,thealgorithm
VOLUME 9, 2021 45243
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
uses one of the two methods described above, depending on
whether communicating files are available or not, to decide
whether the new expanded domains (i.e., the candidates) are
a part of the observed malicious campaign or not.
4) EXTENSIVE PERFORMANCE EVALUATION USING REAL
DATA IN A REAL PRODUCTION ENVIRONMENT
Enterprises tend to be reluctant to share their data and
real-world security performance because of the legal risks of
violating privacy, or to avoid sharing information that could
benefittheircompetitors.Therefore,analyzingandvalidating
cyber security algorithms in real-world systems using up-to-
date real data is one of the main hurdles in academic cyber
security research. This collaboration between Ben-Gurion
University and IBM constitutes an important step forward.
We deployed the algorithm in a real working production
environment, and analyzed and validated its performance
using up-to-date data. Specifically, the performance evalua-
tion consisted of data from Quad9 (9.9.9.9), a free service
IBM launched with Packet Clearing House (PCH) and the
Global Cyber Alliance (GCA). Quad9 handles a massive
amount of DNS requests and responses daily at the recursive
resolver layer, and provides several datasets that originate
from these requests and responses. These datasets are filtered
fromalluser-datatoavoidviolationsofprivacy.Forexample,
one of the datasets we used in this paper is a stream of newly
observed DNS responses, dubbed the Unique DNS Record
(UDR), containing only the queried domain, the query type
and the response record. This stream of around 1 million
UDRrecordsperdaywascondensedfromtheQuad9systems
operatingin76countriesand128locations.Theexperimental
results based on this real-world environment were satisfying
and highly compatible across all tests, and significantly out-
performed existing methods.
B. RELATED WORK
Developing detection methods for cyber security can be
divided broadly into two main approaches: signature-based
detection [21]–[23] and anomaly-based detection [7], [15],
[24]–[27]. To identify malicious domains, detection methods
typically use DNS data, as considered in this paper. Next,
we discuss several aspects of DNS-based detection methods
that were investigated in related studies, including DNS data
collection, data enrichment, ground truth, and algorithmic
methods [16].
1) DNS DATA COLLECTION
The DNS infrastructure is distributed; hence, different loca-
tions can be considered to collect the DNS data. The most
common choice between those is the DNS resolver involve-
ment, since it is the only location that has access to the
clients’ DNS queries. One approach consists of collect-
ing the communication data between an end host (e.g. PC,
smartphone, server) and its DNS resolver (referred to as
the Host-Resolver) [13], [17]. The other collects the com-
munication data between two DNS servers (referred to
as DNS-DNS), one of which may be the DNS resolver
[12], [14]. The first location (Host-Resolver) can pro-
vide detailed information about clients’ DNS queries and
responses (e.g. IP addresses) which can create a better
behavioral pattern for the hosts, because their activity can be
tracked sequentially. In [13], the authors used a table of query
sourceIPaddressesforeachdomainnametocreateaDomain
Name Travel Graph (DNTG) which represents a sequence
of queries in a small time window. In [28], the authors
analyzed a dataset containing more than 26 billion DNS
request-response records collected from more than 600 glob-
ally distributed recursive DNS resolvers to gain insights into
the evolving nature of DNS traffic, and identify malicious
domains. Another advantage of Host-Resolver collection is
that any institute can deploy sensors on its network to col-
lect this kind of DNS data. However, this also can be a
disadvantage since the behavior of hosts can only be seen
within a single organization. The exception is a public DNS
server for recursive queries (e.g. Google Public DNS [29],
Quad9 DNS [30], Cisco OpenDNS [31], Cloudflare 1.1.1.1
DNS [32]). The data collected from these servers is more
diverse because they represent different types of clients and
there is a greater likelihood of catching suspicious behav-
iors related to different attacks. However, because of privacy
issues, public DNS vendors may omit most client details
saved in their datasets.
TheDNS-DNSdatacollectionsensorscollectqueriesfrom
different organizations. In cases where the data are collected
from TLD servers, they have the greatest visibility and can
yield unique insights to expose new malicious trends. How-
ever, the queries’ responses are not available at this level
since these only serve iterative queries. Collecting queries
from an Authoritative server solves this issue. However, due
to caching at the recursive resolver level, not all queries
will be visible to that server. The DNS-ADVP platform [7]
analyzes passive DNS records from an Authoritative DNS
server to identify DDoS (Distributed Denial of Service)
attacks against Top-Level domains. The Kopis system [12]
passively monitors DNS traffic at the upper levels of the
DNS hierarchy (Authoritative servers and TLDs) to detect
malware domains using the global visibility obtained by
monitoring network traffic at the upper DNS hierarchy with-
out relying on monitoring traffic from local recursive DNS
servers. Another distinction between the different DNS data
collection approaches can be made in terms of the method
used to collect the DNS data. One is to initiate queries to
a predetermined large collection of domains to obtain the
domain resolution responses [18]. The other is to collect the
requests and their responses initiated by clients passively [7],
[12]–[14], [20]. The first approach is known as active DNS
data collection, and the latter is called passive DNS data
collection. There are various problems associated with the
active DNS data collection approach. The first is that the
queries initiated by the collector itself do not reflect an actual
user usage pattern. Moreover, if a predetermined limited set
of hosts is queried, the data collected may be biased. On the
45244 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
other hand, active DNS data provides an easy way to collect
data without concerns over privacy issues. Passive DNS data
collection is the approach taken in the majority of studies
conducted in the field of DNS analysis as it better represents
the characteristics of real users and can be more helpful in
identifying trends and patterns in clients’ activity based on
their DNS requests and their corresponding responses.
In the system model considered in this paper, we col-
lected passive DNS data from Quad9, a public DNS recursive
resolver servers. Therefore, the data were collected at the
Host-Resolver level. Bear in mind that the application of
IMDoC is not limited to our evaluation environment and
datasets.ItcanbeappliedtodifferentDNSenvironmentswith
various data collection points (e.g ISP-level).
2) DATA ENRICHMENT
Except for pure DNS data (i.e. request and response), other
sources of information can be used to enrich the data used
in the DNS analysis. In [19], the authors used geo-location
data to determine hosting countries and cities as part of their
IP address analysis. This was used to determine whether an
IP address belonged to a country that is notorious for hosting
malicious domains and to depict the fact that malicious graph
components are often characterized by greater distances
betweencities/countriesinwhichtheirIPsarehosted.In[20],
the authors used the Autonomous System Number (ASN)
from the Border Gateway Protocol (BGP) information as one
of their clustering features. In [18], the authors used WHOIS
data to verify that an IP was public rather than dedicated in
case the Fully Qualified Domain Name (FQDN) belonged to
a hosting service Second Level Domain (SLD). In the system
model considered in this paper, the files communicated with
the observed domains are extracted to enrich the DNS data.
These files can be derived from threat intelligence sites or
from any security vendor report that relates malicious files to
domain names. In our evaluation environment, IMDoC used
VirusTotal as a data source for the communicating files.
3) GROUND TRUTH
Another consideration in a DNS analysis is determining
a high-quality ground truth, whether as a starting seed to
expand from using unsupervised learning methods, or for
training and validation sets using supervised learning meth-
ods. To do so, blacklists and threat intelligence sites can
provide a domains list related to malicious activity. Some
of these blacklists are category-related, such as: spam black-
lists (DNSBL [33]), or phishing blacklists (PhishTank [34],
OpenPhish [35]), whereas other blacklists provide a general
indication of maliciousness (IBM X-Force’s Threat Intel-
ligence database [36], VirusTotal [37], McAfee SiteAdiv-
sor [38], malwaredomainlist.com [39], malc0de.com [40],
DNS-BH [41]). In [13], the authors used a method in which
if one of the cluster members appeared on the blacklist,
the cluster containing the blacklisted domain was marked
as malicious. However, methods based on domain blacklists
are limited to known behaviors, since only known malicious
domains are included. Moreover, one of the problems of
learning from blacklists is that it is a conservative list which
includes only domains that have been confirmed as mali-
cious. However, there are many domains in malicious cam-
paigns that are actually used by malware without directly
contributing to its malicious activity (e.g., C&C commu-
nication, payload download, spam-relaying). Furthermore,
some malicious domains are not on the blacklist because a
specific variant of the malware was not researched or reverse
engineered. Another approach to achieve ground truth on
malicious behavior is to simulate attacks. In [7], the authors
created synthetic DDoS attacks over different time frames to
test their DDoS attack classifier.
In this paper we use popular threat intelligence sites
and domain name blacklists as our ground truth for mali-
cious domains, and specifically OSINT Feeds - Bambenek
Consulting [42], Netlab OpenData Project [43], and Alien-
Vault - Open Threat Exchange [44]. Furthermore, we used
DGArchive [45] to validate our predicted domains. This
ground truth fits our objective of expanding a seed of
known malicious domains that relates to a certain malware
campaign.
4) ALGORITHMIC METHODS
Different algorithmic methods via DNS analysis have been
suggested to identify malicious domains. In [13], the authors
constructed a graph from a batch of ordered queries in a cer-
tain timeslot and clustered the domains based on sequential
correlation. In [14], a single domain at a time was inspected
by constructing a domain graph which represented the cor-
relation among different domains. A path-based mechanism
was used to derive a malicious score for each domain. A dif-
ferent approach proposed in [46] calculated the reputation
score based on domain name lexical features.
Amorecommonapproachistousemachinelearningalgo-
rithms to classify domains as malicious. In [12], the authors
used supervised learning which takes a set of statistical fea-
ture vectors as input, which summarizes the query/response
behavior of each domain. In [47], the J48 decision tree
algorithm was used with a feature vector consisting of both
DNS related features and other network traffic features to
detect domains used for malware C&C servers. In [18],
an iterative semi-supervised random forest classifier was
constructed to separate dedicated and public IP addresses.
In [48], the authors proposed a deep neural networks to clas-
sify domain names as benign or malicious, as part of DGAs.
These methods, however, have not considered the problem
of identifying new malicious domains related to an observed
campaign, as considered in this paper. In [20], the authors
used unsupervised clustering to expand a seed of mali-
cious domains in order to identify new malicious domains.
However, as explained in Subsection I-A, the method is
not robust to general attacks, which is the main focus of
this paper.
VOLUME 9, 2021 45245
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
II. PRELIMINARIES
We start by presenting background knowledge on the
Quad9 DNS Architecture in Subsection II-A, which is the
environmentforthisstudy.WethendescribeVirusTotal(Sub-
section II-B) that was used to extract data about the files
associated with the observed malicious domains, and the
AVClass tool (Subsection II-B1) that was used to parse the
file labeling of VirusTotal’s AV engines.
A. THE Quad9 DNS ARCHITECTURE
The architecture in this paper is based on a real-world envi-
ronment in the form of Quad9, a free service that IBM
launched in collaboration with Packet Clearing House (PCH)
and the Global Cyber Alliance (GCA) to deliver greater
online privacy and security protection to consumers and busi-
nesses[30].Quad9providesastreamofnewlyobservedDNS
responses,oraUniqueDNSRecord(UDR)thatonlycontains
the response domain, query type, and response record. This
stream of roughly 1 million UDR records per day is con-
densedfromtheQuad9systemsoperatingin76countriesand
128 locations. Quad9 also offers aggregations of the request
counts for some domains. These data are called DSURF. Due
to the massive volume Quad9 DNS recursive resolvers deal
with, the aggregation is sampled for only a small percent-
age of the requests that flow through the Quad9 recursive
resolvers.
An illustration of Quad9 DNS architecture is presented
in Fig. 1. Each client sets the Quad9 DNS recursive
resolver address (9.9.9.9) to consume DNS services from
this provider. The Quad9 DNS recursive resolver queries
authoritative DNS servers upon DNS requests by its clients.
Generally, when a DNS client needs to find the IP address
FIGURE 1. An illustration of the Quad9 architecture.
of a host or service known by its FQDN, it queries its DNS
recursive resolver for the IP Address. The recursive resolver
first looks for the IP address in its cache. If it does not exist,
it starts a hierarchical recursive resolution process, which
begins with the root servers and ends at an authoritative name
server. Since the DNS system is hierarchical, the root node
contains the addresses of all Top Level Domain (TLD) name
servers, and the TLD name servers contain the addresses
of Second Level Domain (SLD) name servers. Therefore,
the recursive resolver first requests the root node, followed
by the next tree level, whose addresses are responded to
by current tree level, until an authoritative answer is found
whichyieldstheresponsetotherequestedquery.IftheFQDN
is invalid or non-existent in the tree, the recursive resolver
reports this information to the client.
In our architecture, cached DNS requests do not appear
in the UDR database since it only contains newly observed
DNS responses. Whenever a DNS request does not appear
in the recursive resolver cache and the resolver queries the
rest of the chain of servers within the DNS hierarchical
recursive resolution process, the request is recorded in the
UDR database. As for the DSURF database, the cached DNS
requests for a specific FQDN appear in the aggregation of the
requests. However, as stated above, only a small percentage
of these requests are aggregated.
InordertopreservetheprivacyofQuad9DNSclients,only
some of the details are saved for each request, including the
DNS request code, the queried FQDN, the response code,
Time To Live (TTL), and the resolved IP addresses. The
clients’ identification and characteristics do not appear in the
databases.
B. VirusTotal
VirusTotal [37] is a website that aggregates many
antivirus (AV) products and online scan engines to check
for malware and malicious activity. Upon submitting a file
or domain, basic results are shared with the submitter, and
also between the examining partners, who use the results to
improve their own systems. Users can also scan suspicious
domains, URLs, and search through the VirusTotal dataset.
Currently, VirusTotal inspects samples with over 70 antivirus
scanners and URL/domain blacklisting services.
Regarding files, VirusTotal not only indicates whether
a given AV solution has detected a submitted file as
malicious, but also displays each engine’s detection label
(e.g. Trojan.gen). Regarding domains and URLs, VirusTotal
can obtain data about the IPs the domains has resolved to,
Historical WHOIS Lookup, Historical SSL Certificates, and
the latest files that communicated with this domain when
opened or executed (Communicating Files). VirusTotal also
has URL scanners integrated within it. Most can discriminate
betweentypes ofmalicious sites(e.g.malware sites,phishing
sites, suspicious sites) for some of the submitted sites.
VirusTotal offers numerous ways to submit files and
domains for inspection by the products integrated in
it, including the primary public web interface, desktop
45246 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
uploaders, browser extensions, and a programmatic API.
In this study we used the HTTP-based public API to monitor
for suspicious files and domains in VirusTotal.
1) AVClass
To parse the results of the VirusTotal Anti-Virus (AV)
engines, we used the AVClass tool [49], [50], a malware
labeling tool. AVClass takes the AV labels as input for a large
number of malware samples (e.g., VirusTotal JSON reports)
and outputs the most likely family name for each sample that
it can extract from the AV labels.
III. PROBLEM STATEMENT
WeconsiderasetD , {d 1 ,d 2 ,...,d N D }containingN D mali-
cious domains, a set F , {F 1 ,F 2 ,...,F N F } containing N F
malwarefamiliesandasetB , {B 1 ,B 2 ,...,B N B }containing
N B malware campaigns where N B ≤ N F and N B ≤ N D . Each
domain (say d j ∈ D) relates to a single malware campaign
(say B i ∈ B). Typically, in real-world scenarios, a large
number of domains are involved in each campaign attack.
Each campaign B i follows distribution f i over the malware
family set F. Thus, we say that domain d j relates to malware
campaign B i if the set of malwares that communicates with
domain d j follows distribution f i .
A malware family contains variants or different instances
of a specific malware. For example, Locky is a ransomware
malware released in 2016. Since then several variants found
in the wild contain minor changes in the way the malware
operates. Some of these variants are still operating. All these
variants are categorized as a part of the Locky malware fam-
ily. A malware campaign is assembled from various malware
families. The distribution of these malware families distin-
guishes each campaign from another.
Next, we denote the domain seed S i as the set of domains
related to malware campaign B i . As in [20], we are interested
in expanding the domain seeds to find new domains which
are related to malware campaigns. This is done by expand-
ing each domain in the seed to other candidate domains.
This involves extracting all the domains resolved to this IP,
as described below. Let
ˆ
D d j be a set of candidate domains
for domain d j ∈ S i , and let
ˆ
D S i ,
n
ˆ
D d j ,d j ∈ S i
o
be the set
of all candidate domains for domains in S i . From the set of
candidate domains, we are interested in judiciously selecting
a subset Y S i ⊆
ˆ
D S i of domains to expand the seed S i with
sufficient reliability. The expanded set of domains is defined
by:
E i , S i ∪ Y S i , (1)
and we define the expansion ratio of seed S i by:
η i ,
|E i |
|S i |
. (2)
Next, we define the well-known detection measures that
are used in most of the cyber-security literature. Let TP i ,
FN i , FP i and TN i denote the number of True Positive (i.e.,
when a malware campaign domain is classified as related to
this specific malware campaign), False Negative (i.e., when a
malware campaign domain is classified as unrelated to this
specific malware ), False Positive (i.e., when an unrelated
domain to the observed malware campaign is classified as
related) and True Negative (i.e., when an unrelated domain
to the observed malware campaign is classified as unrelated)
binary classification results for S i , respectively. Let
P i =
TP i
TP i + FP i
(3)
denote the Precision score, and let
R i =
TP i
TP i + FN i
(4)
denote the Recall score for S i .
Since we are interested in categorizing a large number
of malicious domains to malware campaigns, these marked
domains will eventually be blocked, or assigned to SOC
analysts to investigate and act on each case. As a result, our
systemshouldachieveahighPrecisionscore,sodomainsthat
are benign or unrelated to the observed malicious campaign
are not blocked unintentionally or a cyber-security investiga-
tion conducted in vain. At the same time, we are interested
in achieving a Recall score which is not too small (typically,
greater than 0.3), to categorize a sufficiently large number
of malicious domains to a malware campaign. This allows
SOCanalyststobettercharacterizeandbuildefficientmodels
for the malware campaign for cyber security research and
operations.
The objective is thus to develop an algorithm that maxi-
mizes the average expansion ratio over the seeds, under the
target reliability constraints of P i ≥ ρ 1 and R i ≥ ρ 2 for
all S i . In the experiments, we set typical values of the target
Precision score to ρ 1 ≈ 0.8 − 0.9 and the target Recall score
to ρ 2 ≈ 0.3.
IV. THE IDENTIFICATION OF MALICIOUS DOMAIN
CAMPAIGNS (IMDoC) ALGORITHM
In this section we present IMDoC algorithm to meet
the objective described above. The algorithm is illustrated
in Fig. 2, and the pseudocode is given in Algorithm 1.
IMDoC is divided into 3 main stages: Train, Expand, and
Predict. In the Train stage, IMDoC first acquires the ground
truth. Then, it constructs the feature vector accordingly using
associated files. Finally, it clusters the domains based on
the constructed feature vectors. Next, in the Expand stage,
IMDoC expands each cluster by its resolved IPs, and obtains
new samples which are loosely connected to the observed
malicious domains. Finally, in the Predict stage, IMDoC
uses two different methods to decide whether the expanded
domains are part of the observed malicious campaign or not.
Each of these stages plays an important role in the algorithm
as explained in detail next.
A. THE TRAIN STAGE
In the training stage, IMDoC operates on a set of given mali-
ciousdomainsandextractsthefeaturevectorforeachdomain
VOLUME 9, 2021 45247
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 2. The architecture of IMDoC algorithm.
Algorithm 1 IMDoC Algorithm
1: D ← N D malicious domains.
2: for d j ∈ D do
3: C j ← CommunicatingFiles(d j )
4: for c i ∈ C j do
5: l ← AVClass(c i )
6: V d j (l) + +
7: end for
8: end for
9: S ← Clustering(V)
10: for S i ∈ S do
11: T ← S i
12: while T 6= ∅ do
13: for d j ∈ T do
14: IP d j ← ResolvedIPs(d j )
15:
ˆ
D d j ← ResolvedDomains(IP d j )
16: Y d j ← Predict( ˆ D d j )
17: for y ∈ Y d j do
18: if label(y) == i then
19: T.append(y)
20: end if
21: end for
22: T.remove(d j )
23: end for
24: end while
25: end for
based solely on its communicating files. Then, IMDoC clus-
tersthedomainsbasedontheconstructedfeaturevectors.The
goal of this stage is to build a ground truth for each malicious
campaign, consisting of the domains that are related to it,
based on their communicating files. Thus, only malicious
domains are considered in this stage.
1) OBTAINING THE DATA
IMDoC starts by getting a set of domains D containing
N D malicious domains. These domains are suspected of
malicious activity, identified by either a heuristic automated
method or manually, by a security analyst. This domain seed
can contain domains that are related to different malware
campaigns.
2) CONSTRUCTING THE FEATURE VECTOR
Let C j ,
n
c 1 ,c 2 ,...,c N C j
o
be the set of communicating
files for domain d j ∈ D, with cardinality N C j . Next, IMDoC
extracts the set C j for each domain d j ∈ D using VirusTotal
API.Whenadomainis searchedinVirusTotal,agreatdealof
information can relate it to a malicious activity. IMDoC uses
the communicating files to relate each domain to a specific
malware campaign.
For each file, the SHA-256 file hash is provided. When
a file hash is searched in VirusTotal, the results of all
72 Antivirus products collaborating with VirusTotal are
shown. Each AV product has a different way to tag the result
of the malicious entity, and there are different tags for the
same file. These tags can point to the same malware fam-
ily or variants with different descriptions, and can provide
information about different types of malware families for the
same file, as each AV product operates differently. For each
domain d j ∈ D, IMDoC uses the AVClass tool to obtain the
resulting malware family F k ∈ F from these tags for each
communicating file c i ∈ C j . Then, it generates a feature
vector V d j of size N F for each domain d j , where each entry
contains the frequency of the malware families. The overall
processoffeaturevectorconstructionisillustratedinfigure3.
It is worth noting that the date of the communicating files
is used during file extraction. In our environment, VirusTo-
tal provides the date when the malicious file was scanned
(i.e. executed) and communicated with the observed domain.
In the experiments, we extracted the communicating files
for each domain for a period corresponding to the previous
2 years to remain up to date on malicious activities in case
this domain was used in other malicious activities in the
past. This was done because malicious campaign domains
can operate for periods ranging from several days to years,
especially when not identified. When operating in different
network environments where another data source is available
45248 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 3. An illustration of the construction of the feature vector.
for the communicating files (e.g. an AV vendor), it is possible
to redirect any communication from the malicious files to a
controlled server (e.g. using DNS configuration in a sandbox
environment), and to save the exact communication time.
Thesedatacanbeusedlatertofilteronlyup-to-datemalicious
file communications.
3) CLUSTERING
IMDoC uses these feature vectors to cluster malicious
domains, so that domains with similar histograms of com-
municating file malware families reside in the same cluster.
In this study, we used two clustering algorithms on the fea-
ture vectors: K-Means and DBSCAN. We chose these two
popularclusteringalgorithmsbecausetheybothrepresentdif-
ferent approaches when it comes to clustering. Specifically,
DBSCAN uses density-based clustering, while K-Means is
based on a distance metric from a centroid. Generally, one
approach can be superior to the other in different scenarios.
Note that in our experiments, we used DBSCAN with
an epsilon of 0.5 (which is the maximum distance between
two samples for one to be considered in the neighborhood
of the other) and a minimum threshold of 40 samples in a
neighborhood for a sample to be considered a core point.
The distance metric was the standard Euclidean distance.
In K-Means, we noted 9 clusters, which represented the num-
ber of malware campaigns in our experiments. Furthermore,
we have set the number of times the K-Means algorithm
runs with different centroid seeds to 50. Both algorithmic
implementations were taken from the scikit-learn Python
framework [51].
As a result of this stage, IMDoC obtains a set of clusters,
S ,
? S
1 ,S 2 ,...,S N B
? ,whereeachclusterS
i (i.e.,thedomain
seed) contains malicious domains from the same malware
campaignwhichisassociatedwithsimilarbehaviorofthetag
histogram of their communicating files.
B. THE EXPAND STAGE
Next, IMDoC performs the Expand stage, as illustrated
in Fig. 4. Specifically, for each domain d j ∈ S, IMDoC
utilizes the real network data to extract the set IP d j that
contains all the IPs resolved to this domain, for the time
period in question. Next, for each IP in IP d j IMDoC extracts
all the domains resolved to this IP. Finally, for each seed
S i , for each domain d j ∈ S i , a set
ˆ
D d j that contains all the
domainsresolvedtotheseIPsisobtained.Then,theset ˆ D S i =
n
ˆ
D d j ,d j ∈ S i
o
represents the set of all candidate domains for
domains in S i (i.e., each domain in
ˆ
D S i is a candidate to be
an expanded domain of seed S i ). This set of new domains is
derived from the real network data and contains domains that
may be related to one of the malicious campaigns.
Quad9 is a DNS recursive resolver and therefore its main
role is to answer the client queries with the appropriate
answers from the necessary authoritative name server. When
FIGURE 4. An illustration of the IP-based exanpsion stage.
VOLUME 9, 2021 45249
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
such an answer is received, specifically for the case of an ‘A’
or ‘AAAA’ DNS record, the Quad9 servers operate a passive
DNS inspection which stores the requested domain and also
the corresponding IP address answered by the authoritative
name server to the requested domain. As a result, Quad9, and
specifically the UDR dataset, stores pairs of domain name
to IP address, derived from the authoritative answers of ‘A’
and ‘AAAA’ DNS records for all the clients’yy requests.
It is important to emphasize that the records stored in this
dataset are only from authoritative DNS servers’ answers
and therefore can be trusted in security analysis. In order to
find the domain names mapped to a given IP address, which
will be used in the expansion phase, our system goes over
the aforementioned pairs of domain name to IP address and
stores all the domain names that were resolved to the given IP
address (i.e., the domain name that resides in a pair with the
given IP address). This way we can obtain the domain names
that were resolved to the given IP address and then expand
our method to these domain names. Since we rely only on the
clients’ requests, it is possible that there are domain names
that are mapped to a specific IP address but were not queried
by the Quad9 clients and therefore would not appear in the
dataset. However, since Quad9 deals with heavy traffic, our
method still achieves sufficient and trusted data to continue
the expansion process. In our system, we do not use reverse
DNS records of IP addresses (i.e., PTR records). As a source
ofdata,ourwayofmappingIPaddressestoobservedresolved
domain names is more reliable and trusted than reverse DNS
queries since those are configured by the owner of the IP
address and may return any response, which may be false or
not up to date responses [52]. In our implementation, we rely
onlyonactualobservedresolutionsofIPaddressestodomain
namesandhencethereverseofthismappingismoreaccurate
than the reverse DNS protocol.
Another interesting approach to expanding each seed of
malicious domains is by querying the dataset or threat intelli-
gence service (i.e. VirusTotal) for the contacted domains for
each of the communicating files. This query can derive new
domains in the expansion process that may be malicious and
need to be checked. We did not use the communicating files
for the expansion stage in our experiments to avoid bias in
the next stage toward domains that reside solely in VirusTotal
and did not reside in our real-data environment (i.e. Quad 9),
since these domains may already be known to be malicious
and our goal is to expand our seed of known domains to
new undiscovered malicious domains. This allowed us to
better measure our proposed system on a real data network
environment.
C. THE PREDICT STAGE
Finally, in the Predict stage, IMDoC classifies each expanded
domain and relates it to one of the clusters. As a result
of the Predict stage, IMDoC obtains a label for each pre-
dicted domain, and uses these prediction labels to determine
whichmaliciouscampaign(i.e.cluster)thisdomainrelatesto.
When new domains are predicted to be part of the malicious
campaign, IMDoC creates a set of these domains, T, and
expands them as done for the seed domains. This process
cancontinuewhenevertherearemoredomainstoexpandand
predict, i.e. when T is not empty. When a domain is predicted
to be related to one of the malicious campaigns (i.e. cluster),
it is added to this malicious campaign domain set so that
the implemented prediction methods in IMDoC will consider
it in the upcoming decisions on new domains. The Predict
stage is divided into two different approaches, depending on
whether the domain has associated communicating files or
not, as detailed next.
1) COMMUNICATING FILES-BASED PREDICTION
Whenassociatedfilesexistforthecandidatedomain,IMDoC
constructs the feature vector of a domain as same as done
in the Train stage. This is based on the frequency of the
communicating malicious files’ malware families with the
observed domain. After constructing this feature vector, two
approaches can be taken to predict the class of expanded
domains. The first is to use the cluster centers, and assess
the distance from them in the feature space. The closest
cluster center (that exceeds a predefined threshold) becomes
the cluster the sample will reside in. This prediction method
coincides with the K-Means algorithm. The second is to
train a One Class Classifier for each cluster, and create an
ensemble method to choose which of the clusters fits the
best, or classifies this point as a noise point. This method
may be used with the clusters obtained from the DBSCAN
algorithm. Generally, one approach can be superior to the
other in different scenarios.
2) PREDICTION WITHOUT COMMUNICATING FILES
In the case, where associated files do not exist for the can-
didate domain, IMDoC uses a prediction method based on
DNS data, as presented in Algorithm 2 and explained next.
For each seed S i , for each candidate for the expanded domain
ˆ
d r ∈
ˆ
D S i , IMDoC identifies the last IP change (UDR record)
Algorithm 2 Prediction Using the Correlation From Time of
IP Change Event Used in IMDoC Algorithm
1: Y S i ← ∅
2: for ˆ d r ∈
ˆ
D S i do
3: t c ← TimeSeriesLastIPChange( ˆ d r )
4: for d j ∈ S i do
5: t s ← TimeSeriesLastIPChange(d j )
6: C c,s ← SpearmanCorrelation(t c ,t s )
7: if C c,s ≥ Thresh s then
8: Count( ˆ d r ) + +
9: end if
10: end for
11: if Count( ˆ d r ) ≥ Thresh c then
12: Y S i .append( ˆ d r )
13: end if
14: end for
45250 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
day that was observed, and constructs a time-frame, t c , of one
week starting from that day. This time-frame includes the
number of requests observed in the DSURF data for each
day in this time-frame. Next, IMDoC iterates each of the seed
domains d j ∈ S i , and creates the same time-frame t s from the
last IP change of the current observed seed domain. When
these two time-frames of one week are available, IMDoC
calculates a Spearman’s rank correlation coefficient between
the candidate domain and the current seed domain, C c,s .
The Spearman’s rank correlation coefficient is a nonpara-
metric measure of rank correlation that measures monotonic
relationships (whether linear or not) between two variables.
It has a value in the range [−1,+1], where a correlation
value of +1 is achieved when the two observed variables
have a similar rank and a correlation value of −1 indicates
that the observations have a dissimilar rank between the two
variables. Let a i , b i , i = 1,...,n, be a pair of variables with
n observations. The Spearman’s rank correlation coefficient
is defined by:
r S = 1 −
6
P n
i=1 d 2 i
n(n 2 − 1)
, (5)
where d i = rg(a i ) − rg(b i ), and rg(·) is the observation
rank [53]. The reason we chose this type of correlation over
the standard Pearson coefficient correlation is because the
Pearson coefficient correlation measures linear correlations
betweenvariablesandassumesthevariablesarenormallydis-
tributed. However, our observed variables may have different
characteristics from those noted, and can still be considered
correlated.
If the Spearman’s rank correlation coefficient value is
above a predetermined threshold (called the correlation
threshold and denoted as Thresh s ), IMDoC increments a
counter of the candidate domain, Count( ˆ d r ). When IMDoC
has calculated the correlation between the candidate domain
and all the seed domains, it observes the counter value for the
candidate domain. If this counter is above a predetermined
threshold (called the occurrence threshold and denoted by
Thresh c ), IMDoC considers this domain to be related to the
malware campaign, as represented by the seed domains, and
appends this domain to the set of predicted domains, Y S i .
The intuition for this method is based on analyzing com-
mon behaviors of malware campaigns. Domains from the
same malware campaign are more likely to be registered to
a new IP in the same time period. The IP change event repre-
sents the beginning of the specified domain in the observed
malware campaign operations. Therefore, the traffic since
this IP change event should fit the same rate pattern. Fig. 5
illustrates this behavior, and presents a histogram of the
queries observed for 5 domains from the Bayrob malware
campaign during the week after an IP change event occurred.
Practically, the method is split into 2 phases of training and
classification. In the first phase, we calculate the time-frames
since the last IP change of all seed domains and store them
in a seed time-frame database. The classification phase cor-
relates each given suspicious domain with all the domains in
FIGURE 5. An example of query patterns since the IP change of 5
domains from the Bayrob campaign.
FIGURE 6. An illustration of the training phase of the DNS-based method.
the seed. The training phase is presented in Fig. 6 and the
classification phase is presented in Fig. 7.
V. EVALUATION AND EXPERIMENTAL RESULTS
Weimplementedextensiveexperimentsinarealworkingpro-
duction environment to evaluate the performance of IMDoC
algorithm. The experiments conducted in a Quad9 DNS envi-
ronment consisted of DNS data derived from Quad9 Recur-
sive resolvers in the form of UDR and DSURF datasets,
as discussed in Subsection II-A. In the first experiment,
the initial data were a list of known malicious domains and
their related malware campaigns (i.e. their labels). The pur-
poseofthisexperimentwastoevaluatetheclusteringmethod,
where the feature vector for each domain was the histograms
of the domain communicating files’ malware families. In this
experiment,themaliciousdomainsweredividedintoclusters,
where each cluster represented a different malware campaign
and the results were verified against the given labels of the
domains in the different clusters.
In the next two experiments, our purpose was to evalu-
ate the expansion and prediction methods used in IMDoC
algorithm. In both experiments, one of the clusters was cho-
sen as a representative example. The aim of these experi-
ments was to identify new domains which did not appear
in the given malicious domain list, but were connected to
the malware campaign represented by the chosen cluster.
Both experiments use resolved IPs to expand the chosen
cluster of domains into new domains related to this cluster
VOLUME 9, 2021 45251
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 7. An illustration of the classification phase of DNS-based method.
(i.e. these two domains resolved to the same IP address
at some point in time). The main difference between these
phases was the method in IMDoC algorithm they were
designedtoevaluate.Thefirstfocusedonusingthecommuni-
cating files of each suspected domain together with machine
learning methods to decide whether this domain matched the
cluster characteristics, whereas the second focused on using
patterns of DNS requests of each suspected domain together
with statistical methods to determine whether this domain
matched the observed cluster. The methods also operated on
data with different characteristics. For the first, the domains
had observed communicating files, whereas in the second
the domains had suitable DNS data (i.e. UDR and DSURF
available data).
A. EVALUATION BY COMMUNICATING FILES-BASED
CLUSTERING
In this experiment, we manually selected 1846 domains from
9 different malware campaigns: Bayrob, Symmi, Fobber,
Virlock, Dircrypt, Locky, Tinba, Explosive, and Cryptowall,
as shown in Table 1.
TABLE 1. Number of malicious domains in each campaign.
The data were collected using threat intelligence sites pro-
viding malicious domains feeds, such as: OSINT Feeds -
Bambenek Consulting [42], Netlab OpenData Project [43],
AlienVault - Open Threat Exchange [44]. We collected
enoughsamplesforeachmalwarecampaign(morethan50)to
establish a robust notion of the domains operating within the
context of each malware campaign. Some of the domains did
not have DNS information in the UDR dataset or in Virus-
Total, but all the selected domains did have malicious files
FIGURE 8. The distribution of malware families for the Bayrob cluster.
communicating with them, which were extracted from Virus-
Total. As explained when presenting Algorithm 1, the com-
municating files for each of the inspected domains were
extracted using VirusTotal API and the AVClass tool was run
on each file to get the file’s associated malware family from
the VirusTotal AV engines. When all the files had an associ-
ated family, IMDoC algorithm constructed a malware family
distributionforeachdomainbasedontheassociatedmalware
families for each domain’s communicating malicious files.
After going over all the given malicious domains, IMDoC
algorithm clustered them based on the malware family dis-
tribution of each domain (the feature vectors, as explained
above). As a result, each cluster included malicious domains
with a similar malware family distribution. For example,
Fig. 8 shows the average malware family distribution for the
cluster related to the Bayrob malware campaign, where each
color represents a different malware family.
Importantly, in this experiment only malicious domains
have been considered since our system is expected to receive
a feed of malicious domains, where these domains are uncat-
egorized by malicious campaigns. IMDoC clusters these
45252 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 9. A comparison of real labels and clustering results.
domains based on their communicating files, which results
in several seeds for different malicious campaigns. In this
step, benign domains are irrelevant because each cluster con-
tains only malicious domains that are a part of a certain
malicious campaign. Therefore, in this experiment we only
used malicious domains to evaluate the clustering method
that will differentiate between domains that relate to different
malicious campaigns. This is considered our ground truth for
this model.
We evaluated two clustering algorithms in this experiment:
K-Means and DBSCAN, as discussed in Subsection IV-A3.
Bothimplementationswereusedfromthescikit-learnPython
framework [51]. The input provided to these algorithms was
the feature vectors mentioned above.
To measure the performance of the algorithms against
the real labels, we used several metrics: (i) Homogeneity:
each cluster only contained members of a certain class. The
value could be between 0 and 1, where 1 stands for perfect
homogeneous labeling; (ii) Completeness: all members of a
certain class were assigned to the same cluster. The value
couldbebetween0and1,where1standsforperfectcomplete
labeling; (iii) V-measure: the harmonic mean between the
homogeneity score and the completeness score ranging from
0 to 1, where 1 stands for perfect clustering in terms of
both homogeneity and completeness; (iv) Silhouette Coef-
ficient: a measure of how similar an object is to its own
cluster (cohesion) as compared to other clusters (separation).
The best value is +1 and the worst value is −1. This mea-
sures how well a clustering method performs. A score of +1
means that the clusters are well apart from each other and
can be easily distinguished. The Silhouette Coefficient can
be written as:
x−y
max(x,y) , where x is the average inter-cluster
distance (i.e. the average distance between all clusters), and y
is the intra-cluster distance (i.e. the average distance between
each point within a cluster). Achieving high values for the
metrics presented above indicates strong performance for an
algorithm. For DBSCAN we set an epsilon of 0.5 (which is
the maximum distance between two samples for one to be
considered in the neighborhood of the other), and a minimum
threshold of 40 samples in a neighborhood for which the
sampleisconsideredacorepoint.Thedistancemetricwasthe
standard Euclidean distance. For K-Means, we noted 9 clus-
ters, the same as the number of selected malware campaigns.
We set the number of times the K-Means algorithm ran with
different centroid seeds to 50. These parameters yielded the
best results for the above metrics.
The results of the evaluation metrics present strong per-
formance for the suggested methods, as shown in Table 2.
Figure 9 depicts the results of the clustering algorithms and
TABLE 2. Results for the suggested clustering algorithms.
VOLUME 9, 2021 45253
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 10. The confusion matrices of the clustering algorithms.
the comparison of the real labels to the clustering labels
provided by both methods. We used T-distributed Stochas-
tic Neighbor Embedding (T-SNE) for visualization by non-
linear dimensionality reduction, which enables embedding
high-dimensional data for visualization in a low-dimensional
space of two dimensions.
Furthermore, we evaluated the performance of the cluster-
ing algorithms as a multi-class classification problem, where
each class relates to a different malware campaign. The con-
fusion matrices presented in Fig. 10(b) show that for the
K-Meansclusteringalgorithm,allthesampleswereclassified
correctly except 5 from the Explosive malware campaign and
5fromtheCryptowallmalwarecampaignthatwereclassified
as belonging to the Dircrypt malware campaign. Fig. 10(a)
indicates that for the DBSCAN clustering algorithm, all sam-
ples were classified correctly except 16 from the Cryptowall
malware campaign that were classified as noise; i.e., not
compatible with any existing cluster.
B. COMMUNICATING FILES-BASED PREDICTION
METHODS
Inthesecondexperiment,weevaluatedthepredictionmethod
based on the domain’s communicating files. In this exper-
iment, IMDoC algorithm was used to expand one of the
clusters to find more malicious domains related to the same
malware campaign. We chose the cluster that contained the
Bayrob malware domains. Bayrob is a family of Trojans
that target the Windows platform. They can download and
launch additional modules from a C&C server. They can
also function as a proxy server. The malware is used to
send spam messages and steal user data. The family was
detected in 01/26/2017 and is still operating today [54]. Note
that the Bayrob malware uses DGA to generate the mali-
cious domains, which has been reverse engineered and fully
understood [55]. This means an exact answer can be given
when a domain is observed to be generated by this DGA.
In this experiment we used DGArchive [45], a site that
provides a convenient API to check whether a domain is
part of one of the DGAs of the malwares that reside in the
DGArchive database.
To expand this cluster, we first chose the period of time to
operate. Then, IMDoC algorithm iterated over the domains
contained in this cluster, extracted the IPs whose domains
were resolved in this period of time (there could be more
than one IP) and performed a reverse search over these IPs
to find the domains resolved to them in the defined period
of time. In this experiment, IMDoC algorithm used the pas-
sive DNS data in VirusTotal to acquire the data needed to
determine which domain name resolved to which IP address.
In this experiment, for the expansion we chose the time
period between 01/01/2018 and 01/06/2020. The 107 seed
domains related to the Bayrob malware were expanded using
the resolved IPs as stated above. This expansion process
yielded 94,942 expanded domains. Since the Bayrob DGA
only generates domains with a ‘‘net’’ TLD, we filtered the
result by the ‘‘net’’ TLD, and were left with 8,594 expanded
domains. Of these expanded domains, 1,335 were verified by
the DGArchive to be part of the Bayrob DGA. It is worth
noting that the 94,942 expanded domains did not result from
only 1 expansion process, but from several iterations of this
process over domains that were predicted to be related to this
malicious campaign. It used the prediction method described
below.
The expansion process yielded numerous domains which
were either benign or malicious but not related to the specific
malware campaign. Therefore, to find the domains which
were related to the observed malware campaign, for each
of the new domains derived from the expansion process,
45254 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 3. IMDoC prediction results for clustering by communicating files.
IMDoC algorithm extracted the communicating files of these
domains. Unlike the first experiment, it predicted which
domain was related to the observed cluster based on the
malicious file distribution to determine whether it matched
the malicious file distribution of the chosen cluster (Bayrob
malware campaign).
For the K-Means clustering method, this is fairly easy,
since we can see which of the classified cluster centers’ is
the closest in terms of Euclidean distance. If it is the cluster
related to the Bayrob malware campaign, IMDoC algorithm
tags this domain as related to this cluster and the expansion
process continues as described above on the next iteration of
the algorithm.
The procedure is more complex for the DBSCAN cluster-
ingmethod,becausethereisnobuilt-inpredictionmethodfor
thisdensity-basedclustering.Wecreatedaoneclassclassifier
(i.e.OneClassSVM)onthemaliciousfiledistributionsofthe
domains residing in the chosen cluster. When a new domain
derived from the expansion is tested, IMDoC algorithm aims
topredicttheclassofthisdomainwiththeoneclassclassifier,
and determines whether this domain relates to the malware
campaign based on the outcome. One can also expand this
functionality by running a one class classifier for each of the
clusters created by the DBSCAN algorithm and implement-
ing a voting method to determine the clusters to which the
new expanded domain should be assigned.
The results of both prediction methods are described
in Table 3. Using the K-Means prediction IMDoC algorithm
successfully expanded the seed of 107 malicious domains in
the Bayrob malware campaign cluster to 1,288 new domains
predicted to be part of the Bayrob malware campaign. Out of
these domains, 1,286 were verified to have been generated
from the Bayrob malware DGA by the DGArchive. This is a
significant expansion ratio of η ≈ 13. In terms of binary clas-
sification, this experiment resulted in 1,286 TP samples, 2 FP
samples, 7,257 TN samples and 49 FN samples. In addition
to the Precision and Recall scores defined in Subsection III,
we present the Accuracy score as follows:
A =
TP + TN
TP + FP + TN + FN
. (6)
IMDoC with K-Means prediction achieved an Accuracy
score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Open
University of Israel, in 2010. He is currently a
Security Researcher with the IBM’s Cyber Secu-
rity Center of Excellence, Beer-Sheva, specializ-
inginnetworkandsystemsecurity.Priortojoining
IBM, he served as a Security Software Engineer
for PMO.
AVIV RON received the B.Sc. degree in com-
puter science from Ben-Gurion University, Israel,
in 2007. He worked for five years as a Soft-
ware Engineer with Intel, four years as a Security
Researcher and Architect with Intel, and five years
as a Senior Security Researcher with IBM. He also
served for four years as an External Lecturer on
cyber security with Ben Gurion University. He has
17 patents. He is currently focused on detecting
cyber threats by applying artificial intelligence.
45258 VOLUME 9, 2021
 2017, pp. 2171–2175.
[41] (2011). Enisa Technical Report–Botnets: Detection, Measurement,
Disinfection & Defence. [Online]. Available: https://www.enisa.
europa.eu/publications/botnets-measurement-detection-disinfection-
and-defence/at_download/fullReport
[42] D. Zhuang and J. M. Chang, “PeerHunter: Detecting peer-to-peer botnets
through community behavior analysis,” in Proc. IEEE Conf. Dependable
Secure Comput., Zhengzhou, China, Aug. 2017, pp. 493–500.
[43] D. Zhuang and J. M. Chang, “Enhanced PeerHunter: Detecting peer-to-
peer botnets through network-flow level community behavior analysis,”
IEEE Trans. Inf. Forensics Security, vol. 14, no. 6, pp. 1485–1500,
Jun. 2019.
[44] H. P. Joshi and R. Dutta, “Identifying P2P communities in network
traffic using measures of community connections : IEEE CNS 20 poster,”
in Proc. IEEE Conf. Commun. Netw. Secur. (CNS), Avignon, France,
Jun. 2020, pp. 1–2.
[45] H. P. Joshi and R. Dutta, “Improved P2P botnet community detec-
tion: Combining modularity and strong community,” in Proc. IEEE
Global Commun. Conf. (GLOBECOM), Waikoloa, HI, USA, Dec. 2019,
pp. 1–6.
[46] M. Cirillo, M. Di Mauro, V. Matta, and M. Tambasco, “Botnet
identification in DDoS attacks with multiple emulation dictionaries,”
Supplemental Mater., doi: 10.1109/TIFS.2021.3082290.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
-clustered DDoS attacks,” in Proc. EUSIPCO, Kos, Greece,
Aug./Sep. 2017, pp. 2171–2175.
[41] (2011). Enisa Technical Report–Botnets: Detection, Measurement,
Disinfection & Defence. [Online]. Available: https://www.enisa.
europa.eu/publications/botnets-measurement-detection-disinfection-
and-defence/at_download/fullReport
[42] D. Zhuang and J. M. Chang, “PeerHunter: Detecting peer-to-peer botnets
through community behavior analysis,” in Proc. IEEE Conf. Dependable
Secure Comput., Zhengzhou, China, Aug. 2017, pp. 493–500.
[43] D. Zhuang and J. M. Chang, “Enhanced PeerHunter: Detecting peer-to-
peer botnets through network-flow level community behavior analysis,”
IEEE Trans. Inf. Forensics Security, vol. 14, no. 6, pp. 1485–1500,
Jun. 2019.
[44] H. P. Joshi and R. Dutta, “Identifying P2P communities in network
traffic using measures of community connections : IEEE CNS 20 poster,”
in Proc. IEEE Conf. Commun. Netw. Secur. (CNS), Avignon, France,
Jun. 2020, pp. 1–2.
[45] H. P. Joshi and R. Dutta, “Improved P2P botnet community detec-
tion: Combining modularity and strong community,” in Proc. IEEE
Global Commun. Conf. (GLOBECOM), Waikoloa, HI, USA, Dec. 2019,
pp. 1–6.
[46] M. Cirillo, M. Di Mauro, V. Matta, and M. Tambasco, “Botnet
identification in DDoS attacks with multiple emulation dictionaries,”
Supplemental Mater., doi: 10.1109/TIFS.2021.3082290.
Authorized licensed use limited to: University of Tokyo. Downloaded on July 09,2021 at 05:49:17 UTC from IEEE Xplore. Restrictions apply.
 ¼ 1
w i;j x i
!
ð4Þ
where
z is the forecast value;
φ is the activation function;
w is the vector of weights;
b is the bias; and
n is the number of neurons.
In the hidden layer, the activation function is often selected as
the logistic sigmoid function.
sðzÞ ¼
1
1þe ?z
ð5Þ
3.3. Auto-regressive integrated moving average
The ARIMA (auto-regressive integrated moving average) is a
time series forecasting model [38,50] that uses time-series sta-
tionary data. Therefore, the data must be made stationary by
differencing d times. Auto-regression is a forecasting equation
term that explains lags of the time series. Furthermore, lag forecast
errors are explained by a moving average term in the forecasting
equation. Lastly, integration explains the addition of those two
series. Eq. (6) below depicts the non-seasonal ARIMA model as
“ARIMA(p,d,q)”:
r t ¼ φ o þ ∑
p
i ¼ 1
φ r t?i þa t ? ∑
q
i?1
θ i a t?i ð6Þ
where
p is the number of autoregressive terms;
d is the number of non-seasonal differences;
q is the number of lagged forecast errors in the prediction
equation;
φ is the autoregressive constant;
θ is the moving average constant;
t is the number of time series data items;
r is the forecast value; and
a is the moving average value.
3.4. Neural network auto regressive
The NNAR forecasting model is a hybrid ANN–ARIMA model in
which the neural network uses lagged values of the time series as
inputs. Since the model uses one hidden layer feed-forward
network in which the inputs are lags 1 to p, the model uses p last
observations [50]. In the ANN modeling stage, the model starts
with a random weight and then applies the adjusted weight when
performing the forecasting computation. The network is trained
for one-step forecasting and uses a recursive calculation for multi-
step forecasting. Therefore, the mathematical formula for NNAR
becomes:
y t ¼ w 0 þ ∑
k
j ¼ 1
b j Ug w 0j þ ∑
p
i ¼ 1
w ij Uy t?1
!
þ ε t ð7Þ
where
j ¼ 1;2;…;k is the number of neurons;
i ¼ 1;2;…;p is the lag;
w o is a constant;
w j is the connection weight where j ¼ 1;2;…;k;
g is the activation function in Eq. (5);
w oj is a constant at neuron j;
w ij is the connection weight where
i ¼ 1;2;…;p; j ¼ 1;2;…;k; and
ε t is an error term.
In practice, the ANN performs a nonlinear model of the last p
observations with k neurons where
y t ¼ fðy t?1 ;…;y t?p ;wÞþ ε t ð8Þ
y t is the predicting value;
p is the lag number;
w is the weight for all parameter; and
ε t is the error term.
The resulting NNAR(p,k) model resembles a model that uses p
lagged inputs and k nodes in hidden layer. For example NNAR(8,9)
indicates a neural network that uses the previous eight values
ðy t?1 ;y t?2 ;…;y t?8 Þ as inputs for the neural network and uses nine
neurons in hidden layer. A NNAR(p,0) model resembles an ARIMA
(p,0,0) model but does not have the parameter restrictions used to
ensure stationarity.
3.5. Evaluation method
To evaluate the accuracy of electricity demand, several criter-
ions are used. There are different alternative methods for this
purpose: MAPE, MAE and RMSE are defined as follows:
MAPE ¼
1
n
∑
n
i ¼ 1
j _ Y i ?Y i j
Y i
? 100 ð9Þ
RMSE ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1
n
∑
n
i ¼ 1
½ _ Y i ?Y i ? 2
sReceived February 20, 2021, accepted March 7, 2021, date of publication March 18, 2021, date of current version March 29, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3066957
IMDoC: Identification of Malicious Domain
Campaigns via DNS and Communicating Files
DAVID LAZAR
1 , KOBI COHEN 2 , (Senior Member, IEEE), ALON FREUND 3 ,
AVISHAY BARTIK
3 , AND AVIV RON 3
1 Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel
2 School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel
3 IBM Cyber Security Center of Excellence, Beer Sheva 8489325, Israel
Corresponding author: Kobi Cohen (yakovsec@bgu.ac.il)
This work was supported in part by the IBM Cyber Security Center of Excellence at Gav-Yam Negev, and in part by the Israeli National
Cyber Bureau via the Cyber Security Research Center at Ben-Gurion University of the Negev.
ABSTRACT Cyber attacks have become more sophisticated and frequent over the years. Detecting the
components operated during a cyber attack and relating them to a specific threat actor is one of the main
challenges facing cyber security systems. Reliable detection of malicious components and identification
of the threat actor is imperative to mitigate security issues by Security Operations Center (SOC) analysts.
The Domain Name System (DNS) plays a significant role in most cyber attacks observed nowadays in
that domains act as a Command and Control (C&C) in coordinated bot network attacks or impersonate
legitimate websites in phishing attacks. Thus, DNS analysis has become a popular tool for malicious domain
identification.InthiscollaborativeresearchassociatingBen-GurionUniversityandIBM,wedevelopanovel
algorithm to detect malicious domains and relate them to a specific malware campaign in a large-scale real-
data DNS traffic environment, dubbed Identification of Malicious Domain Campaigns (IMDoC) algorithm.
Its novelty resides in developing a framework that combines the existence of communicating files for
the observed domains and their DNS request patterns in a real production environment. The analysis
was conducted on real data from Quad9 (9.9.9.9) DNS recursive resolvers combined with malicious
communicating files extracted from VirusTotal, and confirms the strong performance of the algorithm on
a real large-scale data production environment.
INDEX TERMS Cyber security, domain name system (DNS), clustering methods, detection algorithms.
I. INTRODUCTION
The Domain Name System (DNS) is a fundamental com-
ponent of the functionality of the internet. DNS provides a
mapping between domain names and IP addresses, which is
a core service for applications on the internet. Since DNS
is ubiquitous across the internet, DNS services have been
abused in different ways to execute a range of attacks [1].
An attacker can exploit a set of domains to carry out complex
attacks, while targeting users and organizations through mal-
ware related campaigns such as phishing [2]–[4], pharming
[5], [6], and Distributed Denial of Service (DDoS) attacks
using a multitude of botnets [7], [8]. One notorious example
is the Dyn DDoS cyberattack by the Mirai botnet in 2016 [9].
The associate editor coordinating the review of this manuscript and
approving it for publication was Gautam Srivastava .
To respond to this malicious use of the DNS, domain
blacklists containing known malware domains [10] and IP
reputation information [11] have been developed by net-
work operators to detect DNS queries originating from
malware-infected machines and block their communications
withtheattackers.TocreatetheseblacklistsandIPreputation
information, malicious domains and IP addresses must be
identified to separate them from benign ones. This effort
is crucial since security vendors should not block benign
domains from their clients.
Once a malicious domain has been identified, it is imper-
ative to determine which threat actor or malware campaign
the domain is related to. This can shed light on the type of
malicious activity of the domain and its purpose. This kind
of information can allow Security Operations Center (SOC)
analyststobetterunderstandcybersecuritythreatsandhandle
them efficiently and reliably. The relationship of a given
45242
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
domain to a specific malicious activity can help security
researchers build effective models to mitigate security issues.
Moreover, it can help analysts and researchers to gain better
insights of an observed threat group and help in classifying
executables to a specific malware in addition to YARA rules
and other methods.
OneofthemostpopularwaysofanalyzingDNStrafficisto
use passive DNS (pDNS) data (see [12]–[15] and references
therein). The analysis is performed offline on a copy of live
DNS traffic to study past DNS traffic patterns to evaluate the
maliciousness of non-categorized domains. Offline calcula-
tions overcome the need to process a huge amount of data
in real-time. Recent studies have analyzed pDNS to isolate
malicious domains and IP addresses, and identify infected
machines [12]–[15]. However, developing robust methods to
relatemaliciousdomainstoamalwarecampaignhasnotbeen
addressed and is the main focus of this paper.
Relating a massive amount of unknown domains to a
malware campaign based solely on DNS traffic is a very
challengingtask.However,whencombiningDNStrafficwith
threat intelligence data, a robust method for this task can be
constructed. In this paper, our method utilizes the communi-
cating files of suspicious domains together with passive DNS
traffic to relate unknown domains to a malware campaign.
The communicating files were extracted using VirusTotal’s
file analysis database. The passive DNS traffic was derived
from a real production environment, namely, Quad9 DNS
servers.
A. MAIN RESULTS
This paper addresses the problem of expanding a seed
of known malicious domains related to the same mal-
ware campaign to categorize unknown domains as mali-
cious and related to this malware campaign. Related stud-
ies of malicious domain detection have relied mostly on
DNS patterns and characteristics or domain name analysis
to find evidence of a Domain Generation Algorithm (DGA)
[12]–[14], [16]–[19]. However, these methods are only
used to distinguish between benign and malicious domains.
In[20],theauthorsconsideredtheproblemofidentifyingnew
malicious domains related to an observed campaign, as con-
sidered in this paper. Their method was based on clustering
known malicious domains from the same campaign together
with uncategorized domains to find new malicious domains
related to the observed campaign. It achieved good perfor-
mance in detecting phishing attacks in which the domain
name has a specific structure (where the attacker tries to
mimic a domain name of a well-known website). However,
its performance degrades when facing general attacks when
the domain name is structure agnostic, such as general C&C
domains. In this paper we overcome this issue by developing
a novel robust method for detecting general attacks. It should
be noted that the system described here is not intended to
find zero-day attacks since these are beyond the scope of
this paper. These types of attacks are typically addressed
by anomaly detection algorithms trained on benign samples.
Below, we summarize our main contributions.
1) A NOVEL METHOD TO RELATE MALICIOUS DOMAINS TO
MALWARE CAMPAIGNS BASED ON COMMUNICATING FILES
We develop a novel method to determine the malware cam-
paign of a malicious domain based on its communicating
files. The novelty resides in the use of the communicating
files of each domain to categorize it to its malware campaign.
Our approach takes a set of malicious domains and clusters
them as a function of their malware family distributions
based on communicating files, without relying on their DNS
features at all. This allows the system to relate malicious
domains to malware campaigns with high reliability when
communicating files are available. This contrasts sharply
with most malicious domain identification methods that rely
heavily on DNS features.
2) A NOVEL METHOD TO DETECT UNCATEGORIZED
DOMAINS FROM A SPECIFIC MALWARE CAMPAIGN
BASED ON DNS DATA
We develop a novel method to identify uncategorized mali-
cious domains and relate them to an observed malware cam-
paign. This is done by using the time-based correlation of the
number of aggregated DNS requests per day between a set of
malicious domains from the same malware campaign and a
suspicious domain. Note that in [20], the method clustered a
set of domains based on DNS features for a fixed time frame
(a fixed week for all domains in the set in their experiments)
regardless of the IP change events of domains involved in the
clustering process. Unlike [20], we innovate by analyzing a
dynamic time-frame selection (a week in our experiments)
which starts from the last observed IP change event of each
pair of the known malicious domain and the new suspicious
domain involved in the time-based correlation. This method
allows for detection of new suspicious domains with high
reliability through its dynamic time correlation analysis.
3) ALGORITHM DEVELOPMENT
We develop an algorithm to identify new malicious domains
in the context of a malware campaign, dubbed Identification
of Malicious Domain Campaigns (IMDoC). The algorithm
processes communicating files data as well as DNS data
to identify malicious domains by utilizing the two methods
described above. IMDoC algorithm works as follows. The
algorithm is divided into 3 main stages: Train, Expand, and
Predict.AnillustrationofthealgorithmcanbefoundinFig.2
in Section IV. In the Train stage, the algorithm performs a
training phase, where known malicious domains are given.
In the training process, a feature vector is constructed using
the domains’ communicating files. Then, clustering algo-
rithmsareappliedtothedomainsbasedonthefeaturevectors.
Next, in the Expand stage, the algorithm expands each of
the clusters by their resolved IPs, and as a result obtains
new samples which are loosely connected to the observed
maliciousdomains.Finally,inthePredictstage,thealgorithm
VOLUME 9, 2021 45243
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
uses one of the two methods described above, depending on
whether communicating files are available or not, to decide
whether the new expanded domains (i.e., the candidates) are
a part of the observed malicious campaign or not.
4) EXTENSIVE PERFORMANCE EVALUATION USING REAL
DATA IN A REAL PRODUCTION ENVIRONMENT
Enterprises tend to be reluctant to share their data and
real-world security performance because of the legal risks of
violating privacy, or to avoid sharing information that could
benefittheircompetitors.Therefore,analyzingandvalidating
cyber security algorithms in real-world systems using up-to-
date real data is one of the main hurdles in academic cyber
security research. This collaboration between Ben-Gurion
University and IBM constitutes an important step forward.
We deployed the algorithm in a real working production
environment, and analyzed and validated its performance
using up-to-date data. Specifically, the performance evalua-
tion consisted of data from Quad9 (9.9.9.9), a free service
IBM launched with Packet Clearing House (PCH) and the
Global Cyber Alliance (GCA). Quad9 handles a massive
amount of DNS requests and responses daily at the recursive
resolver layer, and provides several datasets that originate
from these requests and responses. These datasets are filtered
fromalluser-datatoavoidviolationsofprivacy.Forexample,
one of the datasets we used in this paper is a stream of newly
observed DNS responses, dubbed the Unique DNS Record
(UDR), containing only the queried domain, the query type
and the response record. This stream of around 1 million
UDRrecordsperdaywascondensedfromtheQuad9systems
operatingin76countriesand128locations.Theexperimental
results based on this real-world environment were satisfying
and highly compatible across all tests, and significantly out-
performed existing methods.
B. RELATED WORK
Developing detection methods for cyber security can be
divided broadly into two main approaches: signature-based
detection [21]–[23] and anomaly-based detection [7], [15],
[24]–[27]. To identify malicious domains, detection methods
typically use DNS data, as considered in this paper. Next,
we discuss several aspects of DNS-based detection methods
that were investigated in related studies, including DNS data
collection, data enrichment, ground truth, and algorithmic
methods [16].
1) DNS DATA COLLECTION
The DNS infrastructure is distributed; hence, different loca-
tions can be considered to collect the DNS data. The most
common choice between those is the DNS resolver involve-
ment, since it is the only location that has access to the
clients’ DNS queries. One approach consists of collect-
ing the communication data between an end host (e.g. PC,
smartphone, server) and its DNS resolver (referred to as
the Host-Resolver) [13], [17]. The other collects the com-
munication data between two DNS servers (referred to
as DNS-DNS), one of which may be the DNS resolver
[12], [14]. The first location (Host-Resolver) can pro-
vide detailed information about clients’ DNS queries and
responses (e.g. IP addresses) which can create a better
behavioral pattern for the hosts, because their activity can be
tracked sequentially. In [13], the authors used a table of query
sourceIPaddressesforeachdomainnametocreateaDomain
Name Travel Graph (DNTG) which represents a sequence
of queries in a small time window. In [28], the authors
analyzed a dataset containing more than 26 billion DNS
request-response records collected from more than 600 glob-
ally distributed recursive DNS resolvers to gain insights into
the evolving nature of DNS traffic, and identify malicious
domains. Another advantage of Host-Resolver collection is
that any institute can deploy sensors on its network to col-
lect this kind of DNS data. However, this also can be a
disadvantage since the behavior of hosts can only be seen
within a single organization. The exception is a public DNS
server for recursive queries (e.g. Google Public DNS [29],
Quad9 DNS [30], Cisco OpenDNS [31], Cloudflare 1.1.1.1
DNS [32]). The data collected from these servers is more
diverse because they represent different types of clients and
there is a greater likelihood of catching suspicious behav-
iors related to different attacks. However, because of privacy
issues, public DNS vendors may omit most client details
saved in their datasets.
TheDNS-DNSdatacollectionsensorscollectqueriesfrom
different organizations. In cases where the data are collected
from TLD servers, they have the greatest visibility and can
yield unique insights to expose new malicious trends. How-
ever, the queries’ responses are not available at this level
since these only serve iterative queries. Collecting queries
from an Authoritative server solves this issue. However, due
to caching at the recursive resolver level, not all queries
will be visible to that server. The DNS-ADVP platform [7]
analyzes passive DNS records from an Authoritative DNS
server to identify DDoS (Distributed Denial of Service)
attacks against Top-Level domains. The Kopis system [12]
passively monitors DNS traffic at the upper levels of the
DNS hierarchy (Authoritative servers and TLDs) to detect
malware domains using the global visibility obtained by
monitoring network traffic at the upper DNS hierarchy with-
out relying on monitoring traffic from local recursive DNS
servers. Another distinction between the different DNS data
collection approaches can be made in terms of the method
used to collect the DNS data. One is to initiate queries to
a predetermined large collection of domains to obtain the
domain resolution responses [18]. The other is to collect the
requests and their responses initiated by clients passively [7],
[12]–[14], [20]. The first approach is known as active DNS
data collection, and the latter is called passive DNS data
collection. There are various problems associated with the
active DNS data collection approach. The first is that the
queries initiated by the collector itself do not reflect an actual
user usage pattern. Moreover, if a predetermined limited set
of hosts is queried, the data collected may be biased. On the
45244 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
other hand, active DNS data provides an easy way to collect
data without concerns over privacy issues. Passive DNS data
collection is the approach taken in the majority of studies
conducted in the field of DNS analysis as it better represents
the characteristics of real users and can be more helpful in
identifying trends and patterns in clients’ activity based on
their DNS requests and their corresponding responses.
In the system model considered in this paper, we col-
lected passive DNS data from Quad9, a public DNS recursive
resolver servers. Therefore, the data were collected at the
Host-Resolver level. Bear in mind that the application of
IMDoC is not limited to our evaluation environment and
datasets.ItcanbeappliedtodifferentDNSenvironmentswith
various data collection points (e.g ISP-level).
2) DATA ENRICHMENT
Except for pure DNS data (i.e. request and response), other
sources of information can be used to enrich the data used
in the DNS analysis. In [19], the authors used geo-location
data to determine hosting countries and cities as part of their
IP address analysis. This was used to determine whether an
IP address belonged to a country that is notorious for hosting
malicious domains and to depict the fact that malicious graph
components are often characterized by greater distances
betweencities/countriesinwhichtheirIPsarehosted.In[20],
the authors used the Autonomous System Number (ASN)
from the Border Gateway Protocol (BGP) information as one
of their clustering features. In [18], the authors used WHOIS
data to verify that an IP was public rather than dedicated in
case the Fully Qualified Domain Name (FQDN) belonged to
a hosting service Second Level Domain (SLD). In the system
model considered in this paper, the files communicated with
the observed domains are extracted to enrich the DNS data.
These files can be derived from threat intelligence sites or
from any security vendor report that relates malicious files to
domain names. In our evaluation environment, IMDoC used
VirusTotal as a data source for the communicating files.
3) GROUND TRUTH
Another consideration in a DNS analysis is determining
a high-quality ground truth, whether as a starting seed to
expand from using unsupervised learning methods, or for
training and validation sets using supervised learning meth-
ods. To do so, blacklists and threat intelligence sites can
provide a domains list related to malicious activity. Some
of these blacklists are category-related, such as: spam black-
lists (DNSBL [33]), or phishing blacklists (PhishTank [34],
OpenPhish [35]), whereas other blacklists provide a general
indication of maliciousness (IBM X-Force’s Threat Intel-
ligence database [36], VirusTotal [37], McAfee SiteAdiv-
sor [38], malwaredomainlist.com [39], malc0de.com [40],
DNS-BH [41]). In [13], the authors used a method in which
if one of the cluster members appeared on the blacklist,
the cluster containing the blacklisted domain was marked
as malicious. However, methods based on domain blacklists
are limited to known behaviors, since only known malicious
domains are included. Moreover, one of the problems of
learning from blacklists is that it is a conservative list which
includes only domains that have been confirmed as mali-
cious. However, there are many domains in malicious cam-
paigns that are actually used by malware without directly
contributing to its malicious activity (e.g., C&C commu-
nication, payload download, spam-relaying). Furthermore,
some malicious domains are not on the blacklist because a
specific variant of the malware was not researched or reverse
engineered. Another approach to achieve ground truth on
malicious behavior is to simulate attacks. In [7], the authors
created synthetic DDoS attacks over different time frames to
test their DDoS attack classifier.
In this paper we use popular threat intelligence sites
and domain name blacklists as our ground truth for mali-
cious domains, and specifically OSINT Feeds - Bambenek
Consulting [42], Netlab OpenData Project [43], and Alien-
Vault - Open Threat Exchange [44]. Furthermore, we used
DGArchive [45] to validate our predicted domains. This
ground truth fits our objective of expanding a seed of
known malicious domains that relates to a certain malware
campaign.
4) ALGORITHMIC METHODS
Different algorithmic methods via DNS analysis have been
suggested to identify malicious domains. In [13], the authors
constructed a graph from a batch of ordered queries in a cer-
tain timeslot and clustered the domains based on sequential
correlation. In [14], a single domain at a time was inspected
by constructing a domain graph which represented the cor-
relation among different domains. A path-based mechanism
was used to derive a malicious score for each domain. A dif-
ferent approach proposed in [46] calculated the reputation
score based on domain name lexical features.
Amorecommonapproachistousemachinelearningalgo-
rithms to classify domains as malicious. In [12], the authors
used supervised learning which takes a set of statistical fea-
ture vectors as input, which summarizes the query/response
behavior of each domain. In [47], the J48 decision tree
algorithm was used with a feature vector consisting of both
DNS related features and other network traffic features to
detect domains used for malware C&C servers. In [18],
an iterative semi-supervised random forest classifier was
constructed to separate dedicated and public IP addresses.
In [48], the authors proposed a deep neural networks to clas-
sify domain names as benign or malicious, as part of DGAs.
These methods, however, have not considered the problem
of identifying new malicious domains related to an observed
campaign, as considered in this paper. In [20], the authors
used unsupervised clustering to expand a seed of mali-
cious domains in order to identify new malicious domains.
However, as explained in Subsection I-A, the method is
not robust to general attacks, which is the main focus of
this paper.
VOLUME 9, 2021 45245
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
II. PRELIMINARIES
We start by presenting background knowledge on the
Quad9 DNS Architecture in Subsection II-A, which is the
environmentforthisstudy.WethendescribeVirusTotal(Sub-
section II-B) that was used to extract data about the files
associated with the observed malicious domains, and the
AVClass tool (Subsection II-B1) that was used to parse the
file labeling of VirusTotal’s AV engines.
A. THE Quad9 DNS ARCHITECTURE
The architecture in this paper is based on a real-world envi-
ronment in the form of Quad9, a free service that IBM
launched in collaboration with Packet Clearing House (PCH)
and the Global Cyber Alliance (GCA) to deliver greater
online privacy and security protection to consumers and busi-
nesses[30].Quad9providesastreamofnewlyobservedDNS
responses,oraUniqueDNSRecord(UDR)thatonlycontains
the response domain, query type, and response record. This
stream of roughly 1 million UDR records per day is con-
densedfromtheQuad9systemsoperatingin76countriesand
128 locations. Quad9 also offers aggregations of the request
counts for some domains. These data are called DSURF. Due
to the massive volume Quad9 DNS recursive resolvers deal
with, the aggregation is sampled for only a small percent-
age of the requests that flow through the Quad9 recursive
resolvers.
An illustration of Quad9 DNS architecture is presented
in Fig. 1. Each client sets the Quad9 DNS recursive
resolver address (9.9.9.9) to consume DNS services from
this provider. The Quad9 DNS recursive resolver queries
authoritative DNS servers upon DNS requests by its clients.
Generally, when a DNS client needs to find the IP address
FIGURE 1. An illustration of the Quad9 architecture.
of a host or service known by its FQDN, it queries its DNS
recursive resolver for the IP Address. The recursive resolver
first looks for the IP address in its cache. If it does not exist,
it starts a hierarchical recursive resolution process, which
begins with the root servers and ends at an authoritative name
server. Since the DNS system is hierarchical, the root node
contains the addresses of all Top Level Domain (TLD) name
servers, and the TLD name servers contain the addresses
of Second Level Domain (SLD) name servers. Therefore,
the recursive resolver first requests the root node, followed
by the next tree level, whose addresses are responded to
by current tree level, until an authoritative answer is found
whichyieldstheresponsetotherequestedquery.IftheFQDN
is invalid or non-existent in the tree, the recursive resolver
reports this information to the client.
In our architecture, cached DNS requests do not appear
in the UDR database since it only contains newly observed
DNS responses. Whenever a DNS request does not appear
in the recursive resolver cache and the resolver queries the
rest of the chain of servers within the DNS hierarchical
recursive resolution process, the request is recorded in the
UDR database. As for the DSURF database, the cached DNS
requests for a specific FQDN appear in the aggregation of the
requests. However, as stated above, only a small percentage
of these requests are aggregated.
InordertopreservetheprivacyofQuad9DNSclients,only
some of the details are saved for each request, including the
DNS request code, the queried FQDN, the response code,
Time To Live (TTL), and the resolved IP addresses. The
clients’ identification and characteristics do not appear in the
databases.
B. VirusTotal
VirusTotal [37] is a website that aggregates many
antivirus (AV) products and online scan engines to check
for malware and malicious activity. Upon submitting a file
or domain, basic results are shared with the submitter, and
also between the examining partners, who use the results to
improve their own systems. Users can also scan suspicious
domains, URLs, and search through the VirusTotal dataset.
Currently, VirusTotal inspects samples with over 70 antivirus
scanners and URL/domain blacklisting services.
Regarding files, VirusTotal not only indicates whether
a given AV solution has detected a submitted file as
malicious, but also displays each engine’s detection label
(e.g. Trojan.gen). Regarding domains and URLs, VirusTotal
can obtain data about the IPs the domains has resolved to,
Historical WHOIS Lookup, Historical SSL Certificates, and
the latest files that communicated with this domain when
opened or executed (Communicating Files). VirusTotal also
has URL scanners integrated within it. Most can discriminate
betweentypes ofmalicious sites(e.g.malware sites,phishing
sites, suspicious sites) for some of the submitted sites.
VirusTotal offers numerous ways to submit files and
domains for inspection by the products integrated in
it, including the primary public web interface, desktop
45246 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
uploaders, browser extensions, and a programmatic API.
In this study we used the HTTP-based public API to monitor
for suspicious files and domains in VirusTotal.
1) AVClass
To parse the results of the VirusTotal Anti-Virus (AV)
engines, we used the AVClass tool [49], [50], a malware
labeling tool. AVClass takes the AV labels as input for a large
number of malware samples (e.g., VirusTotal JSON reports)
and outputs the most likely family name for each sample that
it can extract from the AV labels.
III. PROBLEM STATEMENT
WeconsiderasetD , {d 1 ,d 2 ,...,d N D }containingN D mali-
cious domains, a set F , {F 1 ,F 2 ,...,F N F } containing N F
malwarefamiliesandasetB , {B 1 ,B 2 ,...,B N B }containing
N B malware campaigns where N B ≤ N F and N B ≤ N D . Each
domain (say d j ∈ D) relates to a single malware campaign
(say B i ∈ B). Typically, in real-world scenarios, a large
number of domains are involved in each campaign attack.
Each campaign B i follows distribution f i over the malware
family set F. Thus, we say that domain d j relates to malware
campaign B i if the set of malwares that communicates with
domain d j follows distribution f i .
A malware family contains variants or different instances
of a specific malware. For example, Locky is a ransomware
malware released in 2016. Since then several variants found
in the wild contain minor changes in the way the malware
operates. Some of these variants are still operating. All these
variants are categorized as a part of the Locky malware fam-
ily. A malware campaign is assembled from various malware
families. The distribution of these malware families distin-
guishes each campaign from another.
Next, we denote the domain seed S i as the set of domains
related to malware campaign B i . As in [20], we are interested
in expanding the domain seeds to find new domains which
are related to malware campaigns. This is done by expand-
ing each domain in the seed to other candidate domains.
This involves extracting all the domains resolved to this IP,
as described below. Let
ˆ
D d j be a set of candidate domains
for domain d j ∈ S i , and let
ˆ
D S i ,
n
ˆ
D d j ,d j ∈ S i
o
be the set
of all candidate domains for domains in S i . From the set of
candidate domains, we are interested in judiciously selecting
a subset Y S i ⊆
ˆ
D S i of domains to expand the seed S i with
sufficient reliability. The expanded set of domains is defined
by:
E i , S i ∪ Y S i , (1)
and we define the expansion ratio of seed S i by:
η i ,
|E i |
|S i |
. (2)
Next, we define the well-known detection measures that
are used in most of the cyber-security literature. Let TP i ,
FN i , FP i and TN i denote the number of True Positive (i.e.,
when a malware campaign domain is classified as related to
this specific malware campaign), False Negative (i.e., when a
malware campaign domain is classified as unrelated to this
specific malware ), False Positive (i.e., when an unrelated
domain to the observed malware campaign is classified as
related) and True Negative (i.e., when an unrelated domain
to the observed malware campaign is classified as unrelated)
binary classification results for S i , respectively. Let
P i =
TP i
TP i + FP i
(3)
denote the Precision score, and let
R i =
TP i
TP i + FN i
(4)
denote the Recall score for S i .
Since we are interested in categorizing a large number
of malicious domains to malware campaigns, these marked
domains will eventually be blocked, or assigned to SOC
analysts to investigate and act on each case. As a result, our
systemshouldachieveahighPrecisionscore,sodomainsthat
are benign or unrelated to the observed malicious campaign
are not blocked unintentionally or a cyber-security investiga-
tion conducted in vain. At the same time, we are interested
in achieving a Recall score which is not too small (typically,
greater than 0.3), to categorize a sufficiently large number
of malicious domains to a malware campaign. This allows
SOCanalyststobettercharacterizeandbuildefficientmodels
for the malware campaign for cyber security research and
operations.
The objective is thus to develop an algorithm that maxi-
mizes the average expansion ratio over the seeds, under the
target reliability constraints of P i ≥ ρ 1 and R i ≥ ρ 2 for
all S i . In the experiments, we set typical values of the target
Precision score to ρ 1 ≈ 0.8 − 0.9 and the target Recall score
to ρ 2 ≈ 0.3.
IV. THE IDENTIFICATION OF MALICIOUS DOMAIN
CAMPAIGNS (IMDoC) ALGORITHM
In this section we present IMDoC algorithm to meet
the objective described above. The algorithm is illustrated
in Fig. 2, and the pseudocode is given in Algorithm 1.
IMDoC is divided into 3 main stages: Train, Expand, and
Predict. In the Train stage, IMDoC first acquires the ground
truth. Then, it constructs the feature vector accordingly using
associated files. Finally, it clusters the domains based on
the constructed feature vectors. Next, in the Expand stage,
IMDoC expands each cluster by its resolved IPs, and obtains
new samples which are loosely connected to the observed
malicious domains. Finally, in the Predict stage, IMDoC
uses two different methods to decide whether the expanded
domains are part of the observed malicious campaign or not.
Each of these stages plays an important role in the algorithm
as explained in detail next.
A. THE TRAIN STAGE
In the training stage, IMDoC operates on a set of given mali-
ciousdomainsandextractsthefeaturevectorforeachdomain
VOLUME 9, 2021 45247
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 2. The architecture of IMDoC algorithm.
Algorithm 1 IMDoC Algorithm
1: D ← N D malicious domains.
2: for d j ∈ D do
3: C j ← CommunicatingFiles(d j )
4: for c i ∈ C j do
5: l ← AVClass(c i )
6: V d j (l) + +
7: end for
8: end for
9: S ← Clustering(V)
10: for S i ∈ S do
11: T ← S i
12: while T 6= ∅ do
13: for d j ∈ T do
14: IP d j ← ResolvedIPs(d j )
15:
ˆ
D d j ← ResolvedDomains(IP d j )
16: Y d j ← Predict( ˆ D d j )
17: for y ∈ Y d j do
18: if label(y) == i then
19: T.append(y)
20: end if
21: end for
22: T.remove(d j )
23: end for
24: end while
25: end for
based solely on its communicating files. Then, IMDoC clus-
tersthedomainsbasedontheconstructedfeaturevectors.The
goal of this stage is to build a ground truth for each malicious
campaign, consisting of the domains that are related to it,
based on their communicating files. Thus, only malicious
domains are considered in this stage.
1) OBTAINING THE DATA
IMDoC starts by getting a set of domains D containing
N D malicious domains. These domains are suspected of
malicious activity, identified by either a heuristic automated
method or manually, by a security analyst. This domain seed
can contain domains that are related to different malware
campaigns.
2) CONSTRUCTING THE FEATURE VECTOR
Let C j ,
n
c 1 ,c 2 ,...,c N C j
o
be the set of communicating
files for domain d j ∈ D, with cardinality N C j . Next, IMDoC
extracts the set C j for each domain d j ∈ D using VirusTotal
API.Whenadomainis searchedinVirusTotal,agreatdealof
information can relate it to a malicious activity. IMDoC uses
the communicating files to relate each domain to a specific
malware campaign.
For each file, the SHA-256 file hash is provided. When
a file hash is searched in VirusTotal, the results of all
72 Antivirus products collaborating with VirusTotal are
shown. Each AV product has a different way to tag the result
of the malicious entity, and there are different tags for the
same file. These tags can point to the same malware fam-
ily or variants with different descriptions, and can provide
information about different types of malware families for the
same file, as each AV product operates differently. For each
domain d j ∈ D, IMDoC uses the AVClass tool to obtain the
resulting malware family F k ∈ F from these tags for each
communicating file c i ∈ C j . Then, it generates a feature
vector V d j of size N F for each domain d j , where each entry
contains the frequency of the malware families. The overall
processoffeaturevectorconstructionisillustratedinfigure3.
It is worth noting that the date of the communicating files
is used during file extraction. In our environment, VirusTo-
tal provides the date when the malicious file was scanned
(i.e. executed) and communicated with the observed domain.
In the experiments, we extracted the communicating files
for each domain for a period corresponding to the previous
2 years to remain up to date on malicious activities in case
this domain was used in other malicious activities in the
past. This was done because malicious campaign domains
can operate for periods ranging from several days to years,
especially when not identified. When operating in different
network environments where another data source is available
45248 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 3. An illustration of the construction of the feature vector.
for the communicating files (e.g. an AV vendor), it is possible
to redirect any communication from the malicious files to a
controlled server (e.g. using DNS configuration in a sandbox
environment), and to save the exact communication time.
Thesedatacanbeusedlatertofilteronlyup-to-datemalicious
file communications.
3) CLUSTERING
IMDoC uses these feature vectors to cluster malicious
domains, so that domains with similar histograms of com-
municating file malware families reside in the same cluster.
In this study, we used two clustering algorithms on the fea-
ture vectors: K-Means and DBSCAN. We chose these two
popularclusteringalgorithmsbecausetheybothrepresentdif-
ferent approaches when it comes to clustering. Specifically,
DBSCAN uses density-based clustering, while K-Means is
based on a distance metric from a centroid. Generally, one
approach can be superior to the other in different scenarios.
Note that in our experiments, we used DBSCAN with
an epsilon of 0.5 (which is the maximum distance between
two samples for one to be considered in the neighborhood
of the other) and a minimum threshold of 40 samples in a
neighborhood for a sample to be considered a core point.
The distance metric was the standard Euclidean distance.
In K-Means, we noted 9 clusters, which represented the num-
ber of malware campaigns in our experiments. Furthermore,
we have set the number of times the K-Means algorithm
runs with different centroid seeds to 50. Both algorithmic
implementations were taken from the scikit-learn Python
framework [51].
As a result of this stage, IMDoC obtains a set of clusters,
S ,
? S
1 ,S 2 ,...,S N B
? ,whereeachclusterS
i (i.e.,thedomain
seed) contains malicious domains from the same malware
campaignwhichisassociatedwithsimilarbehaviorofthetag
histogram of their communicating files.
B. THE EXPAND STAGE
Next, IMDoC performs the Expand stage, as illustrated
in Fig. 4. Specifically, for each domain d j ∈ S, IMDoC
utilizes the real network data to extract the set IP d j that
contains all the IPs resolved to this domain, for the time
period in question. Next, for each IP in IP d j IMDoC extracts
all the domains resolved to this IP. Finally, for each seed
S i , for each domain d j ∈ S i , a set
ˆ
D d j that contains all the
domainsresolvedtotheseIPsisobtained.Then,theset ˆ D S i =
n
ˆ
D d j ,d j ∈ S i
o
represents the set of all candidate domains for
domains in S i (i.e., each domain in
ˆ
D S i is a candidate to be
an expstores all the domain names that were resolved to the given IP
address (i.e., the domain name that resides in a pair with the
given IP address). This way we can obtain the domain names
that were resolved to the given IP address and then expand
our method to these domain names. Since we rely only on the
clients’ requests, it is possible that there are domain names
that are mapped to a specific IP address but were not queried
by the Quad9 clients and therefore would not appear in the
dataset. However, since Quad9 deals with heavy traffic, our
method still achieves sufficient and trusted data to continue
the expansion process. In our system, we do not use reverse
DNS records of IP addresses (i.e., PTR records). As a source
ofdata,ourwayofmappingIPaddressestoobservedresolved
domain names is more reliable and trusted than reverse DNS
queries since those are configured by the owner of the IP
address and may return any response, which may be false or
not up to date responses [52]. In our implementation, we rely
onlyonactualobservedresolutionsofIPaddressestodomain
namesandhencethereverseofthismappingismoreaccurate
than the reverse DNS protocol.
Another interesting approach to expanding each seed of
malicious domains is by querying the dataset or threat intelli-
gence service (i.e. VirusTotal) for the contacted domains for
each of the communicating files. This query can derive new
domains in the expansion process that may be malicious and
need to be checked. We did not use the communicating files
for the expansion stage in our experiments to avoid bias in
the next stage toward domains that reside solely in VirusTotal
and did not reside in our real-data environment (i.e. Quad 9),
since these domains may already be known to be malicious
and our goal is to expand our seed of known domains to
new undiscovered malicious domains. This allowed us to
better measure our proposed system on a real data network
environment.
C. THE PREDICT STAGE
Finally, in the Predict stage, IMDoC classifies each expanded
domain and relates it to one of the clusters. As a result
of the Predict stage, IMDoC obtains a label for each pre-
dicted domain, and uses these prediction labels to determine
whichmaliciouscampaign(i.e.cluster)thisdomainrelatesto.
When new domains are predicted to be part of the malicious
campaign, IMDoC creates a set of these domains, T, and
expands them as done for the seed domains. This process
cancontinuewhenevertherearemoredomainstoexpandand
predict, i.e. when T is not empty. When a domain is predicted
to be related to one of the malicious campaigns (i.e. cluster),
it is added to this malicious campaign domain set so that
the implemented prediction methods in IMDoC will consider
it in the upcoming decisions on new domains. The Predict
stage is divided into two different approaches, depending on
whether the domain has associated communicating files or
not, as detailed next.
1) COMMUNICATING FILES-BASED PREDICTION
Whenassociatedfilesexistforthecandidatedomain,IMDoC
constructs the feature vector of a domain as same as done
in the Train stage. This is based on the frequency of the
communicating malicious files’ malware families with the
observed domain. After constructing this feature vector, two
approaches can be taken to predict the class of expanded
domains. The first is to use the cluster centers, and assess
the distance from them in the feature space. The closest
cluster center (that exceeds a predefined threshold) becomes
the cluster the sample will reside in. This prediction method
coincides with the K-Means algorithm. The second is to
train a One Class Classifier for each cluster, and create an
ensemble method to choose which of the clusters fits the
best, or classifies this point as a noise point. This method
may be used with the clusters obtained from the DBSCAN
algorithm. Generally, one approach can be superior to the
other in different scenarios.
2) PREDICTION WITHOUT COMMUNICATING FILES
In the case, where associated files do not exist for the can-
didate domain, IMDoC uses a prediction method based on
DNS data, as presented in Algorithm 2 and explained next.
For each seed S i , for each candidate for the expanded domain
ˆ
d r ∈
ˆ
D S i , IMDoC identifies the last IP change (UDR record)
Algorithm 2 Prediction Using the Correlation From Time of
IP Change Event Used in IMDoC Algorithm
1: Y S i ← ∅
2: for ˆ d r ∈
ˆ
D S i do
3: t c ← TimeSeriesLastIPChange( ˆ d r )
4: for d j ∈ S i do
5: t s ← TimeSeriesLastIPChange(d j )
6: C c,s ← SpearmanCorrelation(t c ,t s )
7: if C c,s ≥ Thresh s then
8: Count( ˆ d r ) + +
9: end if
10: end for
11: if Count( ˆ d r ) ≥ Thresh c then
12: Y S i .append( ˆ d r )
13: end if
14: end for
45250 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
day that was observed, and constructs a time-frame, t c , of one
week starting from that day. This time-frame includes the
number of requests observed in the DSURF data for each
day in this time-frame. Next, IMDoC iterates each of the seed
domains d j ∈ S i , and creates the same time-frame t s from the
last IP change of the current observed seed domain. When
these two time-frames of one week are available, IMDoC
calculates a Spearman’s rank correlation coefficient between
the candidate domain and the current seed domain, C c,s .
The Spearman’s rank correlation coefficient is a nonpara-
metric measure of rank correlation that measures monotonic
relationships (whether linear or not) between two variables.
It has a value in the range [−1,+1], where a correlation
value of +1 is achieved when the two observed variables
have a similar rank and a correlation value of −1 indicates
that the observations have a dissimilar rank between the two
variables. Let a i , b i , i = 1,...,n, be a pair of variables with
n observations. The Spearman’s rank correlation coefficient
is defined by:
r S = 1 −
6
P n
i=1 d 2 i
n(n 2 − 1)
, (5)
where d i = rg(a i ) − rg(b i ), and rg(·) is the observation
rank [53]. The reason we chose this type of correlation over
the standard Pearson coefficient correlation is because the
Pearson coefficient correlation measures linear correlations
betweenvariablesandassumesthevariablesarenormallydis-
tributed. However, our observed variables may have different
characteristics from those noted, and can still be considered
correlated.
If the Spearman’s rank correlation coefficient value is
above a predetermined threshold (called the correlation
threshold and denoted as Thresh s ), IMDoC increments a
counter of the candidate domain, Count( ˆ d r ). When IMDoC
has calculated the correlation between the candidate domain
and all the seed domains, it observes the counter value for the
candidate domain. If this counter is above a predetermined
threshold (called the occurrence threshold and denoted by
Thresh c ), IMDoC considers this domain to be related to the
malware campaign, as represented by the seed domains, and
appends this domain to the set of predicted domains, Y S i .
The intuition for this method is based on analyzing com-
mon behaviors of malware campaigns. Domains from the
same malware campaign are more likely to be registered to
a new IP in the same time period. The IP change event repre-
sents the beginning of the specified domain in the observed
malware campaign operations. Therefore, the traffic since
this IP change event should fit the same rate pattern. Fig. 5
illustrates this behavior, and presents a histogram of the
queries observed for 5 domains from the Bayrob malware
campaign during the week after an IP change event occurred.
Practically, the method is split into 2 phases of training and
classification. In the first phase, we calculate the time-frames
since the last IP change of all seed domains and store them
in a seed time-frame database. The classification phase cor-
relates each given suspicious domain with all the domains in
FIGURE 5. An example of query patterns since the IP change of 5
domains from the Bayrob campaign.
FIGURE 6. An illustration of the training phase of the DNS-based method.
the seed. The training phase is presented in Fig. 6 and the
classification phase is presented in Fig. 7.
V. EVALUATION AND EXPERIMENTAL RESULTS
Weimplementedextensiveexperimentsinarealworkingpro-
duction environment to evaluate the performance of IMDoC
algorithm. The experiments conducted in a Quad9 DNS envi-
ronment consisted of DNS data derived from Quad9 Recur-
sive resolvers in the form of UDR and DSURF datasets,
as discussed in Subsection II-A. In the first experiment,
the initial data were a list of known malicious domains and
their related malware campaigns (i.e. their labels). The pur-
poseofthisexperimentwastoevaluatetheclusteringmethod,
where the feature vector for each domain was the histograms
of the domain communicating files’ malware families. In this
experiment,themaliciousdomainsweredividedintoclusters,
where each cluster represented a different malware campaign
and the results were verified against the given labels of the
domains in the different clusters.
In the next two experiments, our purpose was to evalu-
ate the expansion and prediction methods used in IMDoC
algorithm. In both experiments, one of the clusters was cho-
sen as a representative example. The aim of these experi-
ments was to identify new domains which did not appear
in the given malicious domain list, but were connected to
the malware campaign represented by the chosen cluster.
Both experiments use resolved IPs to expand the chosen
cluster of domains into new domains related to this cluster
VOLUME 9, 2021 45251
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 7. An illustration of the classification phase of DNS-based method.
(i.e. these two domains resolved to the same IP address
at some point in time). The main difference between these
phases was the method in IMDoC algorithm they were
designedtoevaluate.Thefirstfocusedonusingthecommuni-
cating files of each suspected domain together with machine
learning methods to decide whether this domain matched the
cluster characteristics, whereas the second focused on using
patterns of DNS requests of each suspected domain together
with statistical methods to determine whether this domain
matched the observed cluster. The methods also operated on
data with different characteristics. For the first, the domains
had observed communicating files, whereas in the second
the domains had suitable DNS data (i.e. UDR and DSURF
available data).
A. EVALUATION BY COMMUNICATING FILES-BASED
CLUSTERING
In this experiment, we manually selected 1846 domains from
9 different malware campaigns: Bayrob, Symmi, Fobber,
Virlock, Dircrypt, Locky, Tinba, Explosive, and Cryptowall,
as shown in Table 1.
TABLE 1. Number of malicious domains in each campaign.
The data were collected using threat intelligence sites pro-
viding malicious domains feeds, such as: OSINT Feeds -
Bambenek Consulting [42], Netlab OpenData Project [43],
AlienVault - Open Threat Exchange [44]. We collected
enoughsamplesforeachmalwarecampaign(morethan50)to
establish a robust notion of the domains operating within the
context of each malware campaign. Some of the domains did
not have DNS information in the UDR dataset or in Virus-
Total, but all the selected domains did have malicious files
FIGURE 8. The distribution of malware families for the Bayrob cluster.
communicating with them, which were extracted from Virus-
Total. As explained when presenting Algorithm 1, the com-
municating files for each of the inspected domains were
extracted using VirusTotal API and the AVClass tool was run
on each file to get the file’s associated malware family from
the VirusTotal AV engines. When all the files had an associ-
ated family, IMDoC algorithm constructed a malware family
distributionforeachdomainbasedontheassociatedmalware
families for each domain’s communicating malicious files.
After going over all the given malicious domains, IMDoC
algorithm clustered them based on the malware family dis-
tribution of each domain (the feature vectors, as explained
above). As a result, each cluster included malicious domains
with a similar malware family distribution. For example,
Fig. 8 shows the average malware family distribution for the
cluster related to the Bayrob malware campaign, where each
color represents a different malware family.
Importantly, in this experiment only malicious domains
have been considered since our system is expected to receive
a feed of malicious domains, where these domains are uncat-
egorized by malicious campaigns. IMDoC clusters these
45252 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 9. A comparison of real labels and clustering results.
domains based on their communicating files, which results
in several seeds for different malicious campaigns. In this
step, benign domains are irrelevant because each cluster con-
tains only malicious domains that are a part of a certain
malicious campaign. Therefore, in this experiment we only
used malicious domains to evaluate the clustering method
that will differentiate between domains that relate to different
malicious campaigns. This is considered our ground truth for
this model.
We evaluated two clustering algorithms in this experiment:
K-Means and DBSCAN, as discussed in Subsection IV-A3.
Bothimplementationswereusedfromthescikit-learnPython
framework [51]. The input provided to these algorithms was
the feature vectors mentioned above.
To measure the performance of the algorithms against
the real labels, we used several metrics: (i) Homogeneity:
each cluster only contained members of a certain class. The
value could be between 0 and 1, where 1 stands for perfect
homogeneous labeling; (ii) Completeness: all members of a
certain class were assigned to the same cluster. The value
couldbebetween0and1,where1standsforperfectcomplete
labeling; (iii) V-measure: the harmonic mean between the
homogeneity score and the completeness score ranging from
0 to 1, where 1 stands for perfect clustering in terms of
both homogeneity and completeness; (iv) Silhouette Coef-
ficient: a measure of how similar an object is to its own
cluster (cohesion) as compared to other clusters (separation).
The best value is +1 and the worst value is −1. This mea-
sures how well a clustering method performs. A score of +1
means that the clusters are well apart from each other and
can be easily distinguished. The Silhouette Coefficient can
be written as:
x−y
max(x,y) , where x is the average inter-cluster
distance (i.e. the average distance between all clusters), and y
is the intra-cluster distance (i.e. the average distance between
each point within a cluster). Achieving high values for the
metrics presented above indicates strong performance for an
algorithm. For DBSCAN we set an epsilon of 0.5 (which is
the maximum distance between two samples for one to be
considered in the neighborhood of the other), and a minimum
threshold of 40 samples in a neighborhood for which the
sampleisconsideredacorepoint.Thedistancemetricwasthe
standard Euclidean distance. For K-Means, we noted 9 clus-
ters, the same as the number of selected malware campaigns.
We set the number of times the K-Means algorithm ran with
different centroid seeds to 50. These parameters yielded the
best results for the above metrics.
The results of the evaluation metrics present strong per-
formance for the suggested methods, as shown in Table 2.
Figure 9 depicts the results of the clustering algorithms and
TABLE 2. Results for the suggested clustering algorithms.
VOLUME 9, 2021 45253
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 10. The confusion matrices of the clustering algorithms.
the comparison of the real labels to the clustering labels
provided by both methods. We used T-distributed Stochas-
tic Neighbor Embedding (T-SNE) for visualization by non-
linear dimensionality reduction, which enables embedding
high-dimensional data for visualization in a low-dimensional
space of two dimensions.
Furthermore, we evaluated the performance of the cluster-
ing algorithms as a multi-class classification problem, where
each class relates to a different malware campaign. The con-
fusion matrices presented in Fig. 10(b) show that for the
K-Meansclusteringalgorithm,allthesampleswereclassified
correctly except 5 from the Explosive malware campaign and
5fromtheCryptowallmalwarecampaignthatwereclassified
as belonging to the Dircrypt malware campaign. Fig. 10(a)
indicates that for the DBSCAN clustering algorithm, all sam-
ples were classified correctly except 16 from the Cryptowall
malware campaign that were classified as noise; i.e., not
compatible with any existing cluster.
B. COMMUNICATING FILES-BASED PREDICTION
METHODS
Inthesecondexperiment,weevaluatedthepredictionmethod
based on the domain’s communicating files. In this exper-
iment, IMDoC algorithm was used to expand one of the
clusters to find more malicious domains related to the same
malware campaign. We chose the cluster that contained the
Bayrob malware domains. Bayrob is a family of Trojans
that target the Windows platform. They can download and
launch additional modules from a C&C server. They can
also function as a proxy server. The malware is used to
send spam messages and steal user data. The family was
detected in 01/26/2017 and is still operating today [54]. Note
that the Bayrob malware uses DGA to generate the mali-
cious domains, which has been reverse engineered and fully
understood [55]. This means an exact answer can be given
when a domain is observed to be generated by this DGA.
In this experiment we used DGArchive [45], a site that
provides a convenient API to check whether a domain is
part of one of the DGAs of the malwares that reside in the
DGArchive database.
To expand this cluster, we first chose the period of time to
operate. Then, IMDoC algorithm iterated over the domains
contained in this cluster, extracted the IPs whose domains
were resolved in this period of time (there could be more
than one IP) and performed a reverse search over these IPs
to find the domains resolved to them in the defined period
of time. In this experiment, IMDoC algorithm used the pas-
sive DNS data in VirusTotal to acquire the data needed to
determine which domain name resolved to which IP address.
In this experiment, for the expansion we chose the time
period between 01/01/2018 and 01/06/2020. The 107 seed
domains related to the Bayrob malware were expanded using
the resolved IPs as stated above. This expansion process
yielded 94,942 expanded domains. Since the Bayrob DGA
only generates domains with a ‘‘net’’ TLD, we filtered the
result by the ‘‘net’’ TLD, and were left with 8,594 expanded
domains. Of these expanded domains, 1,335 were verified by
the DGArchive to be part of the Bayrob DGA. It is worth
noting that the 94,942 expanded domains did not result from
only 1 expansion process, but from several iterations of this
process over domains that were predicted to be related to this
malicious campaign. It used the prediction method described
below.
The expansion process yielded numerous domains which
were either benign or malicious but not related to the specific
malware campaign. Therefore, to find the domains which
were related to the observed malware campaign, for each
of the new domains derived from the expansion process,
45254 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 3. IMDoC prediction results for clustering by communicating files.
IMDoC algorithm extracted the communicating files of these
domains. Unlike the first experiment, it predicted which
domain was related to the observed cluster based on the
malicious file distribution to determine whether it matched
the malicious file distribution of the chosen cluster (Bayrob
malware campaign).
For the K-Means clustering method, this is fairly easy,
since we can see which of the classified cluster centers’ is
the closest in terms of Euclidean distance. If it is the cluster
related to the Bayrob malware campaign, IMDoC algorithm
tags this domain as related to this cluster and the expansion
process continues as described above on the next iteration of
the algorithm.
The procedure is more complex for the DBSCAN cluster-
ingmethod,becausethereisnobuilt-inpredictionmethodfor
thisdensity-basedclustering.Wecreatedaoneclassclassifier
(i.e.OneClassSVM)onthemaliciousfiledistributionsofthe
domains residing in the chosen cluster. When a new domain
derived from the expansion is tested, IMDoC algorithm aims
topredicttheclassofthisdomainwiththeoneclassclassifier,
and determines whether this domain relates to the malware
campaign based on the outcome. One can also expand this
functionality by running a one class classifier for each of the
clusters created by the DBSCAN algorithm and implement-
ing a voting method to determine the clusters to which the
new expanded domain should be assigned.
The results of both prediction methods are described
in Table 3. Using the K-Means prediction IMDoC algorithm
successfully expanded the seed of 107 malicious domains in
the Bayrob malware campaign cluster to 1,288 new domains
predicted to be part of the Bayrob malware campaign. Out of
these domains, 1,286 were verified to have been generated
from the Bayrob malware DGA by the DGArchive. This is a
significant expansion ratio of η ≈ 13. In terms of binary clas-
sification, this experiment resulted in 1,286 TP samples, 2 FP
samples, 7,257 TN samples and 49 FN samples. In addition
to the Precision and Recall scores defined in Subsection III,
we present the Accuracy score as follows:
A =
TP + TN
TP + FP + TN + FN
. (6)
IMDoC with K-Means prediction achieved an Accuracy
score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to lascore of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Ostores all the domain names that were resolved to the given IP
address (i.e., the domain name that resides in a pair with the
given IP address). This way we can obtain the domain names
that were resolved to the given IP address and then expand
our method to these domain names. Since we rely only on the
clients’ requests, it is possible that there are domain names
that are mapped to a specific IP address but were not queried
by the Quad9 clients and therefore would not appear in the
dataset. However, since Quad9 deals with heavy traffic, our
method still achieves sufficient and trusted data to continue
the expansion process. In our system, we do not use reverse
DNS records of IP addresses (i.e., PTR records). As a source
ofdata,ourwayofmappingIPaddressestoobservedresolved
domain names is more reliable and trusted than reverse DNS
queries since those are configured by the owner of the IP
address and may return any response, which may be false or
not up to date responses [52]. In our implementation, we rely
onlyonactualobservedresolutionsofIPaddressestodomain
namesandhencethereverseofthismappingismoreaccurate
than the reverse DNS protocol.
Another interesting approach to expanding each seed of
malicious domains is by querying the dataset or threat intelli-
gence service (i.e. VirusTotal) for the contacted domains for
each of the communicating files. This query can derive new
domains in the expansion process that may be malicious and
need to be checked. We did not use the communicating files
for the expansion stage in our experiments to avoid bias in
the next stage toward domains that reside solely in VirusTotal
and did not reside in our real-data environment (i.e. Quad 9),
since these domains may already be known to be malicious
and our goal is to expand our seed of known domains to
new undiscovered malicious domains. This allowed us to
better measure our proposed system on a real data network
environment.
C. THE PREDICT STAGE
Finally, in the Predict stage, IMDoC classifies each expanded
domain and relates it to one of the clusters. As a result
of the Predict stage, IMDoC obtains a label for each pre-
dicted domain, and uses these prediction labels to determine
whichmaliciouscampaign(i.e.cluster)thisdomainrelatesto.
When new domains are predicted to be part of the malicious
campaign, IMDoC creates a set of these domains, T, and
expands them as done for the seed domains. This process
cancontinuewhenevertherearemoredomainstoexpandand
predict, i.e. when T is not empty. When a domain is predicted
to be related to one of the malicious campaigns (i.e. cluster),
it is added to this malicious campaign domain set so that
the implemented prediction methods in IMDoC will consider
it in the upcoming decisions on new domains. The Predict
stage is divided into two different approaches, depending on
whether the domain has associated communicating files or
not, as detailed next.
1) COMMUNICATING FILES-BASED PREDICTION
Whenassociatedfilesexistforthecandidatedomain,IMDoC
constructs the feature vector of a domain as same as done
in the Train stage. This is based on the frequency of the
communicating malicious files’ malware families with the
observed domain. After constructing this feature vector, two
approaches can be taken to predict the class of expanded
domains. The first is to use the cluster centers, and assess
the distance from them in the feature space. The closest
cluster center (that exceeds a predefined threshold) becomes
the cluster the sample will reside in. This prediction method
coincides with the K-Means algorithm. The second is to
train a One Class Classifier for each cluster, and create an
ensemble method to choose which of the clusters fits the
best, or classifies this point as a noise point. This method
may be used with the clusters obtained from the DBSCAN
algorithm. Generally, one approach can be superior to the
other in different scenarios.
2) PREDICTION WITHOUT COMMUNICATING FILES
In the case, where associated files do not exist for the can-
didate domain, IMDoC uses a prediction method based on
DNS data, as presented in Algorithm 2 and explained next.
For each seed S i , for each candidate for the expanded domain
ˆ
d r ∈
ˆ
D S i , IMDoC identifies the last IP change (UDR record)
Algorithm 2 Prediction Using the Correlation From Time of
IP Change Event Used in IMDoC Algorithm
1: Y S i ← ∅
2: for ˆ d r ∈
ˆ
D S i do
3: t c ← TimeSeriesLastIPChange( ˆ d r )
4: for d j ∈ S i do
5: t s ← TimeSeriesLastIPChange(d j )
6: C c,s ← SpearmanCorrelation(t c ,t s )
7: if C c,s ≥ Thresh s then
8: Count( ˆ d r ) + +
9: end if
10: end for
11: if Count( ˆ d r ) ≥ Thresh c then
12: Y S i .append( ˆ d r )
13: end if
14: end for
45250 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
day that was observed, and constructs a time-frame, t c , of one
week starting from that day. This time-frame includes the
number of requests observed in the DSURF data for each
day in this time-frame. Next, IMDoC iterates each of the seed
domains d j ∈ S i , and creates the same time-frame t s from the
last IP change of the current observed seed domain. When
these two time-frames of one week are available, IMDoC
calculates a Spearman’s rank correlation coefficient between
the candidate domain and the current seed domain, C c,s .
The Spearman’s rank correlation coefficient is a nonpara-
metric measure of rank correlation that measures monotonic
relationships (whether linear or not) between two variables.
It has a value in the range [−1,+1], where a correlation
value of +1 is achieved when the two observed variables
have a similar rank and a correlation value of −1 indicates
that the observations have a dissimilar rank between the two
variables. Let a i , b i , i = 1,...,n, be a pair of variables with
n observations. The Spearman’s rank correlation coefficient
is defined by:
r S = 1 −
6
P n
i=1 d 2 i
n(n 2 − 1)
, (5)
where d i = rg(a i ) − rg(b i ), and rg(·) is the observation
rank [53]. The reason we chose this type of correlation over
the standard Pearson coefficient correlation is because the
Pearson coefficient correlation measures linear correlations
betweenvariablesandassumesthevariablesarenormallydis-
tributed. However, our observed variables may have different
characteristics from those noted, and can still be considered
correlated.
If the Spearman’s rank correlation coefficient value is
above a predetermined threshold (called the correlation
threshold and denoted as Thresh s ), IMDoC increments a
counter of the candidate domain, Count( ˆ d r ). When IMDoC
has calculated the correlation between the candidate domain
and all the seed domains, it observes the counter value for the
candidate domain. If this counter is above a predetermined
threshold (called the occurrence threshold and denoted by
Thresh c ), IMDoC considers this domain to be related to the
malware campaign, as represented by the seed domains, and
appends this domain to the set of predicted domains, Y S i .
The intuition for this method is based on analyzing com-
mon behaviors of malware campaigns. Domains from the
same malware campaign are more likely to be registered to
a new IP in the same time period. The IP change event repre-
sents the beginning of the specified domain in the observed
malware campaign operations. Therefore, the traffic since
this IP change event should fit the same rate pattern. Fig. 5
illustrates this behavior, and presents a histogram of the
queries observed for 5 domains from the Bayrob malware
campaign during the week after an IP change event occurred.
Practically, the method is split into 2 phases of training and
classification. In the first phase, we calculate the time-frames
since the last IP change of all seed domains and store them
in a seed time-frame database. The classification phase cor-
relates each given suspicious domain with all the domains in
FIGURE 5. An example of query patterns since the IP change of 5
domains from the Bayrob campaign.
FIGURE 6. An illustration of the training phase of the DNS-based method.
the seed. The training phase is presented in Fig. 6 and the
classification phase is presented in Fig. 7.
V. EVALUATION AND EXPERIMENTAL RESULTS
Weimplementedextensiveexperimentsinarealworkingpro-
duction environment to evaluate the performance of IMDoC
algorithm. The experiments conducted in a Quad9 DNS envi-
ronment consisted of DNS data derived from Quad9 Recur-
sive resolvers in the form of UDR and DSURF datasets,
as discussed in Subsection II-A. In the first experiment,
the initial data were a list of known malicious domains and
their related malware campaigns (i.e. their labels). The pur-
poseofthisexperimentwastoevaluatetheclusteringmethod,
where the feature vector for each domain was the histograms
of the domain communicating files’ malware families. In this
experiment,themaliciousdomainsweredividedintoclusters,
where each cluster represented a different malware campaign
and the results were verified against the given labels of the
domains in the different clusters.
In the next two experiments, our purpose was to evalu-
ate the expansion and prediction methods used in IMDoC
algorithm. In both experiments, one of the clusters was cho-
sen as a representative example. The aim of these experi-
ments was to identify new domains which did not appear
in the given malicious domain list, but were connected to
the malware campaign represented by the chosen cluster.
Both experiments use resolved IPs to expand the chosen
cluster of domains into new domains related to this cluster
VOLUME 9, 2021 45251
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 7. An illustration of the classification phase of DNS-based method.
(i.e. these two domains resolved to the same IP address
at some point in time). The main difference between these
phases was the method in IMDoC algorithm they were
designedtoevaluate.Thefirstfocusedonusingthecommuni-
cating files of each suspected domain together with machine
learning methods to decide whether this domain matched the
cluster characteristics, whereas the second focused on using
patterns of DNS requests of each suspected domain together
with statistical methods to determine whether this domain
matched the observed cluster. The methods also operated on
data with different characteristics. For the first, the domains
had observed communicating files, whereas in the second
the domains had suitable DNS data (i.e. UDR and DSURF
available data).
A. EVALUATION BY COMMUNICATING FILES-BASED
CLUSTERING
In this experiment, we manually selected 1846 domains from
9 different malware campaigns: Bayrob, Symmi, Fobber,
Virlock, Dircrypt, Locky, Tinba, Explosive, and Cryptowall,
as shown in Table 1.
TABLE 1. Number of malicious domains in each campaign.
The data were collected using threat intelligence sites pro-
viding malicious domains feeds, such as: OSINT Feeds -
Bambenek Consulting [42], Netlab OpenData Project [43],
AlienVault - Open Threat Exchange [44]. We collected
enoughsamplesforeachmalwarecampaign(morethan50)to
establish a robust notion of the domains operating within the
context of each malware campaign. Some of the domains did
not have DNS information in the UDR dataset or in Virus-
Total, but all the selected domains did have malicious files
FIGURE 8. The distribution of malware families for the Bayrob cluster.
communicating with them, which were extracted from Virus-
Total. As explained when presenting Algorithm 1, the com-
municating files for each of the inspected domains were
extracted using VirusTotal API and the AVClass tool was run
on each file to get the file’s associated malware family from
the VirusTotal AV engines. When all the files had an associ-
ated family, IMDoC algorithm constructed a malware family
distributionforeachdomainbasedontheassociatedmalware
families for each domain’s communicating malicious files.
After going over all the given malicious domains, IMDoC
algorithm clustered them based on the malware family dis-
tribution of each domain (the feature vectors, as explained
above). As a result, each cluster included malicious domains
with a similar malware family distribution. For example,
Fig. 8 shows the average malware family distribution for the
cluster related to the Bayrob malware campaign, where each
color represents a different malware family.
Importantly, in this experiment only malicious domains
have been considered since our system is expected to receive
a feed of malicious domains, where these domains are uncat-
egorized by malicious campaigns. IMDoC clusters these
45252 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 9. A comparison of real labels and clustering results.
domains based on their communicating files, which results
in several seeds for different malicious campaigns. In this
step, benign domains are irrelevant because each cluster con-
tains only malicious domains that are a part of a certain
malicious campaign. Therefore, in this experiment we only
used malicious domains to evaluate the clustering method
that will differentiate between domains that relate to different
malicious campaigns. This is considered our ground truth for
this model.
We evaluated two clustering algorithms in this experiment:
K-Means and DBSCAN, as discussed in Subsection IV-A3.
Bothimplementationswereusedfromthescikit-learnPython
framework [51]. The input provided to these algorithms was
the feature vectors mentioned above.
To measure the performance of the algorithms against
the real labels, we used several metrics: (i) Homogeneity:
each cluster only contained members of a certain class. The
value could be between 0 and 1, where 1 stands for perfect
homogeneous labeling; (ii) Completeness: all members of a
certain class were assigned to the same cluster. The value
couldbebetween0and1,where1standsforperfectcomplete
labeling; (iii) V-measure: the harmonic mean between the
homogeneity score and the completeness score ranging from
0 to 1, where 1 stands for perfect clustering in terms of
both homogeneity and completeness; (iv) Silhouette Coef-
ficient: a measure of how similar an object is to its own
cluster (cohesion) as compared to other clusters (separation).
The best value is +1 and the worst value is −1. This mea-
sures how well a clustering method performs. A score of +1
means that the clusters are well apart from each other and
can be easily distinguished. The Silhouette Coefficient can
be written as:
x−y
max(x,y) , where x is the average inter-cluster
distance (i.e. the average distance between all clusters), and y
is the intra-cluster distance (i.e. the average distance between
each point within a cluster). Achieving high values for the
metrics presented above indicates strong performance for an
algorithm. For DBSCAN we set an epsilon of 0.5 (which is
the maximum distance between two samples for one to be
considered in the neighborhood of the other), and a minimum
threshold of 40 samples in a neighborhood for which the
sampleisconsideredacorepoint.Thedistancemetricwasthe
standard Euclidean distance. For K-Means, we noted 9 clus-
ters, the same as the number of selected malware campaigns.
We set the number of times the K-Means algorithm ran with
different centroid seeds to 50. These parameters yielded the
best results for the above metrics.
The results of the evaluation metrics present strong per-
formance for the suggested methods, as shown in Table 2.
Figure 9 depicts the results of the clustering algorithms and
TABLE 2. Results for the suggested clustering algorithms.
VOLUME 9, 2021 45253
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 10. The confusion matrices of the clustering algorithms.
the comparison of the real labels to the clustering labels
provided by both methods. We used T-distributed Stochas-
tic Neighbor Embedding (T-SNE) for visualization by non-
linear dimensionality reduction, which enables embedding
high-dimensional data for visualization in a low-dimensional
space of two dimensions.
Furthermore, we evaluated the performance of the cluster-
ing algorithms as a multi-class classification problem, where
each class relates to a different malware campaign. The con-
fusion matrices presented in Fig. 10(b) show that for the
K-Meansclusteringalgorithm,allthesampleswereclassified
correctly except 5 from the Explosive malware campaign and
5fromtheCryptowallmalwarecampaignthatwereclassified
as belonging to the Dircrypt malware campaign. Fig. 10(a)
indicates that for the DBSCAN clustering algorithm, all sam-
ples were classified correctly except 16 from the Cryptowall
malware campaign that were classified as noise; i.e., not
compatible with any existing cluster.
B. COMMUNICATING FILES-BASED PREDICTION
METHODS
Inthesecondexperiment,weevaluatedthepredictionmethod
based on the domain’s communicating files. In this exper-
iment, IMDoC algorithm was used to expand one of the
clusters to find more malicious domains related to the same
malware campaign. We chose the cluster that contained the
Bayrob malware domains. Bayrob is a family of Trojans
that target the Windows platform. They can download and
launch additional modules from a C&C server. They can
also function as a proxy server. The malware is used to
send spam messages and steal user data. The family was
detected in 01/26/2017 and is still operating today [54]. Note
that the Bayrob malware uses DGA to generate the mali-
cious domains, which has been reverse engineered and fully
understood [55]. This means an exact answer can be given
when a domain is observed to be generated by this DGA.
In this experiment we used DGArchive [45], a site that
provides a convenient API to check whether a domain is
part of one of the DGAs of the malwares that reside in the
DGArchive database.
To expand this cluster, we first chose the period of time to
operate. Then, IMDoC algorithm iterated over the domains
contained in this cluster, extracted the IPs whose domains
were resolved in this period of time (there could be more
than one IP) and performed a reverse search over these IPs
to find the domains resolved to them in the defined period
of time. In this experiment, IMDoC algorithm used the pas-
sive DNS data in VirusTotal to acquire the data needed to
determine which domain name resolved to which IP address.
In this experiment, for the expansion we chose the time
period between 01/01/2018 and 01/06/2020. The 107 seed
domains related to the Bayrob malware were expanded using
the resolved IPs as stated above. This expansion process
yielded 94,942 expanded domains. Since the Bayrob DGA
only generates domains with a ‘‘net’’ TLD, we filtered the
result by the ‘‘net’’ TLD, and were left with 8,594 expanded
domains. Of these expanded domains, 1,335 were verified by
the DGArchive to be part of the Bayrob DGA. It is worth
noting that the 94,942 expanded domains did not result from
only 1 expansion process, but from several iterations of this
process over domains that were predicted to be related to this
malicious campaign. It used the prediction method described
below.
The expansion process yielded numerous domains which
were either benign or malicious but not related to the specific
malware campaign. Therefore, to find the domains which
were related to the observed malware campaign, for each
of the new domains derived from the expansion process,
45254 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 3. IMDoC prediction results for clustering by communicating files.
IMDoC algorithm extracted the communicating files of these
domains. Unlike the first experiment, it predicted which
domain was related to the observed cluster based on the
malicious file distribution to determine whether it matched
the malicious file distribution of the chosen cluster (Bayrob
malware campaign).
For the K-Means clustering method, this is fairly easy,
since we can see which of the classified cluster centers’ is
the closest in terms of Euclidean distance. If it is the cluster
related to the Bayrob malware campaign, IMDoC algorithm
tags this domain as related to this cluster and the expansion
process continues as described above on the next iteration of
the algorithm.
The procedure is more complex for the DBSCAN cluster-
ingmethod,becausethereisnobuilt-inpredictionmethodfor
thisdensity-basedclustering.Wecreatedaoneclassclassifier
(i.e.OneClassSVM)onthemaliciousfiledistributionsofthe
domains residing in the chosen cluster. When a new domain
derived from the expansion is tested, IMDoC algorithm aims
topredicttheclassofthisdomainwiththeoneclassclassifier,
and determines whether this domain relates to the malware
campaign based on the outcome. One can also expand this
functionality by running a one class classifier for each of the
clusters created by the DBSCAN algorithm and implement-
ing a voting method to determine the clusters to which the
new expanded domain should be assigned.
The results of both prediction methods are described
in Table 3. Using the K-Means prediction IMDoC algorithm
successfully expanded the seed of 107 malicious domains in
the Bayrob malware campaign cluster to 1,288 new domains
predicted to be part of the Bayrob malware campaign. Out of
these domains, 1,286 were verified to have been generated
from the Bayrob malware DGA by the DGArchive. This is a
significant expansion ratio of η ≈ 13. In terms of binary clas-
sification, this experiment resulted in 1,286 TP samples, 2 FP
samples, 7,257 TN samples and 49 FN samples. In addition
to the Precision and Recall scores defined in Subsection III,
we present the Accuracy score as follows:
A =
TP + TN
TP + FP + TN + FN
. (6)
IMDoC with K-Means prediction achieved an Accuracy
score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to lascore of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Pstores all the domain names that were resolved to the given IP
address (i.e., the domain name that resides in a pair with the
given IP address). This way we can obtain the domain names
that were resolved to the given IP address and then expand
our method to these domain names. Since we rely only on the
clients’ requests, it is possible that there are domain names
that are mapped to a specific IP address but were not queried
by the Quad9 clients and therefore would not appear in the
dataset. However, since Quad9 deals with heavy traffic, our
method still achieves sufficient and trusted data to continue
the expansion process. In our system, we do not use reverse
DNS records of IP addresses (i.e., PTR records). As a source
ofdata,ourwayofmappingIPaddressestoobservedresolved
domain names is more reliable and trusted than reverse DNS
queries since those are configured by the owner of the IP
address and may return any response, which may be false or
not up to date responses [52]. In our implementation, we rely
onlyonactualobservedresolutionsofIPaddressestodomain
namesandhencethereverseofthismappingismoreaccurate
than the reverse DNS protocol.
Another interesting approach to expanding each seed of
malicious domains is by querying the dataset or threat intelli-
gence service (i.e. VirusTotal) for the contacted domains for
each of the communicating files. This query can derive new
domains in the expansion process that may be malicious and
need to be checked. We did not use the communicating files
for the expansion stage in our experiments to avoid bias in
the next stage toward domains that reside solely in VirusTotal
and did not reside in our real-data environment (i.e. Quad 9),
since these domains may already be known to be malicious
and our goal is to expand our seed of known domains to
new undiscovered malicious domains. This allowed us to
better measure our proposed system on a real data network
environment.
C. THE PREDICT STAGE
Finally, in the Predict stage, IMDoC classifies each expanded
domain and relates it to one of the clusters. As a result
of the Predict stage, IMDoC obtains a label for each pre-
dicted domain, and uses these prediction labels to determine
whichmaliciouscampaign(i.e.cluster)thisdomainrelatesto.
When new domains are predicted to be part of the malicious
campaign, IMDoC creates a set of these domains, T, and
expands them as done for the seed domains. This process
cancontinuewhenevertherearemoredomainstoexpandand
predict, i.e. when T is not empty. When a domain is predicted
to be related to one of the malicious campaigns (i.e. cluster),
it is added to this malicious campaign domain set so that
the implemented prediction methods in IMDoC will consider
it in the upcoming decisions on new domains. The Predict
stage is divided into two different approaches, depending on
whether the domain has associated communicating files or
not, as detailed next.
1) COMMUNICATING FILES-BASED PREDICTION
Whenassociatedfilesexistforthecandidatedomain,IMDoC
constructs the feature vector of a domain as same as done
in the Train stage. This is based on the frequency of the
communicating malicious files’ malware families with the
observed domain. After constructing this feature vector, two
approaches can be taken to predict the class of expanded
domains. The first is to use the cluster centers, and assess
the distance from them in the feature space. The closest
cluster center (that exceeds a predefined threshold) becomes
the cluster the sample will reside in. This prediction method
coincides with the K-Means algorithm. The second is to
train a One Class Classifier for each cluster, and create an
ensemble method to choose which of the clusters fits the
best, or classifies this point as a noise point. This method
may be used with the clusters obtained from the DBSCAN
algorithm. Generally, one approach can be superior to the
other in different scenarios.
2) PREDICTION WITHOUT COMMUNICATING FILES
In the case, where associated files do not exist for the can-
didate domain, IMDoC uses a prediction method based on
DNS data, as presented in Algorithm 2 and explained next.
For each seed S i , for each candidate for the expanded domain
ˆ
d r ∈
ˆ
D S i , IMDoC identifies the last IP change (UDR record)
Algorithm 2 Prediction Using the Correlation From Time of
IP Change Event Used in IMDoC Algorithm
1: Y S i ← ∅
2: for ˆ d r ∈
ˆ
D S i do
3: t c ← TimeSeriesLastIPChange( ˆ d r )
4: for d j ∈ S i do
5: t s ← TimeSeriesLastIPChange(d j )
6: C c,s ← SpearmanCorrelation(t c ,t s )
7: if C c,s ≥ Thresh s then
8: Count( ˆ d r ) + +
9: end if
10: end for
11: if Count( ˆ d r ) ≥ Thresh c then
12: Y S i .append( ˆ d r )
13: end if
14: end for
45250 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
day that was observed, and constructs a time-frame, t c , of one
week starting from that day. This time-frame includes the
number of requests observed in the DSURF data for each
day in this time-frame. Next, IMDoC iterates each of the seed
domains d j ∈ S i , and creates the same time-frame t s from the
last IP change of the current observed seed domain. When
these two time-frames of one week are available, IMDoC
calculates a Spearman’s rank correlation coefficient between
the candidate domain and the current seed domain, C c,s .
The Spearman’s rank correlation coefficient is a nonpara-
metric measure of rank correlation that measures monotonic
relationships (whether linear or not) between two variables.
It has a value in the range [−1,+1], where a correlation
value of +1 is achieved when the two observed variables
have a similar rank and a correlation value of −1 indicates
that the observations have a dissimilar rank between the two
variables. Let a i , b i , i = 1,...,n, be a pair of variables with
n observations. The Spearman’s rank correlation coefficient
is defined by:
r S = 1 −
6
P n
i=1 d 2 i
n(n 2 − 1)
, (5)
where d i = rg(a i ) − rg(b i ), and rg(·) is the observation
rank [53]. The reason we chose this type of correlation over
the standard Pearson coefficient correlation is because the
Pearson coefficient correlation measures linear correlations
betweenvariablesandassumesthevariablesarenormallydis-
tributed. However, our observed variables may have different
characteristics from those noted, and can still be considered
correlated.
If the Spearman’s rank correlation coefficient value is
above a predetermined threshold (called the correlation
threshold and denoted as Thresh s ), IMDoC increments a
counter of the candidate domain, Count( ˆ d r ). When IMDoC
has calculated the correlation between the candidate domain
and all the seed domains, it observes the counter value for the
candidate domain. If this counter is above a predetermined
threshold (called the occurrence threshold and denoted by
Thresh c ), IMDoC considers this domain to be related to the
malware campaign, as represented by the seed domains, and
appends this domain to the set of predicted domains, Y S i .
The intuition for this method is based on analyzing com-
mon behaviors of malware campaigns. Domains from the
same malware campaign are more likely to be registered to
a new IP in the same time period. The IP change event repre-
sents the beginning of the specified domain in the observed
malware campaign operations. Therefore, the traffic since
this IP change event should fit the same rate pattern. Fig. 5
illustrates this behavior, and presents a histogram of the
queries observed for 5 domains from the Bayrob malware
campaign during the week after an IP change event occurred.
Practically, the method is split into 2 phases of training and
classification. In the first phase, we calculate the time-frames
since the last IP change of all seed domains and store them
in a seed time-frame database. The classification phase cor-
relates each given suspicious domain with all the domains in
FIGURE 5. An example of query patterns since the IP change of 5
domains from the Bayrob campaign.
FIGURE 6. An illustration of the training phase of the DNS-based method.
the seed. The training phase is presented in Fig. 6 and the
classification phase is presented in Fig. 7.
V. EVALUATION AND EXPERIMENTAL RESULTS
Weimplementedextensiveexperimentsinarealworkingpro-
duction environment to evaluate the performance of IMDoC
algorithm. The experiments conducted in a Quad9 DNS envi-
ronment consisted of DNS data derived from Quad9 Recur-
sive resolvers in the form of UDR and DSURF datasets,
as discussed in Subsection II-A. In the first experiment,
the initial data were a list of known malicious domains and
their related malware campaigns (i.e. their labels). The pur-
poseofthisexperimentwastoevaluatetheclusteringmethod,
where the feature vector for each domain was the histograms
of the domain communicating files’ malware families. In this
experiment,themaliciousdomainsweredividedintoclusters,
where each cluster represented a different malware campaign
and the results were verified against the given labels of the
domains in the different clusters.
In the next two experiments, our purpose was to evalu-
ate the expansion and prediction methods used in IMDoC
algorithm. In both experiments, one of the clusters was cho-
sen as a representative example. The aim of these experi-
ments was to identify new domains which did not appear
in the given malicious domain list, but were connected to
the malware campaign represented by the chosen cluster.
Both experiments use resolved IPs to expand the chosen
cluster of domains into new domains related to this cluster
VOLUME 9, 2021 45251
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 7. An illustration of the classification phase of DNS-based method.
(i.e. these two domains resolved to the same IP address
at some point in time). The main difference between these
phases was the method in IMDoC algorithm they were
designedtoevaluate.Thefirstfocusedonusingthecommuni-
cating files of each suspected domain together with machine
learning methods to decide whether this domain matched the
cluster characteristics, whereas the second focused on using
patterns of DNS requests of each suspected domain together
with statistical methods to determine whether this domain
matched the observed cluster. The methods also operated on
data with different characteristics. For the first, the domains
had observed communicating files, whereas in the second
the domains had suitable DNS data (i.e. UDR and DSURF
available data).
A. EVALUATION BY COMMUNICATING FILES-BASED
CLUSTERING
In this experiment, we manually selected 1846 domains from
9 different malware campaigns: Bayrob, Symmi, Fobber,
Virlock, Dircrypt, Locky, Tinba, Explosive, and Cryptowall,
as shown in Table 1.
TABLE 1. Number of malicious domains in each campaign.
The data were collected using threat intelligence sites pro-
viding malicious domains feeds, such as: OSINT Feeds -
Bambenek Consulting [42], Netlab OpenData Project [43],
AlienVault - Open Threat Exchange [44]. We collected
enoughsamplesforeachmalwarecampaign(morethan50)to
establish a robust notion of the domains operating within the
context of each malware campaign. Some of the domains did
not have DNS information in the UDR dataset or in Virus-
Total, but all the selected domains did have malicious files
FIGURE 8. The distribution of malware families for the Bayrob cluster.
communicating with them, which were extracted from Virus-
Total. As explained when presenting Algorithm 1, the com-
municating files for each of the inspected domains were
extracted using VirusTotal API and the AVClass tool was run
on each file to get the file’s associated malware family from
the VirusTotal AV engines. When all the files had an associ-
ated family, IMDoC algorithm constructed a malware family
distributionforeachdomainbasedontheassociatedmalware
families for each domain’s communicating malicious files.
After going over all the given malicious domains, IMDoC
algorithm clustered them based on the malware family dis-
tribution of each domain (the feature vectors, as explained
above). As a result, each cluster included malicious domains
with a similar malware family distribution. For example,
Fig. 8 shows the average malware family distribution for the
cluster related to the Bayrob malware campaign, where each
color represents a different malware family.
Importantly, in this experiment only malicious domains
have been considered since our system is expected to receive
a feed of malicious domains, where these domains are uncat-
egorized by malicious campaigns. IMDoC clusters these
45252 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 9. A comparison of real labels and clustering results.
domains based on their communicating files, which results
in several seeds for different malicious campaigns. In this
step, benign domains are irrelevant because each cluster con-
tains only malicious domains that are a part of a certain
malicious campaign. Therefore, in this experiment we only
used malicious domains to evaluate the clustering method
that will differentiate between domains that relate to different
malicious campaigns. This is considered our ground truth for
this model.
We evaluated two clustering algorithms in this experiment:
K-Means and DBSCAN, as discussed in Subsection IV-A3.
Bothimplementationswereusedfromthescikit-learnPython
framework [51]. The input provided to these algorithms was
the feature vectors mentioned above.
To measure the performance of the algorithms against
the real labels, we used several metrics: (i) Homogeneity:
each cluster only contained members of a certain class. The
value could be between 0 and 1, where 1 stands for perfect
homogeneous labeling; (ii) Completeness: all members of a
certain class were assigned to the same cluster. The value
couldbebetween0and1,where1standsforperfectcomplete
labeling; (iii) V-measure: the harmonic mean between the
homogeneity score and the completeness score ranging from
0 to 1, where 1 stands for perfect clustering in terms of
both homogeneity and completeness; (iv) Silhouette Coef-
ficient: a measure of how similar an object is to its own
cluster (cohesion) as compared to other clusters (separation).
The best value is +1 and the worst value is −1. This mea-
sures how well a clustering method performs. A score of +1
means that the clusters are well apart from each other and
can be easily distinguished. The Silhouette Coefficient can
be written as:
x−y
max(x,y) , where x is the average inter-cluster
distance (i.e. the average distance between all clusters), and y
is the intra-cluster distance (i.e. the average distance between
each point within a cluster). Achieving high values for the
metrics presented above indicates strong performance for an
algorithm. For DBSCAN we set an epsilon of 0.5 (which is
the maximum distance between two samples for one to be
considered in the neighborhood of the other), and a minimum
threshold of 40 samples in a neighborhood for which the
sampleisconsideredacorepoint.Thedistancemetricwasthe
standard Euclidean distance. For K-Means, we noted 9 clus-
ters, the same as the number of selected malware campaigns.
We set the number of times the K-Means algorithm ran with
different centroid seeds to 50. These parameters yielded the
best results for the above metrics.
The results of the evaluation metrics present strong per-
formance for the suggested methods, as shown in Table 2.
Figure 9 depicts the results of the clustering algorithms and
TABLE 2. Results for the suggested clustering algorithms.
VOLUME 9, 2021 45253
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 10. The confusion matrices of the clustering algorithms.
the comparison of the real labels to the clustering labels
provided by both methods. We used T-distributed Stochas-
tic Neighbor Embedding (T-SNE) for visualization by non-
linear dimensionality reduction, which enables embedding
high-dimensional data for visualization in a low-dimensional
space of two dimensions.
Furthermore, we evaluated the performance of the cluster-
ing algorithms as a multi-class classification problem, where
each class relates to a different malware campaign. The con-
fusion matrices presented in Fig. 10(b) show that for the
K-Meansclusteringalgorithm,allthesampleswereclassified
correctly except 5 from the Explosive malware campaign and
5fromtheCryptowallmalwarecampaignthatwereclassified
as belonging to the Dircrypt malware campaign. Fig. 10(a)
indicates that for the DBSCAN clustering algorithm, all sam-
ples were classified correctly except 16 from the Cryptowall
malware campaign that were classified as noise; i.e., not
compatible with any existing cluster.
B. COMMUNICATING FILES-BASED PREDICTION
METHODS
Inthesecondexperiment,weevaluatedthepredictionmethod
based on the domain’s communicating files. In this exper-
iment, IMDoC algorithm was used to expand one of the
clusters to find more malicious domains related to the same
malware campaign. We chose the cluster that contained the
Bayrob malware domains. Bayrob is a family of Trojans
that target the Windows platform. They can download and
launch additional modules from a C&C server. They can
also function as a proxy server. The malware is used to
send spam messages and steal user data. The family was
detected in 01/26/2017 and is still operating today [54]. Note
that the Bayrob malware uses DGA to generate the mali-
cious domains, which has been reverse engineered and fully
understood [55]. This means an exact answer can be given
when a domain is observed to be generated by this DGA.
In this experiment we used DGArchive [45], a site that
provides a convenient API to check whether a domain is
part of one of the DGAs of the malwares that reside in the
DGArchive database.
To expand this cluster, we first chose the period of time to
operate. Then, IMDoC algorithm iterated over the domains
contained in this cluster, extracted the IPs whose domains
were resolved in this period of time (there could be more
than one IP) and performed a reverse search over these IPs
to find the domains resolved to them in the defined period
of time. In this experiment, IMDoC algorithm used the pas-
sive DNS data in VirusTotal to acquire the data needed to
determine which domain name resolved to which IP address.
In this experiment, for the expansion we chose the time
period between 01/01/2018 and 01/06/2020. The 107 seed
domains related to the Bayrob malware were expanded using
the resolved IPs as stated above. This expansion process
yielded 94,942 expanded domains. Since the Bayrob DGA
only generates domains with a ‘‘net’’ TLD, we filtered the
result by the ‘‘net’’ TLD, and were left with 8,594 expanded
domains. Of these expanded domains, 1,335 were verified by
the DGArchive to be part of the Bayrob DGA. It is worth
noting that the 94,942 expanded domains did not result from
only 1 expansion process, but from several iterations of this
process over domains that were predicted to be related to this
malicious campaign. It used the prediction method described
below.
The expansion process yielded numerous domains which
were either benign or malicious but not related to the specific
malware campaign. Therefore, to find the domains which
were related to the observed malware campaign, for each
of the new domains derived from the expansion process,
45254 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 3. IMDoC prediction results for clustering by communicating files.
IMDoC algorithm extracted the communicating files of these
domains. Unlike the first experiment, it predicted which
domain was related to the observed cluster based on the
malicious file distribution to determine whether it matched
the malicious file distribution of the chosen cluster (Bayrob
malware campaign).
For the K-Means clustering method, this is fairly easy,
since we can see which of the classified cluster centers’ is
the closest in terms of Euclidean distance. If it is the cluster
related to the Bayrob malware campaign, IMDoC algorithm
tags this domain as related to this cluster and the expansion
process continues as described above on the next iteration of
the algorithm.
The procedure is more complex for the DBSCAN cluster-
ingmethod,becausethereisnobuilt-inpredictionmethodfor
thisdensity-basedclustering.Wecreatedaoneclassclassifier
(i.e.OneClassSVM)onthemaliciousfiledistributionsofthe
domains residing in the chosen cluster. When a new domain
derived from the expansion is tested, IMDoC algorithm aims
topredicttheclassofthisdomainwiththeoneclassclassifier,
and determines whether this domain relates to the malware
campaign based on the outcome. One can also expand this
functionality by running a one class classifier for each of the
clusters created by the DBSCAN algorithm and implement-
ing a voting method to determine the clusters to which the
new expanded domain should be assigned.
The results of both prediction methods are described
in Table 3. Using the K-Means prediction IMDoC algorithm
successfully expanded the seed of 107 malicious domains in
the Bayrob malware campaign cluster to 1,288 new domains
predicted to be part of the Bayrob malware campaign. Out of
these domains, 1,286 were verified to have been generated
from the Bayrob malware DGA by the DGArchive. This is a
significant expansion ratio of η ≈ 13. In terms of binary clas-
sification, this experiment resulted in 1,286 TP samples, 2 FP
samples, 7,257 TN samples and 49 FN samples. In addition
to the Precision and Recall scores defined in Subsection III,
we present the Accuracy score as follows:
A =
TP + TN
TP + FP + TN + FN
. (6)
IMDoC with K-Means prediction achieved an Accuracy
score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to lascore of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel 
mathematics and computer science from the Orecision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Oanded domain of seed S i ). This set of new domains is
derived from the real network data and contains domains that
may be related to one of the malicious campaigns.
Quad9 is a DNS recursive resolver and therefore its main
role is to answer the client queries with the appropriate
answers from the necessary authoritative name server. When
FIGURE 4. An illustration of the IP-based exanpsion stage.
VOLUME 9, 2021 45249
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
such an answer is received, specifically for the case of an ‘A’
or ‘AAAA’ DNS record, the Quad9 servers operate a passive
DNS inspection which stores the requested domain and also
the corresponding IP address answered by the authoritative
name server to the requested domain. As a result, Quad9, and
specifically the UDR dataset, stores pairs of domain name
to IP address, derived from the authoritative answers of ‘A’
and ‘AAAA’ DNS records for all the clients’yy requests.
It is important to emphasize that the records stored in this
dataset are only from authoritative DNS servers’ answers
and therefore can be trusted in security analysis. In order to
find the domain names mapped to a given IP address, which
will be used in the expansion phase, our system goes over
the aforementioned pairs of domain name to IP address and
stores all the domain names that were resolved to the given IP
address (i.e., the domain name that resides in a pair with the
given IP address). This way we can obtain the domain names
that were resolved to the given IP address and then expand
our method to these domain names. Since we rely only on the
clients’ requests, it is possible that there are domain names
that are mapped to a specific IP address but were not queried
by the Quad9 clients and therefore would not appear in the
dataset. However, since Quad9 deals with heavy traffic, our
method still achieves sufficient and trusted data to continue
the expansion process. In our system, we do not use reverse
DNS records of IP addresses (i.e., PTR records). As a source
ofdata,ourwayofmappingIPaddressestoobservedresolved
domain names is more reliable and trusted than reverse DNS
queries since those are configured by the owner of the IP
address and may return any response, which may be false or
not up to date responses [52]. In our implementation, we rely
onlyonactualobservedresolutionsofIPaddressestodomain
namesandhencethereverseofthismappingismoreaccurate
than the reverse DNS protocol.
Another interesting approach to expanding each seed of
malicious domains is by querying the dataset or threat intelli-
gence service (i.e. VirusTotal) for the contacted domains for
each of the communicating files. This query can derive new
domains in the expansion process that may be malicious and
need to be checked. We did not use the communicating files
for the expansion stage in our experiments to avoid bias in
the next stage toward domains that reside solely in VirusTotal
and did not reside in our real-data environment (i.e. Quad 9),
since these domains may already be known to be malicious
and our goal is to expand our seed of known domains to
new undiscovered malicious domains. This allowed us to
better measure our proposed system on a real data network
environment.
C. THE PREDICT STAGE
Finally, in the Predict stage, IMDoC classifies each expanded
domain and relates it to one of the clusters. As a result
of the Predict stage, IMDoC obtains a label for each pre-
dicted domain, and uses these prediction labels to determine
whichmaliciouscampaign(i.e.cluster)thisdomainrelatesto.
When new domains are predicted to be part of the malicious
campaign, IMDoC creates a set of these domains, T, and
expands them as done for the seed domains. This process
cancontinuewhenevertherearemoredomainstoexpandand
predict, i.e. when T is not empty. When a domain is predicted
to be related to one of the malicious campaigns (i.e. cluster),
it is added to this malicious campaign domain set so that
the implemented prediction methods in IMDoC will consider
it in the upcoming decisions on new domains. The Predict
stage is divided into two different approaches, depending on
whether the domain has associated communicating files or
not, as detailed next.
1) COMMUNICATING FILES-BASED PREDICTION
Whenassociatedfilesexistforthecandidatedomain,IMDoC
constructs the feature vector of a domain as same as done
in the Train stage. This is based on the frequency of the
communicating malicious files’ malware families with the
observed domain. After constructing this feature vector, two
approaches can be taken to predict the class of expanded
domains. The first is to use the cluster centers, and assess
the distance from them in the feature space. The closest
cluster center (that exceeds a predefined threshold) becomes
the cluster the sample will reside in. This prediction method
coincides with the K-Means algorithm. The second is to
train a One Class Classifier for each cluster, and create an
ensemble method to choose which of the clusters fits the
best, or classifies this point as a noise point. This method
may be used with the clusters obtained from the DBSCAN
algorithm. Generally, one approach can be superior to the
other in different scenarios.
2) PREDICTION WITHOUT COMMUNICATING FILES
In the case, where associated files do not exist for the can-
didate domain, IMDoC uses a prediction method based on
DNS data, as presented in Algorithm 2 and explained next.
For each seed S i , for each candidate for the expanded domain
ˆ
d r ∈
ˆ
D S i , IMDoC identifies the last IP change (UDR record)
Algorithm 2 Prediction Using the Correlation From Time of
IP Change Event Used in IMDoC Algorithm
1: Y S i ← ∅
2: for ˆ d r ∈
ˆ
D S i do
3: t c ← TimeSeriesLastIPChange( ˆ d r )
4: for d j ∈ S i do
5: t s ← TimeSeriesLastIPChange(d j )
6: C c,s ← SpearmanCorrelation(t c ,t s )
7: if C c,s ≥ Thresh s then
8: Count( ˆ d r ) + +
9: end if
10: end for
11: if Count( ˆ d r ) ≥ Thresh c then
12: Y S i .append( ˆ d r )
13: end if
14: end for
45250 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
day that was observed, and constructs a time-frame, t c , of one
week starting from that day. This time-frame includes the
number of requests observed in the DSURF data for each
day in this time-frame. Next, IMDoC iterates each of the seed
domains d j ∈ S i , and creates the same time-frame t s from the
last IP change of the current observed seed domain. When
these two time-frames of one week are available, IMDoC
calculates a Spearman’s rank correlation coefficient between
the candidate domain and the current seed domain, C c,s .
The Spearman’s rank correlation coefficient is a nonpara-
metric measure of rank correlation that measures monotonic
relationships (whether linear or not) between two variables.
It has a value in the range [−1,+1], where a correlation
value of +1 is achieved when the two observed variables
have a similar rank and a correlation value of −1 indicates
that the observations have a dissimilar rank between the two
variables. Let a i , b i , i = 1,...,n, be a pair of variables with
n observations. The Spearman’s rank correlation coefficient
is defined by:
r S = 1 −
6
P n
i=1 d 2 i
n(n 2 − 1)
, (5)
where d i = rg(a i ) − rg(b i ), and rg(·) is the observation
rank [53]. The reason we chose this type of correlation over
the standard Pearson coefficient correlation is because the
Pearson coefficient correlation measures linear correlations
betweenvariablesandassumesthevariablesarenormallydis-
tributed. However, our observed variables may have different
characteristics from those noted, and can still be considered
correlated.
If the Spearman’s rank correlation coefficient value is
above a predetermined threshold (called the correlation
threshold and denoted as Thresh s ), IMDoC increments a
counter of the candidate domain, Count( ˆ d r ). When IMDoC
has calculated the correlation between the candidate domain
and all the seed domains, it observes the counter value for the
candidate domain. If this counter is above a predetermined
threshold (called the occurrence threshold and denoted by
Thresh c ), IMDoC considers this domain to be related to the
malware campaign, as represented by the seed domains, and
appends this domain to the set of predicted domains, Y S i .
The intuition for this method is based on analyzing com-
mon behaviors of malware campaigns. Domains from the
same malware campaign are more likely to be registered to
a new IP in the same time period. The IP change event repre-
sents the beginning of the specified domain in the observed
malware campaign operations. Therefore, the traffic since
this IP change event should fit the same rate pattern. Fig. 5
illustrates this behavior, and presents a histogram of the
queries observed for 5 domains from the Bayrob malware
campaign during the week after an IP change event occurred.
Practically, the method is split into 2 phases of training and
classification. In the first phase, we calculate the time-frames
since the last IP change of all seed domains and store them
in a seed time-frame database. The classification phase cor-
relates each given suspicious domain with all the domains in
FIGURE 5. An example of query patterns since the IP change of 5
domains from the Bayrob campaign.
FIGURE 6. An illustration of the training phase of the DNS-based method.
the seed. The training phase is presented in Fig. 6 and the
classification phase is presented in Fig. 7.
V. EVALUATION AND EXPERIMENTAL RESULTS
Weimplementedextensiveexperimentsinarealworkingpro-
duction environment to evaluate the performance of IMDoC
algorithm. The experiments conducted in a Quad9 DNS envi-
ronment consisted of DNS data derived from Quad9 Recur-
sive resolvers in the form of UDR and DSURF datasets,
as discussed in Subsection II-A. In the first experiment,
the initial data were a list of known malicious domains and
their related malware campaigns (i.e. their labels). The pur-
poseofthisexperimentwastoevaluatetheclusteringmethod,
where the feature vector for each domain was the histograms
of the domain communicating files’ malware families. In this
experiment,themaliciousdomainsweredividedintoclusters,
where each cluster represented a different malware campaign
and the results were verified against the given labels of the
domains in the different clusters.
In the next two experiments, our purpose was to evalu-
ate the expansion and prediction methods used in IMDoC
algorithm. In both experiments, one of the clusters was cho-
sen as a representative example. The aim of these experi-
ments was to identify new domains which did not appear
in the given malicious domain list, but were connected to
the malware campaign represented by the chosen cluster.
Both experiments use resolved IPs to expand the chosen
cluster of domains into new domains related to this cluster
VOLUME 9, 2021 45251
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 7. An illustration of the classification phase of DNS-based method.
(i.e. these two domains resolved to the same IP address
at some point in time). The main difference between these
phases was the method in IMDoC algorithm they were
designedtoevaluate.Thefirstfocusedonusingthecommuni-
cating files of each suspected domain together with machine
learning methods to decide whether this domain matched the
cluster characteristics, whereas the second focused on using
patterns of DNS requests of each suspected domain together
with statistical methods to determine whether this domain
matched the observed cluster. The methods also operated on
data with different characteristics. For the first, the domains
had observed communicating files, whereas in the second
the domains had suitable DNS data (i.e. UDR and DSURF
available data).
A. EVALUATION BY COMMUNICATING FILES-BASED
CLUSTERING
In this experiment, we manually selected 1846 domains from
9 different malware campaigns: Bayrob, Symmi, Fobber,
Virlock, Dircrypt, Locky, Tinba, Explosive, and Cryptowall,
as shown in Table 1.
TABLE 1. Number of malicious domains in each campaign.
The data were collected using threat intelligence sites pro-
viding malicious domains feeds, such as: OSINT Feeds -
Bambenek Consulting [42], Netlab OpenData Project [43],
AlienVault - Open Threat Exchange [44]. We collected
enoughsamplesforeachmalwarecampaign(morethan50)to
establish a robust notion of the domains operating within the
context of each malware campaign. Some of the domains did
not have DNS information in the UDR dataset or in Virus-
Total, but all the selected domains did have malicious files
FIGURE 8. The distribution of malware families for the Bayrob cluster.
communicating with them, which were extracted from Virus-
Total. As explained when presenting Algorithm 1, the com-
municating files for each of the inspected domains were
extracted using VirusTotal API and the AVClass tool was run
on each file to get the file’s associated malware family from
the VirusTotal AV engines. When all the files had an associ-
ated family, IMDoC algorithm constructed a malware family
distributionforeachdomainbasedontheassociatedmalware
families for each domain’s communicating malicious files.
After going over all the given malicious domains, IMDoC
algorithm clustered them based on the malware family dis-
tribution of each domain (the feature vectors, as explained
above). As a result, each cluster included malicious domains
with a similar malware family distribution. For example,
Fig. 8 shows the average malware family distribution for the
cluster related to the Bayrob malware campaign, where each
color represents a different malware family.
Importantly, in this experiment only malicious domains
have been considered since our system is expected to receive
a feed of malicious domains, where these domains are uncat-
egorized by malicious campaigns. IMDoC clusters these
45252 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 9. A comparison of real labels and clustering results.
domains based on their communicating files, which results
in several seeds for different malicious campaigns. In this
step, benign domains are irrelevant because each cluster con-
tains only malicious domains that are a part of a certain
malicious campaign. Therefore, in this experiment we only
used malicious domains to evaluate the clustering method
that will differentiate between domains that relate to different
malicious campaigns. This is considered our ground truth for
this model.
We evaluated two clustering algorithms in this experiment:
K-Means and DBSCAN, as discussed in Subsection IV-A3.
Bothimplementationswereusedfromthescikit-learnPython
framework [51]. The input provided to these algorithms was
the feature vectors mentioned above.
To measure the performance of the algorithms against
the real labels, we used several metrics: (i) Homogeneity:
each cluster only contained members of a certain class. The
value could be between 0 and 1, where 1 stands for perfect
homogeneous labeling; (ii) Completeness: all members of a
certain class were assigned to the same cluster. The value
couldbebetween0and1,where1standsforperfectcomplete
labeling; (iii) V-measure: the harmonic mean between the
homogeneity score and the completeness score ranging from
0 to 1, where 1 stands for perfect clustering in terms of
both homogeneity and completeness; (iv) Silhouette Coef-
ficient: a measure of how similar an object is to its own
cluster (cohesion) as compared to other clusters (separation).
The best value is +1 and the worst value is −1. This mea-
sures how well a clustering method performs. A score of +1
means that the clusters are well apart from each other and
can be easily distinguished. The Silhouette Coefficient can
be written as:
x−y
max(x,y) , where x is the average inter-cluster
distance (i.e. the average distance between all clusters), and y
is the intra-cluster distance (i.e. the average distance between
each point within a cluster). Achieving high values for the
metrics presented above indicates strong performance for an
algorithm. For DBSCAN we set an epsilon of 0.5 (which is
the maximum distance between two samples for one to be
considered in the neighborhood of the other), and a minimum
threshold of 40 samples in a neighborhood for which the
sampleisconsideredacorepoint.Thedistancemetricwasthe
standard Euclidean distance. For K-Means, we noted 9 clus-
ters, the same as the number of selected malware campaigns.
We set the number of times the K-Means algorithm ran with
different centroid seeds to 50. These parameters yielded the
best results for the above metrics.
The results of the evaluation metrics present strong per-
formance for the suggested methods, as shown in Table 2.
Figure 9 depicts the results of the clustering algorithms and
TABLE 2. Results for the suggested clustering algorithms.
VOLUME 9, 2021 45253
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
FIGURE 10. The confusion matrices of the clustering algorithms.
the comparison of the real labels to the clustering labels
provided by both methods. We used T-distributed Stochas-
tic Neighbor Embedding (T-SNE) for visualization by non-
linear dimensionality reduction, which enables embedding
high-dimensional data for visualization in a low-dimensional
space of two dimensions.
Furthermore, we evaluated the performance of the cluster-
ing algorithms as a multi-class classification problem, where
each class relates to a different malware campaign. The con-
fusion matrices presented in Fig. 10(b) show that for the
K-Meansclusteringalgorithm,allthesampleswereclassified
correctly except 5 from the Explosive malware campaign and
5fromtheCryptowallmalwarecampaignthatwereclassified
as belonging to the Dircrypt malware campaign. Fig. 10(a)
indicates that for the DBSCAN clustering algorithm, all sam-
ples were classified correctly except 16 from the Cryptowall
malware campaign that were classified as noise; i.e., not
compatible with any existing cluster.
B. COMMUNICATING FILES-BASED PREDICTION
METHODS
Inthesecondexperiment,weevaluatedthepredictionmethod
based on the domain’s communicating files. In this exper-
iment, IMDoC algorithm was used to expand one of the
clusters to find more malicious domains related to the same
malware campaign. We chose the cluster that contained the
Bayrob malware domains. Bayrob is a family of Trojans
that target the Windows platform. They can download and
launch additional modules from a C&C server. They can
also function as a proxy server. The malware is used to
send spam messages and steal user data. The family was
detected in 01/26/2017 and is still operating today [54]. Note
that the Bayrob malware uses DGA to generate the mali-
cious domains, which has been reverse engineered and fully
understood [55]. This means an exact answer can be given
when a domain is observed to be generated by this DGA.
In this experiment we used DGArchive [45], a site that
provides a convenient API to check whether a domain is
part of one of the DGAs of the malwares that reside in the
DGArchive database.
To expand this cluster, we first chose the period of time to
operate. Then, IMDoC algorithm iterated over the domains
contained in this cluster, extracted the IPs whose domains
were resolved in this period of time (there could be more
than one IP) and performed a reverse search over these IPs
to find the domains resolved to them in the defined period
of time. In this experiment, IMDoC algorithm used the pas-
sive DNS data in VirusTotal to acquire the data needed to
determine which domain name resolved to which IP address.
In this experiment, for the expansion we chose the time
period between 01/01/2018 and 01/06/2020. The 107 seed
domains related to the Bayrob malware were expanded using
the resolved IPs as stated above. This expansion process
yielded 94,942 expanded domains. Since the Bayrob DGA
only generates domains with a ‘‘net’’ TLD, we filtered the
result by the ‘‘net’’ TLD, and were left with 8,594 expanded
domains. Of these expanded domains, 1,335 were verified by
the DGArchive to be part of the Bayrob DGA. It is worth
noting that the 94,942 expanded domains did not result from
only 1 expansion process, but from several iterations of this
process over domains that were predicted to be related to this
malicious campaign. It used the prediction method described
below.
The expansion process yielded numerous domains which
were either benign or malicious but not related to the specific
malware campaign. Therefore, to find the domains which
were related to the observed malware campaign, for each
of the new domains derived from the expansion process,
45254 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 3. IMDoC prediction results for clustering by communicating files.
IMDoC algorithm extracted the communicating files of these
domains. Unlike the first experiment, it predicted which
domain was related to the observed cluster based on the
malicious file distribution to determine whether it matched
the malicious file distribution of the chosen cluster (Bayrob
malware campaign).
For the K-Means clustering method, this is fairly easy,
since we can see which of the classified cluster centers’ is
the closest in terms of Euclidean distance. If it is the cluster
related to the Bayrob malware campaign, IMDoC algorithm
tags this domain as related to this cluster and the expansion
process continues as described above on the next iteration of
the algorithm.
The procedure is more complex for the DBSCAN cluster-
ingmethod,becausethereisnobuilt-inpredictionmethodfor
thisdensity-basedclustering.Wecreatedaoneclassclassifier
(i.e.OneClassSVM)onthemaliciousfiledistributionsofthe
domains residing in the chosen cluster. When a new domain
derived from the expansion is tested, IMDoC algorithm aims
topredicttheclassofthisdomainwiththeoneclassclassifier,
and determines whether this domain relates to the malware
campaign based on the outcome. One can also expand this
functionality by running a one class classifier for each of the
clusters created by the DBSCAN algorithm and implement-
ing a voting method to determine the clusters to which the
new expanded domain should be assigned.
The results of both prediction methods are described
in Table 3. Using the K-Means prediction IMDoC algorithm
successfully expanded the seed of 107 malicious domains in
the Bayrob malware campaign cluster to 1,288 new domains
predicted to be part of the Bayrob malware campaign. Out of
these domains, 1,286 were verified to have been generated
from the Bayrob malware DGA by the DGArchive. This is a
significant expansion ratio of η ≈ 13. In terms of binary clas-
sification, this experiment resulted in 1,286 TP samples, 2 FP
samples, 7,257 TN samples and 49 FN samples. In addition
to the Precision and Recall scores defined in Subsection III,
we present the Accuracy score as follows:
A =
TP + TN
TP + FP + TN + FN
. (6)
IMDoC with K-Means prediction achieved an Accuracy
score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared score of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to lascore of 0.994, a Precision score of 0.998, and a Recall
score of 0.963. Of the 1288 predicted domains only 329 had
data in the UDR dataset whereas all of them were listed in
the VirusTotal database. This may be informative as to the
coverage of malicious domains in the VirusTotal database
as compared to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Open
University of Israel, in 2010. He rge-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Open
University of Israel, in 2010. He to a real world dataset which mostly contains
benign domains.
Using the One Class Classifier (One Class SVM) pre-
diction based on the DBSCAN clustering results, IMDoC
algorithm successfully expanded the seed of 107 mali-
cious domains in the Bayrob malware campaign cluster to
1,153 new domains predicted to be part of the Bayrob mal-
ware campaign. Out of these domains, 1,152 were verified
to have been generated from the Bayrob malware DGA
by DGArchive, which corresponds to an expansion ratio of
η ≈ 11.7. In terms of binary classification, this experiment
resultedin1,152TPsamples,1FPsample,7,258TNsamples
and 183 FN samples. Thus IMDoC with One Class SVM
prediction based on the DBSCAN clustering achieved an
Accuracy score of 0.976, a Precision score of 0.999, and a
Recall score of 0.863.
C. DNS-BASED PREDICTION METHOD
In this experiment, we tested the case where no associated
files exist for the inspected domains, since only DNS related
features were observed. This experiment was used to eval-
uate the performance of the prediction method based solely
on DNS-related features and measured on top of the UDR
and DSURF data. We tested the Bayrob malware campaign
domains again, with the goal of expanding these domains and
predicting new domains related to this malware campaign.
First, to have a robust seed of malicious domains, we con-
structed a seed of 329 domains with UDR and DSURF data
from the 1,286 domains that were predicted and verified in
the previous experiment. This was required since the pre-
diction was based solely on UDR and DSURF data, so that
the domains in the seed had to exist in these datasets to
extract the features. Using IMDoC algorithm, we expanded
these seed domains, based on resolved IPs, as in the previous
experiment. However, this time the data for the IPs resolve
were derived from the UDR data. It is worth noting that
the DNS queries were only of type ’A’ because these were
the DNS queries needed for resolving the domain name into
an IPv4 address. As a result, we obtained 80,221 expanded
domains. Since we knew the domains of the Bayrob malware
had a ’net’ TLD, by its DGA characteristics, we filtered the
expandeddomainsbythisTLDandachieved3,008expanded
domains with a ’net’ TLD. Then, instead of predicting based
on associated files, IMDoC algorithm implemented the sec-
ondmethodsuggestedinAlgorithm2,andusedtheDNSdata
of requests and responses in the UDR and DSURF datasets.
The algorithm calculates a Spearman’s rank correlation coef-
ficient between each expanded domain and all the seed
domains. The correlation was based on a 7 day time period,
starting from the last UDR record for each domain (i.e. the
lastobservedIPchangeforeachdomain).Themethodcounts
VOLUME 9, 2021 45255
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
TABLE 4. IMDoC results for the DNS-based prediction method.
TABLE 5. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.9.
TABLE 6. Comparison of DNS-based prediction methods with constraints:
R ≥ 0.3,P ≥ 0.8.
the number of times the candidate domain exceeded a prede-
finedthreshold,andifitoccursapredefinednumberoftimes,
the domain is predicted to be related to the observed malware
campaign. In this experiment, we applied this prediction
method over all the 3,008 expanded domains. The results
of this experiment depended on the chosen threshold values.
Representative values for these thresholds were chosen to
demonstrate the performance of the method and the tradeoff
between Precision and Recall. When the score thresholds
were fairly low, the Recall score increased whereas the Preci-
sion score decreased. On the other hand, when the thresholds
values were high, the method is stricter and the Precision
score increased, whereas the Recall score decreased. As this
algorithm is intended to be deployed in the cyber-security
domain to identify and block malicious domains, it is more
important to achieve a high Precision score than a Recall
score. Therefore, the chosen thresholds focused on achieving
a high Precision score, while maintaining a reasonable Recall
score, as typically observed in the literature. The results are
presented in Table 4. The correlation score threshold and the
occurrence threshold are denoted by Thresh s , and Thresh c ,
respectively, as presented in Algorithm 2.
Next, we compared the proposed IMDoC algorithm to
the algorithm in [20], which proposed a prediction method
via passive DNA data for seed campaign expansion based
on unsupervised clustering, referred to as Unsupervised
Clustering-based Prediction (UCP) algorithm. The compari-
son results are presented in Tables 5 and 6. IMDoC algorithm
significantly outperformed the UCP algorithm in terms of
maximizing the expansion ratio η, and had larger margins
while meeting all the selected values for the Recall and Preci-
sion constraints. Specifically, for Recall and Precision score
constraints of 0.3 and 0.9, respectively, IMDoC achieved an
expansion ratio of 1.509, whereas UCP achieved an expan-
sion ratio of only 1.047. The actual Recall and Precision
scores were higher under IMDoC. Then, we decreased the
Precision constraint to 0.8. In this case, IMDoC achieved an
expansion ratio of 1.528, whereas UCP achieved an expan-
sion ratio of only 1.118. The actual Recall and Precision
scores were higher under IMDoC. These results demonstrate
the strong performance of IMDoC algorithm in expanding
domain seeds via passive DNS data.
VI. CONCLUSION
Malicious domain identification is a well-known problem
in cyber security systems, and extensive research has been
conducted on this topic. However, very little has been done
to develop effective solutions to relate malicious domains
to their malicious activity (i.e. malware campaign). A cyber
security system or a human analyst can glean important
insights about an observed domain’s malicious behavior and
purpose by knowing about its malicious malware campaign.
The current study lays the groundwork for a system design,
based on both the communicating files and the passive DNS
records of a domain that can identify whether an observed
domain is benign or malicious, and in case it is malicious,
can identify the malware campaign of this domain. The anal-
ysis was conducted on a real data environment, using the
Quad9 (9.9.9.9) DNS Recursive Resolver, and shows that
the proposed algorithm can meet high standards in terms of
expanding the domain seeds related to malware campaigns
under typical system constraints on Precision, and Recall
scores.
REFERENCES
[1] J.-Y. Bisiaux, ‘‘DNS threats and mitigation strategies,’’ Netw. Secur.,
vol. 2014, no. 7, pp. 5–9, Jul. 2014.
[2] K. L. Chiew, K. S. C. Yong, and C. L. Tan, ‘‘A survey of phishing
attacks: Theirtypes, vectors andtechnical approaches,’’Expert Syst.Appl.,
vol. 106, pp. 1–20, Sep. 2018.
[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and
countermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196,
Jul. 2017.
[4] M. Khonji, Y. Iraqi, and A. Jones, ‘‘Phishing detection: A literature
survey,’’ IEEE Commun. Surveys Tuts., vol. 15, no. 4, pp. 2091–2121,
Apr. 2013.
[5] M. Janbeglou, M. Zamani, and S. Ibrahim, ‘‘Redirecting outgoing DNS
requests toward a fake DNS server in a LAN,’’ in Proc. IEEE Int. Conf.
Softw. Eng. Service Sci., Jul. 2010, pp. 29–32.
[6] D. R. Sahu and D. S. Tomar, ‘‘DNS pharming through PHP injection:
Attack scenario and investigation,’’ Int. J. Comput. Netw. Inf. Secur., vol. 7,
no. 4, pp. 21–28, Mar. 2015.
45256 VOLUME 9, 2021
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
[7] L. A. Trejo, V. Ferman, M. A. Medina-Pérez, F. M. A. Giacinti,
R. Monroy, and J. E. Ramirez-Marquez, ‘‘DNS-ADVP: A machine
learning anomaly detection and visual platform to protect top-level
domain name servers against DDoS attacks,’’ IEEE Access, vol. 7,
pp. 116358–116369, Sep. 2019.
[8] W. Li, J. Jin, and J.-H. Lee, ‘‘Analysis of botnet domain names for IoT
cybersecurity,’’ IEEE Access, vol. 7, pp. 94658–94665, Jul. 2019.
[9] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
D. Kumar, C. Lever, Z. Ma, J. Mason, D. Menscher, C. Seaman,
N. Sullivan, K. Thomas, and Y. Zhou, ‘‘Understanding the Mirai botnet,’’
in Proc. USENIX Secur. Symp., Aug. 2017, pp. 1093–1110.
[10] A. Satoh, Y. Nakamura, Y. Fukuda, K. Sasai, and G. Kitagata, ‘‘A cause-
based classification approach for malicious DNS queries detected through
blacklists,’’ IEEE Access, vol. 7, pp. 142991–143001, Sep. 2019.
[11] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster, ‘‘Build-
ingadynamicreputationsystemforDNS,’’inProc.USENIXSecur.Symp.,
Aug. 2010, pp. 273–290.
[12] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon,
‘‘Detecting malware domains at the upper DNS hierarchy,’’ in Proc.
USENIX Secur. Symp., vol. 11, Aug. 2011, pp. 1–16.
[13] J. Lee and H. Lee, ‘‘GMAD: Graph-based malware activity detection by
DNS traffic analysis,’’ Comput. Commun., vol. 49, pp. 33–47, Aug. 2014.
[14] I. Khalil, T. Yu, and B. Guan, ‘‘Discovering malicious domains through
passive DNS data graph analysis,’’ in Proc. 11th ACM Asia Conf. Comput.
Commun. Secur., May 2016, pp. 663–674.
[15] G. Rosenthal, O. E. Kdosha, K. Cohen, A. Freund, A. Bartik, and A. Ron,
‘‘ARBA: Anomaly and reputation based approach for detecting infected
IoT devices,’’ IEEE Access, vol. 8, pp. 145751–145767, Aug. 2020.
[16] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier, ‘‘A survey on malicious
domains detection through DNS data analysis,’’ ACM Comput. Surv.,
vol. 51, no. 4, pp. 1–36, Sep. 2018.
[17] P. Manadhata, S. Yadav, P. Rao, and W. Horne, ‘‘Detecting malicious
domains via graph inference,’’ in Proc. Eur. Symp. Res. Comput. Secur.
Wrocław, Poland: Springer, Sep. 2014, pp. 1–18.
[18] I.Khalil,B.Guan,M.Nabeel,andT.Yu,‘‘Killingtwobirdswithonestone:
Malicious domain detection with high accuracy and coverage,’’ CoRR,
vol. abs/1711.00300, pp. 1–16, Nov. 2017.
[19] M. Stevanovic, J. M. Pedersen, A. D’Alconzo, and S. Ruehrup, ‘‘A method
for identifying compromised clients based on DNS traffic analysis,’’ Int. J.
Inf. Secur., vol. 16, no. 2, pp. 115–132, Apr. 2017.
[20] M. Weber, J. Wang, and Y. Zhou, ‘‘Unsupervised clustering for identifi-
cation of malicious domain campaigns,’’ in Proc. 1st Workshop Radical
Experiential Secur. (RESEC), May 2018, pp. 33–39.
[21] V. Kumar and O. P. Sangwan, ‘‘Signature based intrusion detection system
using SNORT,’’ Int. J. Comput. Appl. Inf. Technol., vol. 1, pp. 35–41,
Nov. 2012.
[22] K. Alieyan, A. Almomani, M. Anbar, M. Alauthman, R. Abdullah, and
B. B. Gupta,‘‘DNSrule-basedschematobotnetdetection,’’EnterpriseInf.
Syst., vol. 378, pp. 1–20, Jul. 2019.
[23] H. Holm, ‘‘Signature based intrusion detection for zero-day attacks: (Not)
a closed chapter?’’ in Proc. 47th Hawaii Int. Conf. Syst. Sci., Jan. 2014,
pp. 4895–4904.
[24] R. Villamarin-Salomon and J. C. Brustoloni, ‘‘Identifying botnets using
anomaly detection techniques applied to DNS traffic,’’ in Proc. 5th IEEE
Consum. Commun. Netw. Conf., Jan. 2008, pp. 476–481.
[25] K. Cohen and Q. Zhao, ‘‘Active hypothesis testing for anomaly detection,’’
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1432–1450, Mar. 2015.
[26] B. Huang, K. Cohen, and Q. Zhao, ‘‘Active anomaly detection in heteroge-
neous processes,’’ IEEE Trans. Inf. Theory, vol. 65, no. 4, pp. 2284–2301,
Apr. 2019.
[27] A.Gurevich,K.Cohen,andQ.Zhao,‘‘Sequentialanomalydetectionunder
a nonlinear system cost,’’ IEEE Trans. Signal Process., vol. 67, no. 14,
pp. 3689–3703, Jul. 2019.
[28] H. Gao, V. Yegneswaran, J. Jiang, Y. Chen, P. Porras, S. Ghosh, and
H. Duan, ‘‘Reexamining DNS from a global recursive resolver perspec-
tive,’’ IEEE/ACM Trans. Netw., vol. 24, no. 1, pp. 43–57, Feb. 2016.
[29] Google. Google Public DNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://developers.google.com/speed/public-dns
[30] IBM, PCH, GCA. Quad9 DNS. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.quad9.net
[31] Cisco. Cisco OpenDNS. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.opendns.com/cisco-opendns
[32] Cloudflare. Cloudflare 1.1.1.1 DNS. Accessed: Oct. 1, 2020. [Online].
Available: https://1.1.1.1/dns
[33] Online Data Source. DNSBL.Info—Spam Database Lookup.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.dnsbl.info
[34] Online Data Source. Phishtank. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://www.phishtank.com.
[35] Online Data Source. Openphish. Accessed: Oct. 1, 2020. [Online]. Avail-
able: https://openphish.com.
[36] Online Data Source by IBM. IBM X-Force Threat Intelligence.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.ibm.com/
security/xforce
[37] Online Data Source by VirusTotal. VirusTotal. Accessed: Oct. 1, 2020.
[Online]. Available: https://www.virustotal.com
[38] Online Data Source by McAfee. Mcafee siteadvisor.
Accessed: Oct. 1, 2020. [Online]. Available: https://www.mcafee.com/
siteadvisor.
[39] OnlineDataSource.malwaredomainlist.Accessed:Oct.1,2020.[Online].
Available: http://www.malwaredomainlist.com.
[40] Online Data Source. malc0de.com. Accessed: Oct. 1, 2020. [Online].
Available: http://malc0de.com.
[41] Online Data Source by RiskAnalytics. DNS-BH—Malware
Domain Blocklist. Accessed: Oct. 1, 2020. [Online]. Available:
https://www.malwaredomains.com
[42] Online Data Source by Bambenek Consulting. OSINT Feeds.
Accessed: Oct. 1, 2020. [Online]. Available: https://osint.
bambenekconsulting.com/feeds
[43] Online Data Source by Netlab. Netlab Opendata Project.
Accessed: Oct. 1, 2020. [Online]. Available: https://data.netlab.360.com
[44] Online Data Source. Alienvault—Open Threat Exchange.
Accessed: Oct. 1, 2020. [Online]. Available: https://otx.alienvault.com.
[45] Online Data Source by Fraunhofer FKIE. DGArchive.
Accessed: Oct. 1, 2020. [Online]. Available: https://dgarchive.caad.
fkie.fraunhofer.de
[46] H. Zhao, Z. Chang, W. Wang, and X. Zeng, ‘‘Malicious domain names
detection algorithm based on lexical analysis and feature quantification,’’
IEEE Access, vol. 7, pp. 128990–128999, Sep. 2019.
[47] G. Zhao, K. Xu, L. Xu, and B. Wu, ‘‘Detecting APT malware infec-
tions based on malicious DNS and traffic analysis,’’ IEEE Access, vol. 3,
pp. 1132–1142, Aug. 2015.
[48] B. Yu, J. Pan, D. Gray, J. Hu, C. Choudhary, A. C. A. Nascimento,
and M. De Cock, ‘‘Weakly supervised deep learning for the detection of
domain generation algorithms,’’ IEEE Access, vol. 7, pp. 51542–51556,
Apr. 2019.
[49] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero, ‘‘AVclass: A tool for
massive malware labeling,’’ in Proc. Int. Symp. Res. Attacks, Intrusions,
Defenses. Évry, France: Springer Sep. 2016, pp. 230–253.
[50] M. Sebastián, R. Rivera, P. Kotzias, and J. Caballero. AVClass:
Malware Labeling Tool’s Github Repository. [Online]. Available:
https://github.com/malicialab/avclass
[51] Online Data Source. Scikit-Learn: Machine Learning in Python.
Accessed: Oct. 1, 2020. [Online]. Available: https://scikit-learn.org
[52] Online Data Source by MITRE. CWE-350: Reliance on Reverse DNS
ResolutionforaSecurity-CriticalAction.Accessed:Oct.1,2020.[Online].
Available: https://cwe.mitre.org/data/definitions/350.html
[53] W. W. Daniel, ‘‘Spearman rank correlation coefficient,’’ Applied Nonpara-
metric Statistics, 2nd ed. Boston, MA, USA: PWS, 1990, pp. 358–365.
Accessed: Oct. 1, 2020.
[54] Online Data Source by Kaspersky. Kaspersky Threats—Bayrob.
Accessed: Oct. 1, 2020. [Online]. Available: https://threats.kaspersky.
com/en/threat/Trojan.Win32.Bayrob
[55] J.Geffner,‘‘Endtoendanalysisofadomaingeneratingalgorithmmalware
family,’’ in Proc. Blackhat USA, Aug. 2013, pp. 1–70.
DAVID LAZAR received the B.Sc. degree in com-
puter science from Tel Aviv University, Israel,
in2014.He iscurrentlypursuingtheM.Sc.degree
in computer science with Ben-Gurion Univer-
sity, Israel. His current research interests include
machine learning, artificial intelligence, and data
science in the cybersecurity domain.
VOLUME 9, 2021 45257
D. Lazar et al.: IMDoC: IMDoC via DNS and Communicating Files
KOBI COHEN (Senior Member, IEEE) received
the B.Sc. and Ph.D. degrees in electrical engineer-
ing from Bar-Ilan University, Ramat Gan, Israel,
in 2007 and 2013, respectively. In October 2015,
he joined the Department of Electrical and Com-
puter Engineering, Ben-Gurion University of the
Negev (BGU), Beer Sheva, Israel, as a Senior
Lecturer (an Assistant Professor in USA). He is
also a member of the Cyber Security Research
Center, and the Data Science Research Center,
BGU.BeforejoiningBGU,hewaswiththeCoordinatedScienceLaboratory,
University of Illinois at Urbana-Champaign, from August 2014 to July 2015,
and the Department of Electrical and Computer Engineering, University of
California at Davis, Davis, CA, USA, from November 2012 to July 2014,
as a Postdoctoral Research Associate. His main research interests include
decision theory, stochastic optimization, and statistical inference and learn-
ing, with applications to large-scale systems, cyber systems, wireless, and
wireline networks. He has received several awards including the Best Paper
Award in the International Symposium on Modeling and Optimization in
Mobile, Ad hoc and Wireless Networks (WiOpt) 2015, the Feder Family
Award (Second Prize), awarded by the Advanced Communication Center
at Tel Aviv University in 2011, and the President Fellowship from 2008 to
2012, and top Honor List’s prizes from Bar-Ilan University, in 2006, 2010,
and 2011.
ALON FREUND received the B.Sc. degree
from the Communication Systems Engineering
Department, Ben-Gurion University, where he is
currently pursuing the M.Sc. degree with the
Software and Information Systems Engineering
Department. He currently works with the IBM’s
Cyber Security Center of Excellence (CCoE),
Beer-Sheva, Israel. His main research interests
include network security and data science.
AVISHAY BARTIK received the B.Sc. degree in
mathematics and computer science from the Open
University of Israel, in 2010. He is currently a
Security Researcher with the IBM’s Cyber Secu-
rity Center of Excellence, Beer-Sheva, specializ-
inginnetworkandsystemsecurity.Priortojoining
IBM, he served as a Security Software Engineer
for PMO.
AVIV RON received the B.Sc. degree in com-
puter science from Ben-Gurion University, Israel,
in 2007. He worked for five years as a Soft-
ware Engineer with Intel, four years as a Security
Researcher and Architect with Intel, and five years
as a Senior Security Researcher with IBM. He also
served for four years as an External Lecturer on
cyber security with Ben Gurion University. He has
17 patents. He is currently focused on detecting
cyber threats by applying artificial intelligence.
45258 VOLUME 9, 2021
